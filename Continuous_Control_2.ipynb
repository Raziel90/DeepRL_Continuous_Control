{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='/Users/claudiocoppola/code/RL_repos/Reacher.app', no_graphics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model.agents:--------------------\n",
      "INFO:src.model.agents: State dimension: 33\t Action dimension: 4\t Action Limit: 1.0\n",
      "INFO:src.model.agents:Network hidden units: [256, 256] -> Total hidden weights: 65536\n",
      "INFO:src.model.agents:Network params: \n",
      "INFO:src.model.agents:{'action_limit': 1.0, 'gamma': 0.99, 'activation': <class 'torch.nn.modules.activation.Tanh'>, 'batch_size': 1024, 'update_every': 1000, 'hidden_sizes': [256, 256]}\n",
      "INFO:src.model.agents:--------------------\n",
      "Episode 0: 200 steps\tAverage Score: 0.00\n",
      "Episode 100: 20200 steps\tAverage Score: 0.15\n",
      "Episode 200: 40200 steps\tAverage Score: 0.09\n",
      "Episode 300: 60200 steps\tAverage Score: 0.20\n",
      "Episode 400: 80200 steps\tAverage Score: 0.23\n",
      "Episode 500: 100200 steps\tAverage Score: 0.26\n",
      "Episode 600: 120200 steps\tAverage Score: 0.27\n",
      "Episode 700: 140200 steps\tAverage Score: 0.30\n",
      "Episode 800: 160200 steps\tAverage Score: 0.30\n",
      "Episode 900: 180200 steps\tAverage Score: 0.36\n",
      "Episode 1000: 200200 steps\tAverage Score: 0.22\n",
      "Episode 1100: 220200 steps\tAverage Score: 0.25\n",
      "Episode 1200: 240200 steps\tAverage Score: 0.32\n",
      "Episode 1300: 260200 steps\tAverage Score: 0.23\n",
      "Episode 1400: 280200 steps\tAverage Score: 0.22\n",
      "Episode 1500: 300200 steps\tAverage Score: 0.16\n",
      "Episode 1600: 320200 steps\tAverage Score: 0.14\n",
      "Episode 1700: 340200 steps\tAverage Score: 0.18\n",
      "Episode 1800: 360200 steps\tAverage Score: 0.20\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from src.model.agents import DDPG_Agent\n",
    "\n",
    "n_episodes = 50_000\n",
    "max_duration = 200\n",
    "network_config = {\n",
    "    \"action_limit\": 1.,\n",
    "    \"gamma\": .99,\n",
    "    \"activation\": nn.Tanh,\n",
    "    \"batch_size\": 1024,\n",
    "    \"update_every\": 1000,\n",
    "    \"pi_lr\": 1e-3,\n",
    "    \"q_lr\" : 1e-4,\n",
    "    \"tau\": 0.1,\n",
    "    \"hidden_sizes\": [256, 256]\n",
    "                  }\n",
    "agent = DDPG_Agent(env, network_config=network_config, seed=None)\n",
    "agent.run_training(\n",
    "    n_episodes, max_duration, \n",
    "    eps_start=0.1, eps_end=0.01, \n",
    "    eps_decay=1-1e-6, update_every=100, \n",
    "    update_after=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.actor_critic.pi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
