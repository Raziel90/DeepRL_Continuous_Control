{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from agent import PPOAgent\n",
    "from trainer import PPOTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "INFO:agent:\t------------------------------- Params -------------------------------\n",
      "INFO:agent:\tState dimension: 33\t Action dimension: 4\t Action Limit: 1.0\n",
      "INFO:agent:\tNetwork hidden units: [256, 256] -> Total hidden weights: 65536\n",
      "INFO:agent:\tNetwork hidden activations: <class 'torch.nn.modules.activation.ReLU'>\n",
      "INFO:agent:\tNetwork output activation: <class 'torch.nn.modules.activation.Tanh'>\n",
      "INFO:agent:\t----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Linear(in_features=33, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=4, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='/Users/claudiocoppola/code/RL_repos/Reacher.app', no_graphics=True)\n",
    "agent = PPOAgent(env, network_config={'hidden_sizes':[256, 512, 256], 'hidden_activation': nn.Tanh, 'action_std': 5e-1})\n",
    "agent.policy.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer:\t------------------------------- Params -------------------------------\n",
      "INFO:trainer:\tEpsilon clip: 0.1\t Gamma: 0.99\t Learning Rate: 0.001\n",
      "INFO:trainer:\tTraining epochs: 40 \n",
      "INFO:trainer:\tUsing Normalized Advantage: True \n",
      "INFO:trainer:\tUsing General Advantage Estimation: True \n",
      "INFO:trainer:\t----------------------------------------------------------------------\n",
      "DEBUG:trainer:Debug mode is : ON\n",
      "INFO:trainer:\t------------------------------ Training ------------------------------\n",
      "INFO:trainer:\tN Episodes 1000 , max length episode: 3000\n",
      "INFO:trainer:\tUpdate every 512 episodes\n",
      "INFO:trainer:\tPrint every 100 episodes\n",
      "INFO:trainer:\tTarget score: 30.0\n",
      "INFO:trainer:\t----------------------------------------------------------------------\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.017539311200380325, critic_loss: 1.1769191026687622, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.017513994127511978, critic_loss: 1.0542184114456177, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.017481781542301178, critic_loss: 0.9815521836280823, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.017444584518671036, critic_loss: 0.9369301795959473, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.017425190657377243, critic_loss: 0.9054689407348633, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.01743427664041519, critic_loss: 0.8781372308731079, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.017442869022488594, critic_loss: 0.8512349724769592, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.01744893752038479, critic_loss: 0.8253272175788879, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.017448537051677704, critic_loss: 0.8035317063331604, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.017439810559153557, critic_loss: 0.7883961200714111, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.01742629148066044, critic_loss: 0.7793940305709839, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.01741017773747444, critic_loss: 0.7736426591873169, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.017390748485922813, critic_loss: 0.7683389186859131, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.0173695906996727, critic_loss: 0.762413501739502, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.017348505556583405, critic_loss: 0.7561132907867432, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.017334861680865288, critic_loss: 0.7500972747802734, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.01732192188501358, critic_loss: 0.7449101209640503, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.017311440780758858, critic_loss: 0.7407046556472778, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.01731814816594124, critic_loss: 0.7372862100601196, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.017318427562713623, critic_loss: 0.7342455387115479, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.017310481518507004, critic_loss: 0.7312043905258179, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.017301322892308235, critic_loss: 0.7279050946235657, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.017288418486714363, critic_loss: 0.7244553565979004, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.017270540818572044, critic_loss: 0.7211924195289612, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.017248500138521194, critic_loss: 0.7184689044952393, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.017236553132534027, critic_loss: 0.7164408564567566, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.01723061501979828, critic_loss: 0.7149143218994141, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.017229581251740456, critic_loss: 0.7135677933692932, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.017222935333848, critic_loss: 0.7121613621711731, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.017208971083164215, critic_loss: 0.7106710076332092, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.017194146290421486, critic_loss: 0.7092451453208923, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.01718147285282612, critic_loss: 0.7080337405204773, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.017172034829854965, critic_loss: 0.7070403695106506, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.0171627439558506, critic_loss: 0.7061378359794617, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.01715274713933468, critic_loss: 0.7051724195480347, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.01714060828089714, critic_loss: 0.7040857076644897, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.017129072919487953, critic_loss: 0.7029375433921814, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.01712009683251381, critic_loss: 0.7018492221832275, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.01711154729127884, critic_loss: 0.7009172439575195, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.01710130088031292, critic_loss: 0.700141966342926, entropy_bonus: 12.113506317138672\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.003661567810922861, critic_loss: 0.6796456575393677, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.025754565373063087, critic_loss: 0.6819161772727966, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.025754565373063087, critic_loss: 0.6817207932472229, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.025754565373063087, critic_loss: 0.6797081828117371, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.025754565373063087, critic_loss: 0.6761826872825623, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.025754565373063087, critic_loss: 0.6713142991065979, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.025754565373063087, critic_loss: 0.66543048620224, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.025754565373063087, critic_loss: 0.6588709950447083, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.025754565373063087, critic_loss: 0.651970386505127, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.025754565373063087, critic_loss: 0.6450887322425842, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.025754565373063087, critic_loss: 0.6386225819587708, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.025754565373063087, critic_loss: 0.6329009532928467, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.025754565373063087, critic_loss: 0.6281557679176331, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.025754565373063087, critic_loss: 0.6245683431625366, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.025754565373063087, critic_loss: 0.622150182723999, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.025754565373063087, critic_loss: 0.6207936406135559, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.025754565373063087, critic_loss: 0.6202834248542786, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.025754565373063087, critic_loss: 0.6203124523162842, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.025754565373063087, critic_loss: 0.6205489039421082, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.025754565373063087, critic_loss: 0.6206892132759094, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.025754565373063087, critic_loss: 0.6204835772514343, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.025754565373063087, critic_loss: 0.6197903752326965, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.025754565373063087, critic_loss: 0.6185717582702637, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.025754565373063087, critic_loss: 0.6168659925460815, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.025754565373063087, critic_loss: 0.614777147769928, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.025754565373063087, critic_loss: 0.612436056137085, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.025754565373063087, critic_loss: 0.6099817752838135, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.025754565373063087, critic_loss: 0.6075440645217896, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.025754565373063087, critic_loss: 0.6052286028862, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.025754565373063087, critic_loss: 0.603105366230011, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.025754565373063087, critic_loss: 0.6012090444564819, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.025754565373063087, critic_loss: 0.5995431542396545, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.025754565373063087, critic_loss: 0.5980957746505737, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.025754565373063087, critic_loss: 0.5968329906463623, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.025754565373063087, critic_loss: 0.595707356929779, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.025754565373063087, critic_loss: 0.5946641564369202, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.025754565373063087, critic_loss: 0.5936505198478699, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.025754565373063087, critic_loss: 0.59263014793396, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.025754565373063087, critic_loss: 0.5915670394897461, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.025754565373063087, critic_loss: 0.5904417037963867, entropy_bonus: -49.58628845214844\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.001269208500161767, critic_loss: 0.8170002102851868, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.012552610598504543, critic_loss: 0.8141857385635376, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.012831008993089199, critic_loss: 0.8096540570259094, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.012616582214832306, critic_loss: 0.8037987351417542, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.012799853459000587, critic_loss: 0.7970413565635681, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.012802374549210072, critic_loss: 0.7898366451263428, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.012978309765458107, critic_loss: 0.7826255559921265, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.01285524107515812, critic_loss: 0.775802731513977, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.01294342428445816, critic_loss: 0.7696841359138489, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.01293341163545847, critic_loss: 0.7645248770713806, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.013014734722673893, critic_loss: 0.7605370879173279, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.01290337834507227, critic_loss: 0.7579053044319153, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.012875682674348354, critic_loss: 0.75644850730896, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.012812290340662003, critic_loss: 0.7559499740600586, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.012803735211491585, critic_loss: 0.7561788558959961, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.012769349850714207, critic_loss: 0.7566697001457214, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.012772218324244022, critic_loss: 0.757073163986206, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.012773476541042328, critic_loss: 0.7570104002952576, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.012879136949777603, critic_loss: 0.7564752697944641, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.012901997193694115, critic_loss: 0.7554994821548462, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.012803630903363228, critic_loss: 0.7542134523391724, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.012765333987772465, critic_loss: 0.7526373267173767, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.01275476161390543, critic_loss: 0.7508359551429749, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.012744590640068054, critic_loss: 0.7489455342292786, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.012715255841612816, critic_loss: 0.7470933198928833, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.012769185937941074, critic_loss: 0.7453874945640564, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.012777107767760754, critic_loss: 0.7439166307449341, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.012737632729113102, critic_loss: 0.7427175641059875, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.012733533047139645, critic_loss: 0.7417466640472412, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.012733020819723606, critic_loss: 0.7409428954124451, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.012724890373647213, critic_loss: 0.7402715086936951, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.012730268761515617, critic_loss: 0.7396852374076843, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.012735964730381966, critic_loss: 0.7391486167907715, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.012701241299510002, critic_loss: 0.7386283278465271, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.01274113729596138, critic_loss: 0.7380675077438354, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.012743460945785046, critic_loss: 0.7375199198722839, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.012751376256346703, critic_loss: 0.7369458079338074, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.01271508727222681, critic_loss: 0.7363446354866028, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.012713786214590073, critic_loss: 0.7357017397880554, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.012707331217825413, critic_loss: 0.7350375056266785, entropy_bonus: -31.205806732177734\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.0009656702750362456, critic_loss: 0.8504406809806824, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.022355061024427414, critic_loss: 0.8481635451316833, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.015741106122732162, critic_loss: 0.8447121381759644, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.015830209478735924, critic_loss: 0.8402707576751709, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.016038861125707626, critic_loss: 0.8350721001625061, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.016194216907024384, critic_loss: 0.829332709312439, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.016312403604388237, critic_loss: 0.8233257532119751, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.016399787738919258, critic_loss: 0.8173657655715942, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.016463790088891983, critic_loss: 0.8117316365242004, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.016511525958776474, critic_loss: 0.8066530823707581, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.01654686965048313, critic_loss: 0.8023056983947754, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.016571957617998123, critic_loss: 0.7988315224647522, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.01659533381462097, critic_loss: 0.7963309288024902, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.016614409163594246, critic_loss: 0.7948322296142578, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.016629640012979507, critic_loss: 0.7942562699317932, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.01664135977625847, critic_loss: 0.7943834066390991, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.016650307923555374, critic_loss: 0.794927716255188, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.016657153144478798, critic_loss: 0.79551100730896, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.0166623555123806, critic_loss: 0.7958419919013977, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.016666194424033165, critic_loss: 0.7957251667976379, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.016668975353240967, critic_loss: 0.7950788140296936, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.016672082245349884, critic_loss: 0.7939218878746033, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.016674984246492386, critic_loss: 0.7923542857170105, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.016677118837833405, critic_loss: 0.7905206680297852, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.01667887158691883, critic_loss: 0.7885792851448059, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.016682090237736702, critic_loss: 0.7866766452789307, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.01668640412390232, critic_loss: 0.7849270701408386, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.016690438613295555, critic_loss: 0.783404529094696, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.016695227473974228, critic_loss: 0.7821395993232727, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.016699789091944695, critic_loss: 0.7811253666877747, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.016703084111213684, critic_loss: 0.7803246378898621, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.016705505549907684, critic_loss: 0.7796821594238281, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.016706736758351326, critic_loss: 0.7791377902030945, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.016706865280866623, critic_loss: 0.7786336541175842, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.016705704852938652, critic_loss: 0.7781184911727905, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.01670331507921219, critic_loss: 0.777559757232666, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.01669994182884693, critic_loss: 0.7769367098808289, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.01669555902481079, critic_loss: 0.7762452363967896, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.016690174117684364, critic_loss: 0.7754947543144226, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.016684578731656075, critic_loss: 0.7747039198875427, entropy_bonus: -28.413066864013672\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: -0.0030074084643274546, critic_loss: 0.6145902276039124, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.027581173926591873, critic_loss: 0.6084660887718201, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.0289203729480505, critic_loss: 0.6004847288131714, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.029963931068778038, critic_loss: 0.5914500951766968, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.035380374640226364, critic_loss: 0.5823336243629456, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.031212223693728447, critic_loss: 0.5738528370857239, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0321393720805645, critic_loss: 0.5663426518440247, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.03299727290868759, critic_loss: 0.5601276755332947, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.033210717141628265, critic_loss: 0.5552468299865723, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.03339686989784241, critic_loss: 0.5516605973243713, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.03347715362906456, critic_loss: 0.5491312742233276, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.033483266830444336, critic_loss: 0.5473021864891052, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.03344053775072098, critic_loss: 0.5458328723907471, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.033364925533533096, critic_loss: 0.5444313883781433, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.033270321786403656, critic_loss: 0.5428866744041443, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.03316313400864601, critic_loss: 0.5410881042480469, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.03303425759077072, critic_loss: 0.5390030145645142, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.03287778049707413, critic_loss: 0.5366589426994324, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.032682038843631744, critic_loss: 0.5341376066207886, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.032443173229694366, critic_loss: 0.531546413898468, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0321490652859211, critic_loss: 0.5289905071258545, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.03229861706495285, critic_loss: 0.5266307592391968, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.03207718953490257, critic_loss: 0.5244584679603577, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.03199707344174385, critic_loss: 0.5225142240524292, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.0318770706653595, critic_loss: 0.5208120942115784, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.03172248229384422, critic_loss: 0.5193495154380798, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.03158709779381752, critic_loss: 0.5181331634521484, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.0313820019364357, critic_loss: 0.517129123210907, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.031177401542663574, critic_loss: 0.5162906050682068, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.030880291014909744, critic_loss: 0.5155742764472961, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.03092212602496147, critic_loss: 0.5149481296539307, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.030906006693840027, critic_loss: 0.5143806338310242, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.03078412264585495, critic_loss: 0.5138389468193054, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.030772216618061066, critic_loss: 0.5133171081542969, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.0307270810008049, critic_loss: 0.5128062963485718, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.030589360743761063, critic_loss: 0.5123023986816406, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.030439002439379692, critic_loss: 0.5118005275726318, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.030422493815422058, critic_loss: 0.5113016366958618, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.03042161464691162, critic_loss: 0.5108248591423035, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.030490819364786148, critic_loss: 0.5103855729103088, entropy_bonus: -26.78451156616211\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.010923399589955807, critic_loss: 0.5926340222358704, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.056201424449682236, critic_loss: 0.590208888053894, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.056989263743162155, critic_loss: 0.58713299036026, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.05632314458489418, critic_loss: 0.5834335088729858, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.0571894496679306, critic_loss: 0.5795078277587891, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.057206667959690094, critic_loss: 0.5750240087509155, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.057249680161476135, critic_loss: 0.5703502297401428, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.057879868894815445, critic_loss: 0.5656022429466248, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.059072595089673996, critic_loss: 0.5608617067337036, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.05764912813901901, critic_loss: 0.5564570426940918, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.057979706674814224, critic_loss: 0.5522024631500244, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.05841605365276337, critic_loss: 0.5480829477310181, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.058836519718170166, critic_loss: 0.5441218018531799, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.058923766016960144, critic_loss: 0.5403419733047485, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.05896193906664848, critic_loss: 0.5367524027824402, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.0590132400393486, critic_loss: 0.5333633422851562, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.05899902805685997, critic_loss: 0.5301679968833923, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.058968476951122284, critic_loss: 0.5271891951560974, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.05882686376571655, critic_loss: 0.5244730710983276, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.05859093368053436, critic_loss: 0.5219926238059998, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.058546144515275955, critic_loss: 0.5197558999061584, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.05836540833115578, critic_loss: 0.5179417729377747, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.05833997204899788, critic_loss: 0.5163354873657227, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.058431562036275864, critic_loss: 0.5149489641189575, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.05840243399143219, critic_loss: 0.5137584209442139, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.059264086186885834, critic_loss: 0.5127429366111755, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.057905346155166626, critic_loss: 0.5119656920433044, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.058532942086458206, critic_loss: 0.5113341212272644, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.05821145325899124, critic_loss: 0.5108681321144104, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.05798516422510147, critic_loss: 0.5105020403862, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.05888381227850914, critic_loss: 0.5102032423019409, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.058738939464092255, critic_loss: 0.5100196003913879, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.05862778052687645, critic_loss: 0.509869396686554, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.05919749289751053, critic_loss: 0.5097999572753906, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.05982078239321709, critic_loss: 0.5097992420196533, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.059748247265815735, critic_loss: 0.5097919702529907, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.06258249282836914, critic_loss: 0.509678840637207, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.0603732205927372, critic_loss: 0.5093807578086853, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.06001506745815277, critic_loss: 0.509063720703125, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.06002203747630119, critic_loss: 0.5087265372276306, entropy_bonus: -25.630441665649414\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008198871277272701, critic_loss: 0.5220306515693665, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.04451148957014084, critic_loss: 0.5205873847007751, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.04435804858803749, critic_loss: 0.51811283826828, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.04169763624668121, critic_loss: 0.5153769254684448, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.040910568088293076, critic_loss: 0.5125378370285034, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.04005622863769531, critic_loss: 0.5097554326057434, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.04016002640128136, critic_loss: 0.5069431066513062, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.040097132325172424, critic_loss: 0.5043273568153381, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.04014759510755539, critic_loss: 0.5019086599349976, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.04012950137257576, critic_loss: 0.4995259642601013, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.04014885053038597, critic_loss: 0.49714556336402893, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.040133070200681686, critic_loss: 0.49469423294067383, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.04008275270462036, critic_loss: 0.49213674664497375, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.04000499099493027, critic_loss: 0.48945507407188416, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.03990188613533974, critic_loss: 0.48663705587387085, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.03977544233202934, critic_loss: 0.48370102047920227, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.03965061157941818, critic_loss: 0.48067033290863037, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.039551373571157455, critic_loss: 0.4775688648223877, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.0394892618060112, critic_loss: 0.47443586587905884, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.03946631774306297, critic_loss: 0.4713142216205597, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.03950589522719383, critic_loss: 0.4682375192642212, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.03953761234879494, critic_loss: 0.46526098251342773, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.03964352607727051, critic_loss: 0.4624611735343933, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.039634544402360916, critic_loss: 0.45989280939102173, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.039649032056331635, critic_loss: 0.45758676528930664, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.03963325545191765, critic_loss: 0.4555446207523346, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.039601247757673264, critic_loss: 0.45373621582984924, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.03954674303531647, critic_loss: 0.4520989656448364, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.039625540375709534, critic_loss: 0.45060721039772034, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.03961687907576561, critic_loss: 0.4492799937725067, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.039486855268478394, critic_loss: 0.44810062646865845, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.0394616574048996, critic_loss: 0.4470306932926178, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.039469439536333084, critic_loss: 0.44603919982910156, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.03939928114414215, critic_loss: 0.44512122869491577, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.03941422700881958, critic_loss: 0.4442906081676483, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.03936202451586723, critic_loss: 0.4434933364391327, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.03928274288773537, critic_loss: 0.442721962928772, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.039211053401231766, critic_loss: 0.4419708251953125, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.03914296254515648, critic_loss: 0.44123679399490356, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.0390961579978466, critic_loss: 0.44055983424186707, entropy_bonus: -24.735862731933594\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.010829806327819824, critic_loss: 0.5321325063705444, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.042157940566539764, critic_loss: 0.5299702882766724, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.04605584591627121, critic_loss: 0.5267143845558167, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.04327556863427162, critic_loss: 0.5228686332702637, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.043188661336898804, critic_loss: 0.5185788869857788, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.04297300800681114, critic_loss: 0.5142260193824768, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.043614111840724945, critic_loss: 0.5097649693489075, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.04398063197731972, critic_loss: 0.5052546262741089, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.044347457587718964, critic_loss: 0.5008611083030701, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.04400267079472542, critic_loss: 0.49664396047592163, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.04367803782224655, critic_loss: 0.49265316128730774, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.04374557361006737, critic_loss: 0.4889548122882843, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.04391630366444588, critic_loss: 0.48547717928886414, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.04402900114655495, critic_loss: 0.4822733402252197, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.04404205456376076, critic_loss: 0.47943687438964844, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.04424960911273956, critic_loss: 0.47693106532096863, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.04394283518195152, critic_loss: 0.4747298061847687, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.04370037093758583, critic_loss: 0.47279366850852966, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.043598804622888565, critic_loss: 0.47108203172683716, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.043400079011917114, critic_loss: 0.46963268518447876, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0430668406188488, critic_loss: 0.46838223934173584, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.04271396994590759, critic_loss: 0.4672960340976715, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.04254969581961632, critic_loss: 0.4663686156272888, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.04270056635141373, critic_loss: 0.4655287563800812, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.042715445160865784, critic_loss: 0.4647327661514282, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.04268357902765274, critic_loss: 0.4639575481414795, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.04264843463897705, critic_loss: 0.46320679783821106, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.04234565794467926, critic_loss: 0.4624846577644348, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.04209639132022858, critic_loss: 0.46179112792015076, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.04206383600831032, critic_loss: 0.4611474871635437, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.04186893254518509, critic_loss: 0.46056318283081055, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.041920505464076996, critic_loss: 0.46004724502563477, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.041810330003499985, critic_loss: 0.4595779478549957, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.04162270575761795, critic_loss: 0.4591444432735443, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.041519660502672195, critic_loss: 0.45872628688812256, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.04134400933980942, critic_loss: 0.45830613374710083, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.041186943650245667, critic_loss: 0.45787709951400757, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.04117796570062637, critic_loss: 0.4574351906776428, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.041098035871982574, critic_loss: 0.4569990038871765, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.04101870581507683, critic_loss: 0.4565708041191101, entropy_bonus: -24.00524139404297\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.015128337778151035, critic_loss: 0.5295515060424805, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.035978127270936966, critic_loss: 0.5258440375328064, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.03667319566011429, critic_loss: 0.5198919177055359, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.04306634142994881, critic_loss: 0.5125262141227722, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.04522547870874405, critic_loss: 0.5043774247169495, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.047217439860105515, critic_loss: 0.49581611156463623, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.048197098076343536, critic_loss: 0.4874711036682129, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.048709023743867874, critic_loss: 0.47962686419487, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.048789143562316895, critic_loss: 0.4724501371383667, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.048476096242666245, critic_loss: 0.4660135805606842, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.04791269823908806, critic_loss: 0.46041491627693176, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.04731673747301102, critic_loss: 0.4557003080844879, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0468389131128788, critic_loss: 0.4518887996673584, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.04634147509932518, critic_loss: 0.44892239570617676, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.04603099822998047, critic_loss: 0.4467184841632843, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.046215303242206573, critic_loss: 0.44516995549201965, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.046298831701278687, critic_loss: 0.44415172934532166, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.04667577147483826, critic_loss: 0.44353926181793213, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.04611438140273094, critic_loss: 0.44321906566619873, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.045993685722351074, critic_loss: 0.44306761026382446, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.04576832056045532, critic_loss: 0.44297516345977783, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.045812156051397324, critic_loss: 0.44285881519317627, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.04638272896409035, critic_loss: 0.44265541434288025, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.04641351103782654, critic_loss: 0.4423348307609558, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.04666623845696449, critic_loss: 0.44192972779273987, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.04669857397675514, critic_loss: 0.4414786398410797, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.0460430383682251, critic_loss: 0.4409950077533722, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.045922283083200455, critic_loss: 0.4404756724834442, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.04576197639107704, critic_loss: 0.4398975968360901, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.045852985233068466, critic_loss: 0.4392431676387787, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.04607810080051422, critic_loss: 0.4385271966457367, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.04609208181500435, critic_loss: 0.437772661447525, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.04600062593817711, critic_loss: 0.4370053708553314, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.04589926451444626, critic_loss: 0.4362570643424988, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.04578171670436859, critic_loss: 0.4355536103248596, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.0458136610686779, critic_loss: 0.434923380613327, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.045755382627248764, critic_loss: 0.43437713384628296, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.045610152184963226, critic_loss: 0.4339201748371124, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.045465610921382904, critic_loss: 0.4335517883300781, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.045290131121873856, critic_loss: 0.43326714634895325, entropy_bonus: -23.387683868408203\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.006086338777095079, critic_loss: 0.5216191411018372, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.02727622538805008, critic_loss: 0.5212616324424744, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.022064220160245895, critic_loss: 0.5199439525604248, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.027401281520724297, critic_loss: 0.5179462432861328, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.03027508035302162, critic_loss: 0.5160547494888306, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.031202027574181557, critic_loss: 0.5137396454811096, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.02998681180179119, critic_loss: 0.5112741589546204, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.02904052659869194, critic_loss: 0.5086225271224976, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.0284370556473732, critic_loss: 0.505850613117218, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.02920066937804222, critic_loss: 0.5030121803283691, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.029641248285770416, critic_loss: 0.5002737641334534, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.02961030788719654, critic_loss: 0.49759578704833984, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.02959287539124489, critic_loss: 0.4949788749217987, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.029513338580727577, critic_loss: 0.49247482419013977, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.02952253632247448, critic_loss: 0.49003955721855164, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.029664190486073494, critic_loss: 0.48768022656440735, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.029490726068615913, critic_loss: 0.48533371090888977, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.02928817830979824, critic_loss: 0.48300522565841675, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.02958931401371956, critic_loss: 0.48081591725349426, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.02950778603553772, critic_loss: 0.4787663221359253, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.029049353674054146, critic_loss: 0.4768391251564026, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.029235096648335457, critic_loss: 0.47500208020210266, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.029261821880936623, critic_loss: 0.47325146198272705, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.029008669778704643, critic_loss: 0.47157710790634155, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.028249913826584816, critic_loss: 0.4700028896331787, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.028106791898608208, critic_loss: 0.4685390889644623, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.028108742088079453, critic_loss: 0.4671640396118164, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.028374996036291122, critic_loss: 0.4658195972442627, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.028385113924741745, critic_loss: 0.4646184742450714, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.02808191440999508, critic_loss: 0.4635619521141052, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.027980022132396698, critic_loss: 0.4626522660255432, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.027547305449843407, critic_loss: 0.46187180280685425, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.027465464547276497, critic_loss: 0.4611966609954834, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.027523241937160492, critic_loss: 0.4605913460254669, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.027298880741000175, critic_loss: 0.4600493609905243, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.027374500408768654, critic_loss: 0.459530770778656, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.027350790798664093, critic_loss: 0.4590495526790619, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.027282677590847015, critic_loss: 0.45858675241470337, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.027259843423962593, critic_loss: 0.4581407606601715, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.02750173583626747, critic_loss: 0.45771005749702454, entropy_bonus: -22.85284423828125\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00022939093469176441, critic_loss: 0.9820303916931152, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0009648569393903017, critic_loss: 0.9792377352714539, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.0007979281363077462, critic_loss: 0.9719658493995667, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.0010910240234807134, critic_loss: 0.9570629000663757, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.0014025744749233127, critic_loss: 0.9312705993652344, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.0010637594386935234, critic_loss: 0.8992052674293518, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0012202311772853136, critic_loss: 0.8701893091201782, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.001249338616617024, critic_loss: 0.8563450574874878, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.001220331876538694, critic_loss: 0.8607158660888672, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.0011713090352714062, critic_loss: 0.8709786534309387, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.0011513272766023874, critic_loss: 0.8789300322532654, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.0011650893138721585, critic_loss: 0.8831834197044373, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0011760251363739371, critic_loss: 0.883143961429596, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.0012074607657268643, critic_loss: 0.8788657784461975, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.0012004479067400098, critic_loss: 0.8712610006332397, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.0012055744882673025, critic_loss: 0.8619319796562195, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.0012207252439111471, critic_loss: 0.8522142767906189, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.001200397964566946, critic_loss: 0.8436134457588196, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.001184156397357583, critic_loss: 0.837073802947998, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.0011630888329818845, critic_loss: 0.833090603351593, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0011478096712380648, critic_loss: 0.8309148550033569, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.0011799008352681994, critic_loss: 0.8297744989395142, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.00121197453700006, critic_loss: 0.8287721276283264, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.0012295941123738885, critic_loss: 0.826935887336731, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.0012223846279084682, critic_loss: 0.8234766721725464, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.0012174760922789574, critic_loss: 0.8181316256523132, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.0012466806219890714, critic_loss: 0.8117279410362244, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.0012543663615360856, critic_loss: 0.8059144020080566, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.001257502124644816, critic_loss: 0.8017385601997375, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.0012761678081005812, critic_loss: 0.7989910840988159, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.0013007489033043385, critic_loss: 0.797033429145813, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.001317591522820294, critic_loss: 0.7955484390258789, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.0013338013086467981, critic_loss: 0.7942206859588623, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.001346326433122158, critic_loss: 0.7926722168922424, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.001367824850603938, critic_loss: 0.7906224727630615, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.0013900574995204806, critic_loss: 0.788018524646759, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.0014012515312060714, critic_loss: 0.7850794196128845, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.001394238555803895, critic_loss: 0.7821674942970276, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.001373041421175003, critic_loss: 0.7797146439552307, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.001327303471043706, critic_loss: 0.7780570983886719, entropy_bonus: -22.381155014038086\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00884882640093565, critic_loss: 0.568517804145813, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.03218231722712517, critic_loss: 0.5666962265968323, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.03259698674082756, critic_loss: 0.5635446310043335, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.030112698674201965, critic_loss: 0.5590834617614746, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.03815460577607155, critic_loss: 0.5535209774971008, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.035778678953647614, critic_loss: 0.5466562509536743, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.036726612597703934, critic_loss: 0.5398854613304138, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.037261009216308594, critic_loss: 0.533955454826355, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.037726566195487976, critic_loss: 0.5295857191085815, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.03794214874505997, critic_loss: 0.5264317989349365, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.03802340105175972, critic_loss: 0.5240350365638733, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.03801610693335533, critic_loss: 0.522088885307312, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.03800841420888901, critic_loss: 0.5202981233596802, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.038126394152641296, critic_loss: 0.5184523463249207, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.03820888698101044, critic_loss: 0.5164953470230103, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.03823472559452057, critic_loss: 0.5144424438476562, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.038334790617227554, critic_loss: 0.5123707056045532, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.03840438649058342, critic_loss: 0.5103143453598022, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.03844168409705162, critic_loss: 0.5082884430885315, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.038457781076431274, critic_loss: 0.5063089728355408, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.03845696151256561, critic_loss: 0.5043758749961853, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.03844166919589043, critic_loss: 0.5025013089179993, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.03841462358832359, critic_loss: 0.500713050365448, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.03838153928518295, critic_loss: 0.4990333616733551, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.03835423290729523, critic_loss: 0.4974979758262634, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.0383341945707798, critic_loss: 0.49615100026130676, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.03831358253955841, critic_loss: 0.49501898884773254, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.038303885608911514, critic_loss: 0.49410125613212585, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.03830023482441902, critic_loss: 0.4933769702911377, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.03829050436615944, critic_loss: 0.4928043782711029, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.03827659413218498, critic_loss: 0.49233126640319824, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.03825945407152176, critic_loss: 0.49190834164619446, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.038240380585193634, critic_loss: 0.4914984405040741, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.038218434900045395, critic_loss: 0.49108028411865234, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.038192298263311386, critic_loss: 0.4906494617462158, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.038162410259246826, critic_loss: 0.4902135729789734, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.03813200071454048, critic_loss: 0.4897858202457428, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.03810383006930351, critic_loss: 0.4893798530101776, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.038074515759944916, critic_loss: 0.48900657892227173, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.03803717717528343, critic_loss: 0.48867109417915344, entropy_bonus: -21.95926856994629\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.015933584421873093, critic_loss: 0.6595770716667175, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.031589362770318985, critic_loss: 0.6530207991600037, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.06714057177305222, critic_loss: 0.6423912048339844, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.06438083201646805, critic_loss: 0.6288521885871887, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.06410989165306091, critic_loss: 0.6133117079734802, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.06549236923456192, critic_loss: 0.5973519086837769, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.07067416608333588, critic_loss: 0.5827834010124207, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.06797179579734802, critic_loss: 0.5711889266967773, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.06737247109413147, critic_loss: 0.5627962350845337, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.06776804476976395, critic_loss: 0.5565289855003357, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.0671597421169281, critic_loss: 0.551477313041687, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.06569498032331467, critic_loss: 0.5470139980316162, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0666760802268982, critic_loss: 0.5428764224052429, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.06683327257633209, critic_loss: 0.5386738777160645, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.0667540431022644, critic_loss: 0.5340999364852905, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.06648267805576324, critic_loss: 0.5290459990501404, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.06661760807037354, critic_loss: 0.5238122344017029, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.0671568438410759, critic_loss: 0.5189356803894043, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.06730739772319794, critic_loss: 0.5147477984428406, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.0671895444393158, critic_loss: 0.5115591287612915, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.06691642105579376, critic_loss: 0.5093982815742493, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.06712544709444046, critic_loss: 0.50816410779953, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.06709495931863785, critic_loss: 0.5078831911087036, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.06687479466199875, critic_loss: 0.5081981420516968, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.06640683114528656, critic_loss: 0.5086448788642883, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.0661686360836029, critic_loss: 0.5089411735534668, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.06618542224168777, critic_loss: 0.5089699029922485, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.06584358215332031, critic_loss: 0.5086483359336853, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.06542112678289413, critic_loss: 0.5080291628837585, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.06574979424476624, critic_loss: 0.5072187781333923, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.0696815624833107, critic_loss: 0.5064979791641235, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.06799184530973434, critic_loss: 0.5055621862411499, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.06667735427618027, critic_loss: 0.5045994520187378, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.06576869636774063, critic_loss: 0.5036159753799438, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.06635745614767075, critic_loss: 0.5026824474334717, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.0669994205236435, critic_loss: 0.5018559694290161, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.06713629513978958, critic_loss: 0.5010912418365479, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.06721466779708862, critic_loss: 0.500373125076294, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.06739025563001633, critic_loss: 0.49969902634620667, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.06739392131567001, critic_loss: 0.4990684390068054, entropy_bonus: -21.57766342163086\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.016467921435832977, critic_loss: 0.6172921061515808, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.03698712959885597, critic_loss: 0.6106018424034119, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.08520595729351044, critic_loss: 0.6025143265724182, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.06104292348027229, critic_loss: 0.5910242795944214, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.06314963847398758, critic_loss: 0.5779812932014465, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.06438521295785904, critic_loss: 0.5660524964332581, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.06486844271421432, critic_loss: 0.5570614337921143, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.0649535059928894, critic_loss: 0.5512934327125549, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.06553676724433899, critic_loss: 0.5480546355247498, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.06579043716192245, critic_loss: 0.5462658405303955, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.06578376889228821, critic_loss: 0.5448850393295288, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.06557103991508484, critic_loss: 0.5429342985153198, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.06534896045923233, critic_loss: 0.5399559736251831, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.06552144885063171, critic_loss: 0.5358068346977234, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.06553783267736435, critic_loss: 0.5307490229606628, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.06511929631233215, critic_loss: 0.5251327753067017, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.06487444043159485, critic_loss: 0.5193122029304504, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.06486395001411438, critic_loss: 0.5134844779968262, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.06453526020050049, critic_loss: 0.5076043605804443, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.06453099846839905, critic_loss: 0.5020905137062073, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.06450365483760834, critic_loss: 0.4976125955581665, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.06420192122459412, critic_loss: 0.49439460039138794, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.06417053937911987, critic_loss: 0.49311789870262146, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.06415579468011856, critic_loss: 0.49352070689201355, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.06401480734348297, critic_loss: 0.494427889585495, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.06411344558000565, critic_loss: 0.49496716260910034, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.06403700262308121, critic_loss: 0.49483945965766907, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.06422338634729385, critic_loss: 0.4941333830356598, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.06416971981525421, critic_loss: 0.4931567311286926, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.0640353411436081, critic_loss: 0.4920985996723175, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.06407976150512695, critic_loss: 0.4910459816455841, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.06405338644981384, critic_loss: 0.4900829792022705, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.0639406219124794, critic_loss: 0.4892793595790863, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.0639534592628479, critic_loss: 0.4885944128036499, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.06369155645370483, critic_loss: 0.4879198968410492, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.06383265554904938, critic_loss: 0.48725223541259766, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.06351042538881302, critic_loss: 0.486591100692749, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.06374773383140564, critic_loss: 0.4858897924423218, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.0636148452758789, critic_loss: 0.48511573672294617, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.06355272233486176, critic_loss: 0.4842873215675354, entropy_bonus: -21.22931480407715\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.012994715943932533, critic_loss: 0.597577691078186, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.01927906647324562, critic_loss: 0.5960913896560669, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.0684446394443512, critic_loss: 0.591957688331604, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.056737106293439865, critic_loss: 0.5880337953567505, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.051062922924757004, critic_loss: 0.5825405716896057, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.05192457512021065, critic_loss: 0.5757105350494385, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.05338554456830025, critic_loss: 0.5676894783973694, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.05372841656208038, critic_loss: 0.5588979125022888, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.05344720184803009, critic_loss: 0.5500612258911133, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.05270998924970627, critic_loss: 0.541842520236969, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.05192068964242935, critic_loss: 0.534833550453186, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.05122954770922661, critic_loss: 0.5291628837585449, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.050737299025058746, critic_loss: 0.5246845483779907, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.05050971359014511, critic_loss: 0.5210127830505371, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.05073198676109314, critic_loss: 0.5175857543945312, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.05091530457139015, critic_loss: 0.5140330791473389, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.05077261105179787, critic_loss: 0.5104587078094482, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.05036460980772972, critic_loss: 0.5071917772293091, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.05000395327806473, critic_loss: 0.5044007301330566, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.0500771589577198, critic_loss: 0.5022163987159729, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.05016854405403137, critic_loss: 0.5008431673049927, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.050189852714538574, critic_loss: 0.5003753900527954, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.050092753022909164, critic_loss: 0.500503659248352, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.05012713000178337, critic_loss: 0.5007697343826294, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.049744054675102234, critic_loss: 0.5007480978965759, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.04945443570613861, critic_loss: 0.5003976821899414, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.04966771602630615, critic_loss: 0.4997096061706543, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.05012775957584381, critic_loss: 0.4988159239292145, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.05034119635820389, critic_loss: 0.49779030680656433, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.0499303825199604, critic_loss: 0.49670666456222534, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.04943691939115524, critic_loss: 0.4956018626689911, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.04921363294124603, critic_loss: 0.49446389079093933, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.04904024302959442, critic_loss: 0.4933457672595978, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.048935674130916595, critic_loss: 0.49230775237083435, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.04882006719708443, critic_loss: 0.4913879632949829, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.04863543063402176, critic_loss: 0.4906035363674164, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.048402007669210434, critic_loss: 0.4899437427520752, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.048228710889816284, critic_loss: 0.4893820285797119, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.04820026829838753, critic_loss: 0.4888853430747986, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.04812901094555855, critic_loss: 0.48842331767082214, entropy_bonus: -20.90888786315918\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.015538010746240616, critic_loss: 0.6139257550239563, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.018497716635465622, critic_loss: 0.61102694272995, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.04387984052300453, critic_loss: 0.6049063801765442, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.038363710045814514, critic_loss: 0.5954267382621765, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.05271338298916817, critic_loss: 0.5856769680976868, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.053964316844940186, critic_loss: 0.5741751194000244, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.049711283296346664, critic_loss: 0.5627023577690125, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.04871899262070656, critic_loss: 0.5517551898956299, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.04975282773375511, critic_loss: 0.5414799451828003, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.049553487449884415, critic_loss: 0.5318687558174133, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.04856327176094055, critic_loss: 0.5230036377906799, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.0489489883184433, critic_loss: 0.5145971775054932, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.050214994698762894, critic_loss: 0.5067532658576965, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.05131734162569046, critic_loss: 0.49953556060791016, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.051601674407720566, critic_loss: 0.4932462275028229, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.05106709524989128, critic_loss: 0.4883650839328766, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.05048311874270439, critic_loss: 0.48503854870796204, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.050993021577596664, critic_loss: 0.48311692476272583, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.050973858684301376, critic_loss: 0.48252829909324646, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.05056149512529373, critic_loss: 0.4829365611076355, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.05025996267795563, critic_loss: 0.48371535539627075, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.05000732094049454, critic_loss: 0.48437780141830444, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.04961273819208145, critic_loss: 0.48470064997673035, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.049050990492105484, critic_loss: 0.4846302568912506, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.048504672944545746, critic_loss: 0.48419615626335144, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.047694671899080276, critic_loss: 0.4834648072719574, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.04680539295077324, critic_loss: 0.48253631591796875, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.04586038738489151, critic_loss: 0.4815439283847809, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.04588141292333603, critic_loss: 0.4806616008281708, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.04450618475675583, critic_loss: 0.47998499870300293, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.04479396715760231, critic_loss: 0.47960397601127625, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.04453339800238609, critic_loss: 0.47946488857269287, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.044045206159353256, critic_loss: 0.47939515113830566, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.04370323196053505, critic_loss: 0.4792352616786957, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.04326656460762024, critic_loss: 0.4788907468318939, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.04252082481980324, critic_loss: 0.4783720076084137, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.04182811453938484, critic_loss: 0.4777252674102783, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.041744545102119446, critic_loss: 0.47701549530029297, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.04197936877608299, critic_loss: 0.4762706458568573, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.04136223718523979, critic_loss: 0.475570946931839, entropy_bonus: -20.61223602294922\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00850746501237154, critic_loss: 0.5845297574996948, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.02769007533788681, critic_loss: 0.580755889415741, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.034123074263334274, critic_loss: 0.5725001096725464, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.042063720524311066, critic_loss: 0.5610787868499756, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.04387398436665535, critic_loss: 0.5478070378303528, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.04545779526233673, critic_loss: 0.5338349342346191, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.04681652411818504, critic_loss: 0.5208005309104919, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.047655798494815826, critic_loss: 0.5094780921936035, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.04814886674284935, critic_loss: 0.49973064661026, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.048448555171489716, critic_loss: 0.4911087453365326, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.04864627122879028, critic_loss: 0.48326775431632996, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.04875924810767174, critic_loss: 0.4762319028377533, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.048805952072143555, critic_loss: 0.47016504406929016, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.0488002710044384, critic_loss: 0.4650958776473999, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.04876987263560295, critic_loss: 0.460824579000473, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.04875929653644562, critic_loss: 0.4571813642978668, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.04875069484114647, critic_loss: 0.45420825481414795, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.04872569814324379, critic_loss: 0.4520184397697449, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.04867687076330185, critic_loss: 0.45061519742012024, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.04863280802965164, critic_loss: 0.44985684752464294, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.048567112535238266, critic_loss: 0.4495289921760559, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.04848167300224304, critic_loss: 0.4494170546531677, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.048370201140642166, critic_loss: 0.44935065507888794, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.0482277013361454, critic_loss: 0.44920265674591064, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.04805297777056694, critic_loss: 0.44891756772994995, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.047850362956523895, critic_loss: 0.44849634170532227, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.04762046039104462, critic_loss: 0.4479866921901703, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.047361038625240326, critic_loss: 0.4474588632583618, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.047080982476472855, critic_loss: 0.44697311520576477, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.046779997646808624, critic_loss: 0.44656866788864136, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.04648016765713692, critic_loss: 0.4462515115737915, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.046163998544216156, critic_loss: 0.44600608944892883, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.04575376957654953, critic_loss: 0.4458000659942627, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.04519651457667351, critic_loss: 0.44559693336486816, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.04447169974446297, critic_loss: 0.4453624486923218, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.04423334449529648, critic_loss: 0.4450685977935791, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.044225260615348816, critic_loss: 0.4447385370731354, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.04412740096449852, critic_loss: 0.44437375664711, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.043940220028162, critic_loss: 0.4439825415611267, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.043658725917339325, critic_loss: 0.44357338547706604, entropy_bonus: -20.33607292175293\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00708382111042738, critic_loss: 0.5594013929367065, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.010431241244077682, critic_loss: 0.5579637885093689, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.02736758440732956, critic_loss: 0.5541988015174866, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.02717357501387596, critic_loss: 0.5491677522659302, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.02908213622868061, critic_loss: 0.5429903268814087, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.027656257152557373, critic_loss: 0.535699188709259, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.02988114394247532, critic_loss: 0.5276750326156616, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.029405798763036728, critic_loss: 0.5192846059799194, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.029149439185857773, critic_loss: 0.5107851028442383, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.02915332280099392, critic_loss: 0.5022571682929993, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.029119929298758507, critic_loss: 0.4939664304256439, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.029584897682070732, critic_loss: 0.48622947931289673, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.02927492931485176, critic_loss: 0.47922787070274353, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.029500383883714676, critic_loss: 0.47303593158721924, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.02899988926947117, critic_loss: 0.4677359163761139, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.02994244545698166, critic_loss: 0.4632584750652313, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.029893621802330017, critic_loss: 0.45956140756607056, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.02902088314294815, critic_loss: 0.45651975274086, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.029032934457063675, critic_loss: 0.4540335536003113, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.028001876547932625, critic_loss: 0.4519127905368805, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.02841404639184475, critic_loss: 0.4501306116580963, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.028266187757253647, critic_loss: 0.4486076235771179, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.027897655963897705, critic_loss: 0.44730421900749207, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.028129136189818382, critic_loss: 0.4461585283279419, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.02781931683421135, critic_loss: 0.4451620876789093, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.02788900025188923, critic_loss: 0.44430723786354065, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.02787821739912033, critic_loss: 0.4436121881008148, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.027356209233403206, critic_loss: 0.4430530369281769, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.027443116530776024, critic_loss: 0.4426044225692749, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.026786109432578087, critic_loss: 0.44223010540008545, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.027112212032079697, critic_loss: 0.441914826631546, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.02700968086719513, critic_loss: 0.44165441393852234, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.026639500632882118, critic_loss: 0.4414372146129608, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.026278788223862648, critic_loss: 0.4412502944469452, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.02610921487212181, critic_loss: 0.4410722553730011, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.025862907990813255, critic_loss: 0.44090208411216736, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.02575470320880413, critic_loss: 0.44073358178138733, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.025768158957362175, critic_loss: 0.4405738115310669, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.026149334385991096, critic_loss: 0.4404295086860657, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.026380198076367378, critic_loss: 0.4402807056903839, entropy_bonus: -20.0777530670166\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.006640588399022818, critic_loss: 0.5449806451797485, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0076174549758434296, critic_loss: 0.5435080528259277, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.015945443883538246, critic_loss: 0.5410752296447754, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.016485076397657394, critic_loss: 0.5379565358161926, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.01590239442884922, critic_loss: 0.5342749357223511, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.019951218739151955, critic_loss: 0.5301963686943054, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.016756119206547737, critic_loss: 0.5258136987686157, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.01582496054470539, critic_loss: 0.5212701559066772, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.018201321363449097, critic_loss: 0.5167279243469238, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.025292053818702698, critic_loss: 0.5121958255767822, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.020284106954932213, critic_loss: 0.5077027082443237, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.02181859500706196, critic_loss: 0.5033649802207947, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.023807287216186523, critic_loss: 0.49919775128364563, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.02084205485880375, critic_loss: 0.4952419400215149, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.018468905240297318, critic_loss: 0.4915713667869568, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.01937989890575409, critic_loss: 0.4881918728351593, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.019428400322794914, critic_loss: 0.4850548207759857, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.018531693145632744, critic_loss: 0.4821067750453949, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.016218412667512894, critic_loss: 0.4792376458644867, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.01656581088900566, critic_loss: 0.476350873708725, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.016642890870571136, critic_loss: 0.473403662443161, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.016112323850393295, critic_loss: 0.4703840911388397, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.01632283627986908, critic_loss: 0.4673137962818146, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.01661459542810917, critic_loss: 0.46424776315689087, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.016660816967487335, critic_loss: 0.46134114265441895, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.016339655965566635, critic_loss: 0.45877671241760254, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.01605912297964096, critic_loss: 0.4566406011581421, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.015887944027781487, critic_loss: 0.4549398720264435, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.015229886397719383, critic_loss: 0.4536117613315582, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.015084708109498024, critic_loss: 0.4526020884513855, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.015529944561421871, critic_loss: 0.4518343210220337, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.015139054507017136, critic_loss: 0.4512462019920349, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.015381020493805408, critic_loss: 0.4507688581943512, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.014987938106060028, critic_loss: 0.45035603642463684, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.014767259359359741, critic_loss: 0.4499721825122833, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.014050199650228024, critic_loss: 0.4496000409126282, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.014274747110903263, critic_loss: 0.44922056794166565, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.013096770271658897, critic_loss: 0.44882965087890625, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.01535795908421278, critic_loss: 0.4484497606754303, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.013007216155529022, critic_loss: 0.4480700194835663, entropy_bonus: -19.835107803344727\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.011540045030415058, critic_loss: 0.5235357880592346, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.017187941819429398, critic_loss: 0.5220611691474915, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.01832723058760166, critic_loss: 0.5194269418716431, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.01674208790063858, critic_loss: 0.5158161520957947, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.01760452426970005, critic_loss: 0.5112350583076477, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.020336953923106194, critic_loss: 0.5057455897331238, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.018419833853840828, critic_loss: 0.49944305419921875, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.016922852024435997, critic_loss: 0.4925955533981323, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.01991342566907406, critic_loss: 0.48552989959716797, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.021075531840324402, critic_loss: 0.4787760078907013, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.021421024575829506, critic_loss: 0.4727078676223755, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.020936857908964157, critic_loss: 0.46748772263526917, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.01960211992263794, critic_loss: 0.4631021320819855, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.017450667917728424, critic_loss: 0.45938655734062195, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.01994379609823227, critic_loss: 0.4561537802219391, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.021802591159939766, critic_loss: 0.45327866077423096, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.022313155233860016, critic_loss: 0.4507383108139038, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.022526198998093605, critic_loss: 0.44851699471473694, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.022641317918896675, critic_loss: 0.44664186239242554, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.022537488490343094, critic_loss: 0.445113867521286, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.022322967648506165, critic_loss: 0.4439088702201843, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.021938972175121307, critic_loss: 0.4429686665534973, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.02110285498201847, critic_loss: 0.44223371148109436, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.020426344126462936, critic_loss: 0.4416511356830597, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.019933966919779778, critic_loss: 0.44119518995285034, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.018962133675813675, critic_loss: 0.4408375918865204, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.017308998852968216, critic_loss: 0.44055357575416565, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.016834761947393417, critic_loss: 0.4403124451637268, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.019615432247519493, critic_loss: 0.4400857985019684, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.01985432393848896, critic_loss: 0.43987366557121277, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.01997103914618492, critic_loss: 0.4396933615207672, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.01726958341896534, critic_loss: 0.439546138048172, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.017596371471881866, critic_loss: 0.43942204117774963, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.01961047388613224, critic_loss: 0.4393025040626526, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.019253451377153397, critic_loss: 0.4391831159591675, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.02150273323059082, critic_loss: 0.4390788674354553, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.02015511505305767, critic_loss: 0.43898868560791016, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.019469935446977615, critic_loss: 0.4389079213142395, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.020492002367973328, critic_loss: 0.43882647156715393, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.017360925674438477, critic_loss: 0.43873846530914307, entropy_bonus: -19.606342315673828\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007720251102000475, critic_loss: 0.5377790331840515, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.014941021800041199, critic_loss: 0.5359189510345459, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.011329787783324718, critic_loss: 0.5328766703605652, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.013077683746814728, critic_loss: 0.5288017392158508, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.011458519846200943, critic_loss: 0.5237565040588379, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.0106706777587533, critic_loss: 0.5179340839385986, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.011610970832407475, critic_loss: 0.5117287635803223, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.010336617939174175, critic_loss: 0.5053405165672302, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.01159927062690258, critic_loss: 0.4989226758480072, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.012010038830339909, critic_loss: 0.4926597774028778, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.01095988042652607, critic_loss: 0.48673272132873535, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.011318691074848175, critic_loss: 0.4811784625053406, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.011798245832324028, critic_loss: 0.4759068787097931, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.011363363824784756, critic_loss: 0.47081345319747925, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.010914959944784641, critic_loss: 0.4658142328262329, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.011500777676701546, critic_loss: 0.4608878195285797, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.01089017279446125, critic_loss: 0.45606958866119385, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.010776958428323269, critic_loss: 0.4514520466327667, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.0119511429220438, critic_loss: 0.44714799523353577, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.010561521165072918, critic_loss: 0.44320085644721985, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.011435877531766891, critic_loss: 0.43957972526550293, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.01096191443502903, critic_loss: 0.43637290596961975, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.010596967302262783, critic_loss: 0.43374115228652954, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.010847263969480991, critic_loss: 0.43180668354034424, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.01081054750829935, critic_loss: 0.43052756786346436, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.010255968198180199, critic_loss: 0.42973318696022034, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.0114281689748168, critic_loss: 0.4292372465133667, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.011260421015322208, critic_loss: 0.42890411615371704, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.010790168307721615, critic_loss: 0.42864832282066345, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.010670384392142296, critic_loss: 0.428436815738678, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.010429928079247475, critic_loss: 0.42825955152511597, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.010279286652803421, critic_loss: 0.4281167685985565, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.010234267450869083, critic_loss: 0.4280070662498474, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.009990621358156204, critic_loss: 0.4279293119907379, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.011353799141943455, critic_loss: 0.4278782904148102, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.010049914941191673, critic_loss: 0.427839070558548, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.010664544999599457, critic_loss: 0.4278110861778259, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.01021044421941042, critic_loss: 0.4277915358543396, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.009968138299882412, critic_loss: 0.4277663230895996, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.010047598741948605, critic_loss: 0.4277433156967163, entropy_bonus: -19.389957427978516\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.011431366205215454, critic_loss: 0.5837449431419373, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.013468792662024498, critic_loss: 0.5806354284286499, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.020387960597872734, critic_loss: 0.5753695964813232, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.01709744893014431, critic_loss: 0.5689922571182251, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.01381540298461914, critic_loss: 0.561883270740509, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.017081089317798615, critic_loss: 0.5539619326591492, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.017995495349168777, critic_loss: 0.5452107787132263, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.015509570948779583, critic_loss: 0.5359975695610046, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.01803412102162838, critic_loss: 0.5267526507377625, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.01684972085058689, critic_loss: 0.5177786350250244, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.015428632497787476, critic_loss: 0.5093472599983215, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.016665492206811905, critic_loss: 0.5017043948173523, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.01609881967306137, critic_loss: 0.4948568344116211, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.016644896939396858, critic_loss: 0.48879796266555786, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.015714840963482857, critic_loss: 0.4833768904209137, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.015490194782614708, critic_loss: 0.47850745916366577, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.017331916838884354, critic_loss: 0.4742450416088104, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.014682741835713387, critic_loss: 0.4703051745891571, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.015918051823973656, critic_loss: 0.466808944940567, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.016417978331446648, critic_loss: 0.4638451635837555, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.014392722398042679, critic_loss: 0.46124374866485596, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.01853181980550289, critic_loss: 0.4589947760105133, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.015646742656826973, critic_loss: 0.45731034874916077, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.014956170693039894, critic_loss: 0.4559897184371948, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.01669996604323387, critic_loss: 0.4549490213394165, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.014546364545822144, critic_loss: 0.4542319178581238, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.01548986230045557, critic_loss: 0.4536891579627991, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.015625005587935448, critic_loss: 0.453330397605896, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.01524172630161047, critic_loss: 0.45310091972351074, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.015854528173804283, critic_loss: 0.4529894292354584, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.014494867995381355, critic_loss: 0.4529421925544739, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.014654803089797497, critic_loss: 0.4529460370540619, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.015125885605812073, critic_loss: 0.4529615640640259, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.014382189139723778, critic_loss: 0.45297181606292725, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.014722020365297794, critic_loss: 0.4529667794704437, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.014702939428389072, critic_loss: 0.45292410254478455, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.014590853825211525, critic_loss: 0.45285335183143616, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.01486964337527752, critic_loss: 0.4527123272418976, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.01355942152440548, critic_loss: 0.45252200961112976, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.014825950376689434, critic_loss: 0.4523160755634308, entropy_bonus: -19.18467903137207\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.020044321194291115, critic_loss: 0.7592408061027527, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.03598269820213318, critic_loss: 0.7506373524665833, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.08370863646268845, critic_loss: 0.7371119260787964, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.051450613886117935, critic_loss: 0.7189481258392334, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.059537000954151154, critic_loss: 0.6977859735488892, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.0618775449693203, critic_loss: 0.676104724407196, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.05651767924427986, critic_loss: 0.6564677357673645, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.058437976986169815, critic_loss: 0.6401577591896057, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.059280168265104294, critic_loss: 0.6271468997001648, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.05980294942855835, critic_loss: 0.6166124939918518, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.05953432247042656, critic_loss: 0.6082053780555725, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.059004053473472595, critic_loss: 0.6016013622283936, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.05877184122800827, critic_loss: 0.5966366529464722, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.05831826850771904, critic_loss: 0.5929135084152222, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.0578438974916935, critic_loss: 0.5899026393890381, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.057858675718307495, critic_loss: 0.5873182415962219, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.05783785879611969, critic_loss: 0.5849317312240601, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.05717748403549194, critic_loss: 0.5824893116950989, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.05711621418595314, critic_loss: 0.5797985196113586, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.05698723718523979, critic_loss: 0.5768691301345825, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.056816015392541885, critic_loss: 0.5738633871078491, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.056535009294748306, critic_loss: 0.5710237622261047, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.05624997615814209, critic_loss: 0.5685755610466003, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.05604559928178787, critic_loss: 0.5666119456291199, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.05585131049156189, critic_loss: 0.5651044845581055, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.055671483278274536, critic_loss: 0.5639985799789429, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.055304307490587234, critic_loss: 0.5632702708244324, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.05485490709543228, critic_loss: 0.562913715839386, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.054575443267822266, critic_loss: 0.5628837943077087, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.05397794768214226, critic_loss: 0.5630828738212585, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.05415498465299606, critic_loss: 0.5633878707885742, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.05373646691441536, critic_loss: 0.5637035965919495, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.05332474038004875, critic_loss: 0.563949465751648, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.052963986992836, critic_loss: 0.5640561580657959, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.05294672027230263, critic_loss: 0.5639967322349548, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.05273541435599327, critic_loss: 0.5637632012367249, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.05237724632024765, critic_loss: 0.563371479511261, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.05253804475069046, critic_loss: 0.5628456473350525, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.052786584943532944, critic_loss: 0.5622127056121826, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.052280232310295105, critic_loss: 0.5615168213844299, entropy_bonus: -18.989421844482422\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.010017480701208115, critic_loss: 0.5435519814491272, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.012394391000270844, critic_loss: 0.5428438782691956, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.024962550029158592, critic_loss: 0.5411249995231628, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.027970777824521065, critic_loss: 0.5380216836929321, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.02795019932091236, critic_loss: 0.5337483882904053, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.027260061353445053, critic_loss: 0.5284786224365234, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.026834623888134956, critic_loss: 0.5223439335823059, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.026450220495462418, critic_loss: 0.5155698657035828, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.0255076065659523, critic_loss: 0.5084730386734009, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.024579310789704323, critic_loss: 0.5014458298683167, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.024602629244327545, critic_loss: 0.49481281638145447, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.025732828304171562, critic_loss: 0.48869994282722473, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.02587592601776123, critic_loss: 0.48300427198410034, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.025274110957980156, critic_loss: 0.477539598941803, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.024349911138415337, critic_loss: 0.472212553024292, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.023829255253076553, critic_loss: 0.4670409858226776, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.023743513971567154, critic_loss: 0.4621633291244507, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.023676393553614616, critic_loss: 0.4577588737010956, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.023464228957891464, critic_loss: 0.4539424479007721, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.023288965225219727, critic_loss: 0.4507327675819397, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.023385532200336456, critic_loss: 0.4481525123119354, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.02307868003845215, critic_loss: 0.44621485471725464, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.022370798513293266, critic_loss: 0.4448734521865845, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.022504614666104317, critic_loss: 0.44404274225234985, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.022640429437160492, critic_loss: 0.44361642003059387, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.022477326914668083, critic_loss: 0.4434788227081299, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.022030573338270187, critic_loss: 0.44351962208747864, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.021929854527115822, critic_loss: 0.44366002082824707, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.021943943575024605, critic_loss: 0.4438381493091583, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.021822800859808922, critic_loss: 0.4440096914768219, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.021413234993815422, critic_loss: 0.44414860010147095, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.021067732945084572, critic_loss: 0.44424307346343994, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.021133681759238243, critic_loss: 0.4442947804927826, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.02102247253060341, critic_loss: 0.4443163573741913, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.02101772278547287, critic_loss: 0.4443095624446869, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.0207750853151083, critic_loss: 0.4442756772041321, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.02057572454214096, critic_loss: 0.4442277252674103, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.020457398146390915, critic_loss: 0.444172203540802, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.020314980298280716, critic_loss: 0.4441114366054535, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.020162511616945267, critic_loss: 0.4440416693687439, entropy_bonus: -18.803255081176758\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.01482461765408516, critic_loss: 0.7094911932945251, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.024059079587459564, critic_loss: 0.7039571404457092, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.05163181945681572, critic_loss: 0.6967496275901794, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.054198212921619415, critic_loss: 0.686105489730835, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.05555551126599312, critic_loss: 0.6730523109436035, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.05621171370148659, critic_loss: 0.6588534116744995, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.05653338506817818, critic_loss: 0.6445980072021484, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.056772973388433456, critic_loss: 0.6309872269630432, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.05687570571899414, critic_loss: 0.6187266707420349, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.05689733102917671, critic_loss: 0.6083534359931946, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.05687984079122543, critic_loss: 0.5999760627746582, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.05685656890273094, critic_loss: 0.593359649181366, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0568578764796257, critic_loss: 0.5882089734077454, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.0568772628903389, critic_loss: 0.5841608643531799, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.056945256888866425, critic_loss: 0.5808171629905701, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.05695815756917, critic_loss: 0.577820897102356, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.05693456158041954, critic_loss: 0.5749390125274658, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.05692024901509285, critic_loss: 0.5720088481903076, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.056888025254011154, critic_loss: 0.5689658522605896, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.056834541261196136, critic_loss: 0.5657734870910645, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.05672710761427879, critic_loss: 0.5626623034477234, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.05668482184410095, critic_loss: 0.559917688369751, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.05668644607067108, critic_loss: 0.557741105556488, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.056667689234018326, critic_loss: 0.556190013885498, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.05661597475409508, critic_loss: 0.5551530718803406, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.056539349257946014, critic_loss: 0.5544742345809937, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.05645553767681122, critic_loss: 0.5540301203727722, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.05642244592308998, critic_loss: 0.553739607334137, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.056387145072221756, critic_loss: 0.5535615682601929, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.056342896074056625, critic_loss: 0.5534781217575073, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.05628933385014534, critic_loss: 0.5534588098526001, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.056250061839818954, critic_loss: 0.5534960031509399, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.056216124445199966, critic_loss: 0.5535646677017212, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.05619429051876068, critic_loss: 0.5536242127418518, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.05616122856736183, critic_loss: 0.5536414980888367, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.05611630901694298, critic_loss: 0.5535964965820312, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.05606640502810478, critic_loss: 0.553476095199585, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.05603277310729027, critic_loss: 0.5532754063606262, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.05600927025079727, critic_loss: 0.5529987215995789, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.05599230155348778, critic_loss: 0.5526565909385681, entropy_bonus: -18.625370025634766\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.015895498916506767, critic_loss: 0.5680354833602905, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.015884922817349434, critic_loss: 0.5666501522064209, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.015882812440395355, critic_loss: 0.5637449622154236, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.0159060750156641, critic_loss: 0.5594854950904846, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.015923285856842995, critic_loss: 0.5541046857833862, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.015929166227579117, critic_loss: 0.5478271842002869, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.015940241515636444, critic_loss: 0.5408611297607422, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.015907661989331245, critic_loss: 0.5334235429763794, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.015937430784106255, critic_loss: 0.5257009863853455, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.015960082411766052, critic_loss: 0.5179224014282227, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.015960222110152245, critic_loss: 0.5102924108505249, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.016000621020793915, critic_loss: 0.5029953122138977, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.016091151162981987, critic_loss: 0.4961800277233124, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.01613173447549343, critic_loss: 0.48995867371559143, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.016198284924030304, critic_loss: 0.48442065715789795, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.016226595267653465, critic_loss: 0.47950974106788635, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.0161964762955904, critic_loss: 0.4752920866012573, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.01637193001806736, critic_loss: 0.47175735235214233, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.016655208542943, critic_loss: 0.4688854217529297, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.01624131016433239, critic_loss: 0.46662279963493347, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.016609782353043556, critic_loss: 0.4648999869823456, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.016959473490715027, critic_loss: 0.4636407494544983, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.01627778634428978, critic_loss: 0.4627862572669983, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.016953324899077415, critic_loss: 0.46223556995391846, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.0165984146296978, critic_loss: 0.4619000256061554, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.01639946736395359, critic_loss: 0.4617317318916321, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.016908004879951477, critic_loss: 0.46166250109672546, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.016438066959381104, critic_loss: 0.4616318941116333, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.016368580982089043, critic_loss: 0.46163076162338257, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.016487063840031624, critic_loss: 0.46162647008895874, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.01658792234957218, critic_loss: 0.4615914225578308, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.01648031733930111, critic_loss: 0.461526483297348, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.016368702054023743, critic_loss: 0.46141138672828674, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.01633034646511078, critic_loss: 0.4612552523612976, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.016284314915537834, critic_loss: 0.4610491096973419, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.016260672360658646, critic_loss: 0.4607982635498047, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.016244448721408844, critic_loss: 0.4605075716972351, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.016235824674367905, critic_loss: 0.460184246301651, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.01621795818209648, critic_loss: 0.45983409881591797, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.016211669892072678, critic_loss: 0.4594665467739105, entropy_bonus: -18.455059051513672\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.005510933697223663, critic_loss: 0.592017650604248, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0055146897211670876, critic_loss: 0.5911032557487488, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.005545851308852434, critic_loss: 0.5889280438423157, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.005523607134819031, critic_loss: 0.5857082009315491, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.005511892028152943, critic_loss: 0.5816653370857239, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.005524803418666124, critic_loss: 0.5769996047019958, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0055548278614878654, critic_loss: 0.5719645619392395, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.005540687590837479, critic_loss: 0.5667629241943359, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.005556534975767136, critic_loss: 0.5615467429161072, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.005592850968241692, critic_loss: 0.5564244389533997, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.00558823999017477, critic_loss: 0.5514001250267029, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.005587603896856308, critic_loss: 0.5464795827865601, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.005640340968966484, critic_loss: 0.5417037606239319, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.005680245812982321, critic_loss: 0.537154495716095, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.005695478990674019, critic_loss: 0.5329590439796448, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.005753965582698584, critic_loss: 0.5292842388153076, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.005774864461272955, critic_loss: 0.52629154920578, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.005805035121738911, critic_loss: 0.5240399241447449, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.005849776789546013, critic_loss: 0.5223625302314758, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00586321298032999, critic_loss: 0.5210127830505371, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.005899075418710709, critic_loss: 0.5198057293891907, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.005900534801185131, critic_loss: 0.5186387300491333, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.005913045722991228, critic_loss: 0.517484724521637, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.005924044642597437, critic_loss: 0.5163401365280151, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.005900304764509201, critic_loss: 0.5151863098144531, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.005929281003773212, critic_loss: 0.5139728784561157, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.0059084901586174965, critic_loss: 0.5126575231552124, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.00589777622371912, critic_loss: 0.5112667679786682, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.005895716138184071, critic_loss: 0.5099018216133118, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.005874865222722292, critic_loss: 0.5086726546287537, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.005879939999431372, critic_loss: 0.5076148509979248, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.005856441333889961, critic_loss: 0.5066732168197632, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.00585626857355237, critic_loss: 0.5057634115219116, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.005835630465298891, critic_loss: 0.5048354268074036, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.0058502936735749245, critic_loss: 0.5038780570030212, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.005842693615704775, critic_loss: 0.5029116868972778, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.005826090462505817, critic_loss: 0.5019783973693848, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.005831436719745398, critic_loss: 0.5011078715324402, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.005811645649373531, critic_loss: 0.5003179907798767, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.005824043415486813, critic_loss: 0.4996054172515869, entropy_bonus: -18.291704177856445\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00808798149228096, critic_loss: 0.5761188268661499, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008088238537311554, critic_loss: 0.5724650621414185, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008086837828159332, critic_loss: 0.567484974861145, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008107369765639305, critic_loss: 0.5615906119346619, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008174534887075424, critic_loss: 0.5552181005477905, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.00822213664650917, critic_loss: 0.5487353801727295, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008457339368760586, critic_loss: 0.5424336791038513, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008366391994059086, critic_loss: 0.5365539789199829, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008875707164406776, critic_loss: 0.5311440825462341, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008845294825732708, critic_loss: 0.5261484384536743, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.009120742790400982, critic_loss: 0.52140212059021, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008816343732178211, critic_loss: 0.5169229507446289, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008780017495155334, critic_loss: 0.512739896774292, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.009273731149733067, critic_loss: 0.5088210105895996, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008807317353785038, critic_loss: 0.5050310492515564, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.009269668720662594, critic_loss: 0.5009708404541016, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.009307630360126495, critic_loss: 0.4961877167224884, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008987109176814556, critic_loss: 0.4904021918773651, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008986023254692554, critic_loss: 0.4839686155319214, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.009317531250417233, critic_loss: 0.4778372049331665, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.009111830033361912, critic_loss: 0.47286009788513184, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.00899538118392229, critic_loss: 0.4690622389316559, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.00929702166467905, critic_loss: 0.465655118227005, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.009254036471247673, critic_loss: 0.4620532691478729, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008988535031676292, critic_loss: 0.4581752121448517, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.009272551164031029, critic_loss: 0.45451849699020386, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.009103478863835335, critic_loss: 0.45190224051475525, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.00905947107821703, critic_loss: 0.4502790868282318, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.009233333170413971, critic_loss: 0.44930943846702576, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00909943226724863, critic_loss: 0.44877922534942627, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008973165415227413, critic_loss: 0.44859078526496887, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.00907073076814413, critic_loss: 0.44858917593955994, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.009160642512142658, critic_loss: 0.4486334025859833, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.009316216222941875, critic_loss: 0.4486387073993683, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.00898947473615408, critic_loss: 0.4485952854156494, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.00891503132879734, critic_loss: 0.4485242962837219, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.009298281744122505, critic_loss: 0.44843101501464844, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008967703208327293, critic_loss: 0.44829100370407104, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.009493864141404629, critic_loss: 0.4481227993965149, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.00946981180459261, critic_loss: 0.4479272663593292, entropy_bonus: -18.1347599029541\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.010229550302028656, critic_loss: 0.6404266357421875, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.010431328788399696, critic_loss: 0.6341238021850586, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.010396340861916542, critic_loss: 0.6240927577018738, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.010297021828591824, critic_loss: 0.610772967338562, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.010491881519556046, critic_loss: 0.5946816802024841, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.010453540831804276, critic_loss: 0.5768560171127319, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.010393894277513027, critic_loss: 0.5594605803489685, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.010579260997474194, critic_loss: 0.5432524681091309, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.010494295507669449, critic_loss: 0.5266848206520081, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.01048087328672409, critic_loss: 0.5109617114067078, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.010627436451613903, critic_loss: 0.49892884492874146, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.010646563023328781, critic_loss: 0.4915003180503845, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.010671553201973438, critic_loss: 0.48655182123184204, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.010841739363968372, critic_loss: 0.4827497601509094, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.01082865335047245, critic_loss: 0.4799588918685913, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.010850301943719387, critic_loss: 0.4782184362411499, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.010831604711711407, critic_loss: 0.47721603512763977, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.010752574540674686, critic_loss: 0.4765564203262329, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.010770490393042564, critic_loss: 0.47601625323295593, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.01074365433305502, critic_loss: 0.47546088695526123, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.01071159914135933, critic_loss: 0.4748865067958832, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.010711277835071087, critic_loss: 0.4743501842021942, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.010697520337998867, critic_loss: 0.4738967716693878, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.010675824247300625, critic_loss: 0.4735133647918701, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.01071188785135746, critic_loss: 0.4731774926185608, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.010697944089770317, critic_loss: 0.47289198637008667, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.010675492696464062, critic_loss: 0.4726811945438385, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.010655347257852554, critic_loss: 0.4725552201271057, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.010636471211910248, critic_loss: 0.47251012921333313, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.010630141943693161, critic_loss: 0.4725217819213867, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.010584521107375622, critic_loss: 0.47255492210388184, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.010573478415608406, critic_loss: 0.4725688695907593, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.010554573498666286, critic_loss: 0.4725307822227478, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.010522561147809029, critic_loss: 0.4724280834197998, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.01049902755767107, critic_loss: 0.4722523093223572, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.010497861541807652, critic_loss: 0.47200897336006165, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.010468012653291225, critic_loss: 0.47171464562416077, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.010449414141476154, critic_loss: 0.47138822078704834, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.010422571562230587, critic_loss: 0.471056193113327, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.010424520820379257, critic_loss: 0.47073599696159363, entropy_bonus: -17.983741760253906\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.004345856606960297, critic_loss: 0.6342503428459167, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0044323778711259365, critic_loss: 0.627159833908081, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.004659127909690142, critic_loss: 0.6146416664123535, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.004740178119391203, critic_loss: 0.5976277589797974, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.00457007996737957, critic_loss: 0.5815065503120422, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.004896547645330429, critic_loss: 0.5693220496177673, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.00537060247734189, critic_loss: 0.5589604377746582, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.004966245498508215, critic_loss: 0.549514889717102, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.006138371769338846, critic_loss: 0.5421115756034851, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.004867753479629755, critic_loss: 0.5372145771980286, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.006153223570436239, critic_loss: 0.5336747169494629, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.005595277063548565, critic_loss: 0.529779851436615, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0058906166814267635, critic_loss: 0.5246718525886536, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.00558027159422636, critic_loss: 0.5185661315917969, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.005966298282146454, critic_loss: 0.5119237303733826, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.006233999039977789, critic_loss: 0.5054143667221069, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.005136117339134216, critic_loss: 0.4998219609260559, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.005959741771221161, critic_loss: 0.4954630732536316, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.005187903996556997, critic_loss: 0.4922848045825958, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.005528254900127649, critic_loss: 0.49029669165611267, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.005001612938940525, critic_loss: 0.48936209082603455, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.00566253112629056, critic_loss: 0.4891291856765747, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.004905557259917259, critic_loss: 0.4892328977584839, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.005186184775084257, critic_loss: 0.48941120505332947, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.004919838160276413, critic_loss: 0.4895062744617462, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.004791287239640951, critic_loss: 0.48941829800605774, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.004889572039246559, critic_loss: 0.4891155958175659, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.004839159548282623, critic_loss: 0.4886162281036377, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.004904580768197775, critic_loss: 0.48795294761657715, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.0047056484036147594, critic_loss: 0.4871722161769867, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.004796747118234634, critic_loss: 0.48635154962539673, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.005173244513571262, critic_loss: 0.4855155944824219, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.004649273119866848, critic_loss: 0.4846753776073456, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.005597184877842665, critic_loss: 0.48385629057884216, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.004649944603443146, critic_loss: 0.4830819368362427, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.005035161040723324, critic_loss: 0.48235464096069336, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.004927085712552071, critic_loss: 0.48166564106941223, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.004593970254063606, critic_loss: 0.48101189732551575, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.004837485961616039, critic_loss: 0.480365514755249, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.0049273851327598095, critic_loss: 0.4797102212905884, entropy_bonus: -17.838218688964844\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.012290958315134048, critic_loss: 0.5818250775337219, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.012501080520451069, critic_loss: 0.5806027054786682, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.012302444316446781, critic_loss: 0.5773730874061584, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.012445075437426567, critic_loss: 0.5724535584449768, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.012316171079874039, critic_loss: 0.566093921661377, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.012381755746901035, critic_loss: 0.5585627555847168, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.012325304560363293, critic_loss: 0.5503225326538086, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.01236102357506752, critic_loss: 0.5419997572898865, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.0124049112200737, critic_loss: 0.5339756608009338, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.01238864753395319, critic_loss: 0.5260781645774841, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.012499666772782803, critic_loss: 0.5179764032363892, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.012415960431098938, critic_loss: 0.5096011161804199, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.012616305612027645, critic_loss: 0.5011489987373352, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.012495717033743858, critic_loss: 0.49300718307495117, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.012637881562113762, critic_loss: 0.4855477809906006, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.012514627538621426, critic_loss: 0.4790884554386139, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.01269465871155262, critic_loss: 0.47372642159461975, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.012601835653185844, critic_loss: 0.4693390130996704, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.01275467686355114, critic_loss: 0.4657162129878998, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.012607601471245289, critic_loss: 0.46273478865623474, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.012829739600419998, critic_loss: 0.4603288173675537, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.012638523243367672, critic_loss: 0.4584140181541443, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.01284336019307375, critic_loss: 0.45687273144721985, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.012659547850489616, critic_loss: 0.45560261607170105, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.01285965833812952, critic_loss: 0.4545658230781555, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.012733806855976582, critic_loss: 0.4537460505962372, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.012788724154233932, critic_loss: 0.4531310498714447, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.012755305506289005, critic_loss: 0.45269113779067993, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.012672128155827522, critic_loss: 0.45236870646476746, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.012675768695771694, critic_loss: 0.45209699869155884, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.01264240499585867, critic_loss: 0.45183277130126953, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.012660469859838486, critic_loss: 0.4515634775161743, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.012638356536626816, critic_loss: 0.45129576325416565, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.012667331844568253, critic_loss: 0.451036661863327, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.012639635242521763, critic_loss: 0.4507954716682434, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.012636067345738411, critic_loss: 0.4505760669708252, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.012578715570271015, critic_loss: 0.4503811299800873, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.012606051750481129, critic_loss: 0.4502018094062805, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.012576973997056484, critic_loss: 0.4500245749950409, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.012563010677695274, critic_loss: 0.4498353898525238, entropy_bonus: -17.697803497314453\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.005979740526527166, critic_loss: 0.5945975184440613, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0059771547093987465, critic_loss: 0.5919249057769775, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.005978178232908249, critic_loss: 0.5877822041511536, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.006007177755236626, critic_loss: 0.582413911819458, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.006007008254528046, critic_loss: 0.5759798884391785, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.005997768137603998, critic_loss: 0.5686151385307312, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0059890467673540115, critic_loss: 0.5605227947235107, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.005996816325932741, critic_loss: 0.552152693271637, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.006005825009196997, critic_loss: 0.5439297556877136, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.00601539108902216, critic_loss: 0.5359089374542236, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.006037839222699404, critic_loss: 0.5280066132545471, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.006052768789231777, critic_loss: 0.5202215909957886, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.006065155379474163, critic_loss: 0.5126701593399048, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.006075261160731316, critic_loss: 0.5055431127548218, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.006093482952564955, critic_loss: 0.4990033805370331, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.006108060944825411, critic_loss: 0.4931080639362335, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.006113840267062187, critic_loss: 0.48784416913986206, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.006120193749666214, critic_loss: 0.48316076397895813, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.006134645082056522, critic_loss: 0.4790218770503998, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.006149661261588335, critic_loss: 0.47539493441581726, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.006169562693685293, critic_loss: 0.4722442030906677, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.006181873846799135, critic_loss: 0.46952471137046814, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.0061846268363296986, critic_loss: 0.46719110012054443, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.006193222012370825, critic_loss: 0.46519723534584045, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.006199738476425409, critic_loss: 0.4634997248649597, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.006213005632162094, critic_loss: 0.4620567560195923, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.006214215885847807, critic_loss: 0.46082064509391785, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.0062174247577786446, critic_loss: 0.459743857383728, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.006230519153177738, critic_loss: 0.45877328515052795, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.0062256669625639915, critic_loss: 0.45785266160964966, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.0062340484000742435, critic_loss: 0.4569339454174042, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.006236842833459377, critic_loss: 0.45598453283309937, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.006229314487427473, critic_loss: 0.45499736070632935, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.006233427207916975, critic_loss: 0.4539961516857147, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.006236387882381678, critic_loss: 0.4530337154865265, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.0062374547123909, critic_loss: 0.45217812061309814, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.006241439841687679, critic_loss: 0.45148399472236633, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.006240359041839838, critic_loss: 0.4509742259979248, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.006242153700441122, critic_loss: 0.4506325423717499, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.006243307609111071, critic_loss: 0.4504190981388092, entropy_bonus: -17.562150955200195\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007734834682196379, critic_loss: 0.5565721392631531, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.007733884733170271, critic_loss: 0.5524411797523499, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.007732598576694727, critic_loss: 0.546992838382721, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.007730731274932623, critic_loss: 0.540733277797699, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.007735231891274452, critic_loss: 0.5340572595596313, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.007729691918939352, critic_loss: 0.5272351503372192, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.007737510837614536, critic_loss: 0.5204187035560608, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.007763052359223366, critic_loss: 0.513706624507904, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.007779907900840044, critic_loss: 0.507156491279602, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.007798286154866219, critic_loss: 0.5007762908935547, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.007820399478077888, critic_loss: 0.49452829360961914, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.007813104428350925, critic_loss: 0.488421231508255, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.007806012406945229, critic_loss: 0.48257115483283997, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.007821207866072655, critic_loss: 0.4771880507469177, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.00784932542592287, critic_loss: 0.4725027084350586, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.007851955480873585, critic_loss: 0.46866869926452637, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.007850597612559795, critic_loss: 0.46567460894584656, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.007865434512495995, critic_loss: 0.4633868932723999, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.007871699519455433, critic_loss: 0.461635559797287, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00786976795643568, critic_loss: 0.46027207374572754, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.007871637120842934, critic_loss: 0.45919397473335266, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.007867269217967987, critic_loss: 0.4583285450935364, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.00785395409911871, critic_loss: 0.45762720704078674, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.007855575531721115, critic_loss: 0.4570397138595581, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.007855215109884739, critic_loss: 0.45651185512542725, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.00785116758197546, critic_loss: 0.4560118019580841, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.007865016348659992, critic_loss: 0.4555002748966217, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.007856279611587524, critic_loss: 0.4549587070941925, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.007858636789023876, critic_loss: 0.4543904662132263, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.007858844473958015, critic_loss: 0.4538118243217468, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.007852881215512753, critic_loss: 0.4532533288002014, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.007850955240428448, critic_loss: 0.452730655670166, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.007848271168768406, critic_loss: 0.45225536823272705, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.007853042334318161, critic_loss: 0.45182645320892334, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.007850833237171173, critic_loss: 0.45143595337867737, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.007844265550374985, critic_loss: 0.4510730504989624, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.007852156646549702, critic_loss: 0.45072701573371887, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.007838419638574123, critic_loss: 0.450385183095932, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.007835960946977139, critic_loss: 0.45003271102905273, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.00783741194754839, critic_loss: 0.44965144991874695, entropy_bonus: -17.43094825744629\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00663049565628171, critic_loss: 0.5420781373977661, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.006628089584410191, critic_loss: 0.5401401519775391, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.006625717040151358, critic_loss: 0.5365719199180603, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.006646593566983938, critic_loss: 0.5316792130470276, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.006641482934355736, critic_loss: 0.5257752537727356, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.006680436432361603, critic_loss: 0.5191634297370911, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.006637284066528082, critic_loss: 0.5121327042579651, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.00673235859721899, critic_loss: 0.5049638152122498, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.006682947278022766, critic_loss: 0.49793297052383423, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.00677934056147933, critic_loss: 0.49128085374832153, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.00675974041223526, critic_loss: 0.4851536750793457, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.006774719804525375, critic_loss: 0.4795931875705719, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.006804965436458588, critic_loss: 0.4746090769767761, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.006730613298714161, critic_loss: 0.47020626068115234, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.0068555655889213085, critic_loss: 0.4663964807987213, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.0067634726874530315, critic_loss: 0.4631706178188324, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.006819799076765776, critic_loss: 0.4604648947715759, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.006814179476350546, critic_loss: 0.45819833874702454, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.0068127005361020565, critic_loss: 0.4562720060348511, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.006815494038164616, critic_loss: 0.4545963704586029, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.006807899102568626, critic_loss: 0.4531077444553375, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.006806351710110903, critic_loss: 0.45177748799324036, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.006814778316766024, critic_loss: 0.4505937993526459, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.00681723328307271, critic_loss: 0.4495503008365631, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.006812932435423136, critic_loss: 0.44863665103912354, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.0068266745656728745, critic_loss: 0.4478361904621124, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.006807963363826275, critic_loss: 0.44712936878204346, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.006834276486188173, critic_loss: 0.4464958608150482, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.006812264211475849, critic_loss: 0.44591766595840454, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.006851076614111662, critic_loss: 0.44538313150405884, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.0068125552497804165, critic_loss: 0.44488468766212463, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.006817110348492861, critic_loss: 0.44441384077072144, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.006815094035118818, critic_loss: 0.4439658224582672, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.006807715632021427, critic_loss: 0.4435376524925232, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.006805691868066788, critic_loss: 0.44312784075737, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.006802234798669815, critic_loss: 0.44273728132247925, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.006803289521485567, critic_loss: 0.44236743450164795, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.006801270414143801, critic_loss: 0.44201529026031494, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.006795690860599279, critic_loss: 0.4416791796684265, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.006788940634578466, critic_loss: 0.4413567781448364, entropy_bonus: -17.303913116455078\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.011359347961843014, critic_loss: 0.5175800323486328, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.011351990513503551, critic_loss: 0.5160565972328186, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.011377769522368908, critic_loss: 0.5138154625892639, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.011448950506746769, critic_loss: 0.5109099745750427, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.011448617093265057, critic_loss: 0.50747150182724, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.011427733115851879, critic_loss: 0.5034950971603394, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.01153247058391571, critic_loss: 0.4990415573120117, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.01137520931661129, critic_loss: 0.4942338466644287, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.01146659255027771, critic_loss: 0.48910120129585266, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.011452584527432919, critic_loss: 0.48371681571006775, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.011433862149715424, critic_loss: 0.478272408246994, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.011552752926945686, critic_loss: 0.4729572534561157, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.01149956975132227, critic_loss: 0.46790122985839844, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.011672573164105415, critic_loss: 0.4631289839744568, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.011554161086678505, critic_loss: 0.458525151014328, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.011661031283438206, critic_loss: 0.45398128032684326, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.011614800430834293, critic_loss: 0.449584424495697, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.01165652833878994, critic_loss: 0.4456762969493866, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.011639748699963093, critic_loss: 0.44256073236465454, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.011657526716589928, critic_loss: 0.44018545746803284, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.011656367219984531, critic_loss: 0.4382857382297516, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.011663545854389668, critic_loss: 0.43663880228996277, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.011670850217342377, critic_loss: 0.43512585759162903, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.011674294248223305, critic_loss: 0.4336933493614197, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.011684667319059372, critic_loss: 0.4323292672634125, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.011677137576043606, critic_loss: 0.4310397803783417, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.011681578122079372, critic_loss: 0.42984023690223694, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.01167267095297575, critic_loss: 0.4287354350090027, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.011668957769870758, critic_loss: 0.42773035168647766, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.011662551201879978, critic_loss: 0.4268212616443634, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.011659293435513973, critic_loss: 0.42599716782569885, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.011684129014611244, critic_loss: 0.4252484142780304, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.011747263371944427, critic_loss: 0.4245685040950775, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.011703304946422577, critic_loss: 0.42395225167274475, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.011702322401106358, critic_loss: 0.42339888215065, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.011672653257846832, critic_loss: 0.42290493845939636, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.011800013482570648, critic_loss: 0.422466516494751, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.011854647658765316, critic_loss: 0.4220772087574005, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.011744985356926918, critic_loss: 0.42173564434051514, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.011952551081776619, critic_loss: 0.42143529653549194, entropy_bonus: -17.180789947509766\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.006211507134139538, critic_loss: 0.5097521543502808, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.006290980149060488, critic_loss: 0.506853461265564, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.006328577641397715, critic_loss: 0.5030112862586975, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.006246509030461311, critic_loss: 0.49845242500305176, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.006261902861297131, critic_loss: 0.49346762895584106, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.006355786696076393, critic_loss: 0.48832690715789795, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.006328687071800232, critic_loss: 0.48317721486091614, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.006265361327677965, critic_loss: 0.478041410446167, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.006360238417983055, critic_loss: 0.47290560603141785, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.006363680586218834, critic_loss: 0.46782219409942627, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.006297736894339323, critic_loss: 0.462899774312973, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.0063720704056322575, critic_loss: 0.45827823877334595, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0064079733565449715, critic_loss: 0.4540623426437378, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.006360432133078575, critic_loss: 0.4502753019332886, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.006381229963153601, critic_loss: 0.44686490297317505, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.006428999360650778, critic_loss: 0.4438237249851227, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.00640165526419878, critic_loss: 0.4412079155445099, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.006416536867618561, critic_loss: 0.43909209966659546, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.006464058067649603, critic_loss: 0.4374678134918213, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.006447655148804188, critic_loss: 0.4362383186817169, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0064271073788404465, critic_loss: 0.43529435992240906, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.006456754636019468, critic_loss: 0.43455424904823303, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.006460243836045265, critic_loss: 0.43396633863449097, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.006443345919251442, critic_loss: 0.43349429965019226, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.00644794711843133, critic_loss: 0.4331169128417969, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.006444661412388086, critic_loss: 0.43281909823417664, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00642420956864953, critic_loss: 0.43258577585220337, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.006424664985388517, critic_loss: 0.4324016273021698, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.006408658344298601, critic_loss: 0.4322530925273895, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00639897957444191, critic_loss: 0.432127445936203, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.006395326461642981, critic_loss: 0.4320152997970581, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.0063803973607718945, critic_loss: 0.43190860748291016, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.0063761575147509575, critic_loss: 0.4318009912967682, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.006373621989041567, critic_loss: 0.43168866634368896, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.006367432419210672, critic_loss: 0.43156903982162476, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.006364301312714815, critic_loss: 0.43144112825393677, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.006363764870911837, critic_loss: 0.43130525946617126, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.006357020232826471, critic_loss: 0.4311646521091461, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.006350637413561344, critic_loss: 0.43101754784584045, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.006353162694722414, critic_loss: 0.43086501955986023, entropy_bonus: -17.061342239379883\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008668129332363605, critic_loss: 0.510229229927063, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008665147237479687, critic_loss: 0.5085394978523254, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008662320673465729, critic_loss: 0.505592942237854, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008673402480781078, critic_loss: 0.5017111301422119, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.00874587893486023, critic_loss: 0.4972352087497711, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008800948970019817, critic_loss: 0.4923965334892273, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008758262731134892, critic_loss: 0.48742735385894775, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008924736641347408, critic_loss: 0.4824303090572357, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008766692131757736, critic_loss: 0.4774322807788849, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008952347561717033, critic_loss: 0.47247564792633057, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008803050965070724, critic_loss: 0.4676041901111603, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008856725879013538, critic_loss: 0.46286627650260925, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008890029974281788, critic_loss: 0.45835980772972107, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008870494551956654, critic_loss: 0.45420074462890625, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008930318988859653, critic_loss: 0.4504847824573517, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008896203711628914, critic_loss: 0.4472810924053192, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.0090312035754323, critic_loss: 0.444601833820343, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008912344463169575, critic_loss: 0.44239282608032227, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.00902616512030363, critic_loss: 0.44061338901519775, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.008948522619903088, critic_loss: 0.43921157717704773, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.009037613868713379, critic_loss: 0.4381271302700043, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.009039347991347313, critic_loss: 0.4372901916503906, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.009043147787451744, critic_loss: 0.43667247891426086, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.009017784148454666, critic_loss: 0.4362293779850006, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.009033999405801296, critic_loss: 0.43592512607574463, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.009031681343913078, critic_loss: 0.4357239305973053, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.009050019085407257, critic_loss: 0.43558236956596375, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.009028763510286808, critic_loss: 0.4354587495326996, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.009042982943356037, critic_loss: 0.43532508611679077, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.009009786881506443, critic_loss: 0.4351601302623749, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.009002761915326118, critic_loss: 0.4349454939365387, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008976409211754799, critic_loss: 0.43467846512794495, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008988038636744022, critic_loss: 0.4343634843826294, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008964681066572666, critic_loss: 0.4340128004550934, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008934351615607738, critic_loss: 0.4336339235305786, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008936803787946701, critic_loss: 0.43324270844459534, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.00897134467959404, critic_loss: 0.4328515827655792, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008906357921659946, critic_loss: 0.4324713349342346, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.009022090584039688, critic_loss: 0.4321100413799286, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008918722160160542, critic_loss: 0.4317665994167328, entropy_bonus: -16.945358276367188\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.006412913557142019, critic_loss: 0.4982869625091553, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.006412817630916834, critic_loss: 0.4970558285713196, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.0064188456162810326, critic_loss: 0.493787556886673, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.00643800338730216, critic_loss: 0.4887793958187103, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.006473185028880835, critic_loss: 0.4824218451976776, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.00651122909039259, critic_loss: 0.47519004344940186, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.006577859632670879, critic_loss: 0.46754950284957886, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.00664001889526844, critic_loss: 0.45986270904541016, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.006711883470416069, critic_loss: 0.45232442021369934, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.006776785012334585, critic_loss: 0.44529789686203003, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.006829939316958189, critic_loss: 0.4392060339450836, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.006871510297060013, critic_loss: 0.43427807092666626, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0068999528884887695, critic_loss: 0.4304386079311371, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.0069228289648890495, critic_loss: 0.4275161623954773, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.006933434866368771, critic_loss: 0.4253907799720764, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.006947685033082962, critic_loss: 0.4238741993904114, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.006969052832573652, critic_loss: 0.422820121049881, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.00699205044656992, critic_loss: 0.4221181571483612, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.007028358988463879, critic_loss: 0.42170917987823486, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.007060466334223747, critic_loss: 0.4215596914291382, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.007088547572493553, critic_loss: 0.4216251075267792, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.007110028062015772, critic_loss: 0.42184677720069885, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.007114886771887541, critic_loss: 0.422161340713501, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.00709804380312562, critic_loss: 0.4225006401538849, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.007086483296006918, critic_loss: 0.4228130280971527, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.007063082419335842, critic_loss: 0.4230619966983795, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.007026286795735359, critic_loss: 0.4232262074947357, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.00698925880715251, critic_loss: 0.42329898476600647, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.00695505877956748, critic_loss: 0.42328330874443054, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.0069041624665260315, critic_loss: 0.42318597435951233, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.006851157173514366, critic_loss: 0.42301836609840393, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.0068201287649571896, critic_loss: 0.4227956533432007, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.00678703049197793, critic_loss: 0.42253294587135315, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.00675777206197381, critic_loss: 0.4222470223903656, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.0067309183068573475, critic_loss: 0.42195016145706177, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.006699416786432266, critic_loss: 0.4216538071632385, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.006667164620012045, critic_loss: 0.4213714897632599, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.006643443834036589, critic_loss: 0.42111313343048096, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.0066442545503377914, critic_loss: 0.4208807349205017, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.006632820703089237, critic_loss: 0.42067691683769226, entropy_bonus: -16.8326416015625\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008373350836336613, critic_loss: 0.5216816663742065, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008370655588805676, critic_loss: 0.521272599697113, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008369388990104198, critic_loss: 0.5191248059272766, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008407370187342167, critic_loss: 0.5154948234558105, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008432234637439251, critic_loss: 0.5106635689735413, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008501240983605385, critic_loss: 0.5049020648002625, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008543132804334164, critic_loss: 0.49846959114074707, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008598878048360348, critic_loss: 0.49159863591194153, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008689342997968197, critic_loss: 0.4845235049724579, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.0087991151958704, critic_loss: 0.4774135947227478, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008917965926229954, critic_loss: 0.4704571068286896, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.009021091274917126, critic_loss: 0.46383845806121826, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.00911746360361576, critic_loss: 0.45780661702156067, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.00919026043266058, critic_loss: 0.4524758756160736, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.009218821302056313, critic_loss: 0.4478946030139923, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.009246096946299076, critic_loss: 0.4440290331840515, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.00926954299211502, critic_loss: 0.4407523572444916, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.009289033710956573, critic_loss: 0.4379691183567047, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.009288109838962555, critic_loss: 0.43571603298187256, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.009291409514844418, critic_loss: 0.43403783440589905, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.00927722454071045, critic_loss: 0.43291547894477844, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.009259686805307865, critic_loss: 0.43225497007369995, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.00923840794712305, critic_loss: 0.43192970752716064, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.009206335991621017, critic_loss: 0.43182599544525146, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.009153755381703377, critic_loss: 0.43185755610466003, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.009104619733989239, critic_loss: 0.4319540858268738, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00905859749764204, critic_loss: 0.4320628345012665, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008997435681521893, critic_loss: 0.4321509897708893, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008937708102166653, critic_loss: 0.4321969151496887, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008882586844265461, critic_loss: 0.43219226598739624, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008831684477627277, critic_loss: 0.4321340024471283, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008780816569924355, critic_loss: 0.43202248215675354, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008759609423577785, critic_loss: 0.4318596422672272, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008749700151383877, critic_loss: 0.4316568970680237, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008744866587221622, critic_loss: 0.4314214885234833, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008745795115828514, critic_loss: 0.43116316199302673, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008757472969591618, critic_loss: 0.4308890402317047, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008780166506767273, critic_loss: 0.4306049644947052, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008768727071583271, critic_loss: 0.4303153455257416, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008777515031397343, critic_loss: 0.4300232231616974, entropy_bonus: -16.7230167388916\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.010691430419683456, critic_loss: 0.554630696773529, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.010680277831852436, critic_loss: 0.5526988506317139, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.01068638265132904, critic_loss: 0.5490454435348511, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.01079566776752472, critic_loss: 0.5440925359725952, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.01078798621892929, critic_loss: 0.5382484793663025, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.010799922049045563, critic_loss: 0.5317342281341553, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.010899780318140984, critic_loss: 0.5249432325363159, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.010934059508144855, critic_loss: 0.518274188041687, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.010971802286803722, critic_loss: 0.5119505524635315, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.011134576983749866, critic_loss: 0.5060866475105286, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.01113397628068924, critic_loss: 0.5006356239318848, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.011281860060989857, critic_loss: 0.49547746777534485, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.011321701109409332, critic_loss: 0.49047431349754333, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.011340079829096794, critic_loss: 0.4856102764606476, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.011402294039726257, critic_loss: 0.481021910905838, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.011397070251405239, critic_loss: 0.4769009053707123, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.01139075867831707, critic_loss: 0.4733627438545227, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.01143454760313034, critic_loss: 0.47035372257232666, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.011385812424123287, critic_loss: 0.4677368700504303, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.011493301950395107, critic_loss: 0.4654127359390259, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.011391225270926952, critic_loss: 0.46333521604537964, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.011514034122228622, critic_loss: 0.4614766538143158, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.01147189736366272, critic_loss: 0.45980140566825867, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.011428597383201122, critic_loss: 0.458286851644516, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.011394839733839035, critic_loss: 0.4569782018661499, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.011489007622003555, critic_loss: 0.4559391438961029, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.011521979235112667, critic_loss: 0.45517975091934204, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.011408580467104912, critic_loss: 0.4546423554420471, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.011497157625854015, critic_loss: 0.4542354345321655, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.011453676968812943, critic_loss: 0.45388278365135193, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.011475779116153717, critic_loss: 0.45355433225631714, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.01146719604730606, critic_loss: 0.4532274901866913, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.011427400633692741, critic_loss: 0.45287129282951355, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.011446075513958931, critic_loss: 0.45248374342918396, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.011410706676542759, critic_loss: 0.4520675837993622, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.01143611129373312, critic_loss: 0.4516218900680542, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.011401122435927391, critic_loss: 0.45114725828170776, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.011412195861339569, critic_loss: 0.45065659284591675, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.011396399699151516, critic_loss: 0.45016351342201233, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.011385602876543999, critic_loss: 0.44967055320739746, entropy_bonus: -16.616315841674805\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.006103075575083494, critic_loss: 0.5187228918075562, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.006168283987790346, critic_loss: 0.516762912273407, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.006103536579757929, critic_loss: 0.5142735242843628, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.006148569285869598, critic_loss: 0.511345386505127, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.0061316764913499355, critic_loss: 0.508085310459137, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.006198527291417122, critic_loss: 0.5045936703681946, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.006205359008163214, critic_loss: 0.5009447336196899, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.006240840069949627, critic_loss: 0.497169554233551, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.006287644151598215, critic_loss: 0.4932972490787506, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.006296974606812, critic_loss: 0.4894178509712219, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.006309886928647757, critic_loss: 0.48568958044052124, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.0063138618133962154, critic_loss: 0.48214542865753174, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0062996093183755875, critic_loss: 0.4788222908973694, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.006338175386190414, critic_loss: 0.4757063388824463, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.00632640952244401, critic_loss: 0.47274842858314514, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.006347456015646458, critic_loss: 0.469908207654953, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.006341732107102871, critic_loss: 0.4671255350112915, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.006360339932143688, critic_loss: 0.4643285870552063, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.006364088971167803, critic_loss: 0.46143588423728943, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.006359393242746592, critic_loss: 0.458392858505249, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0063825929537415504, critic_loss: 0.4552902579307556, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.006363163236528635, critic_loss: 0.45243969559669495, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.006395545322448015, critic_loss: 0.4501759111881256, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.006399127654731274, critic_loss: 0.44857680797576904, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.006414520554244518, critic_loss: 0.44752037525177, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.006396177224814892, critic_loss: 0.44684725999832153, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.006425956264138222, critic_loss: 0.4464179277420044, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.006436184514313936, critic_loss: 0.44612523913383484, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.006441983859986067, critic_loss: 0.4459041953086853, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00644482159987092, critic_loss: 0.44571536779403687, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.006420358549803495, critic_loss: 0.44553670287132263, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.006421992555260658, critic_loss: 0.44535350799560547, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.006422038655728102, critic_loss: 0.4451626241207123, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.006416575517505407, critic_loss: 0.44496479630470276, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.0064105987548828125, critic_loss: 0.44476255774497986, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.006393423303961754, critic_loss: 0.44455575942993164, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.0063841454684734344, critic_loss: 0.44434651732444763, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.006383430678397417, critic_loss: 0.44413450360298157, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.006370180286467075, critic_loss: 0.44391900300979614, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.006365290377289057, critic_loss: 0.44370028376579285, entropy_bonus: -16.512386322021484\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.013032866641879082, critic_loss: 0.5457146763801575, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.013031421229243279, critic_loss: 0.5433894395828247, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.01302845124155283, critic_loss: 0.539925217628479, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.013034123927354813, critic_loss: 0.5355482697486877, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.013040080666542053, critic_loss: 0.5304848551750183, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.01303758006542921, critic_loss: 0.5249731540679932, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.013042839244008064, critic_loss: 0.5192540884017944, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.013054607436060905, critic_loss: 0.5135984420776367, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.013060472905635834, critic_loss: 0.5082994103431702, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.013075318187475204, critic_loss: 0.5036015510559082, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.013098537921905518, critic_loss: 0.4996316730976105, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.013106905855238438, critic_loss: 0.4964165687561035, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.013120071031153202, critic_loss: 0.49388009309768677, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.013135776855051517, critic_loss: 0.49192023277282715, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.013153254054486752, critic_loss: 0.49043798446655273, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.013172252103686333, critic_loss: 0.4893358647823334, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.013184266164898872, critic_loss: 0.4885234236717224, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.013190259225666523, critic_loss: 0.48791036009788513, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.013193280436098576, critic_loss: 0.4874095320701599, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.01319701224565506, critic_loss: 0.4869382083415985, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.013198889791965485, critic_loss: 0.48642346262931824, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.013200836256146431, critic_loss: 0.48580384254455566, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.013200964778661728, critic_loss: 0.48503339290618896, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.013203805312514305, critic_loss: 0.4840785562992096, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.01319803949445486, critic_loss: 0.48291370272636414, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.013194375671446323, critic_loss: 0.48151224851608276, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.013189442455768585, critic_loss: 0.47983941435813904, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.013179069384932518, critic_loss: 0.47787967324256897, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.01316649466753006, critic_loss: 0.47572195529937744, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.01315809041261673, critic_loss: 0.47359946370124817, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.013150173239409924, critic_loss: 0.47175487875938416, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.013143683783710003, critic_loss: 0.4702729284763336, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.013140466995537281, critic_loss: 0.4689963459968567, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.013139633461833, critic_loss: 0.4676136076450348, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.013143179006874561, critic_loss: 0.4658743143081665, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.013151261955499649, critic_loss: 0.46372106671333313, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.013156209141016006, critic_loss: 0.46130213141441345, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.01316719688475132, critic_loss: 0.4588959515094757, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.01316853892058134, critic_loss: 0.4567459225654602, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.013167434372007847, critic_loss: 0.45495888590812683, entropy_bonus: -16.411088943481445\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.013292334042489529, critic_loss: 0.5447854995727539, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.013287845999002457, critic_loss: 0.5404226779937744, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.013283138163387775, critic_loss: 0.5347278118133545, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.013323487713932991, critic_loss: 0.5282427668571472, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.013312728144228458, critic_loss: 0.5215897560119629, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.013396774418652058, critic_loss: 0.515378475189209, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.013370383530855179, critic_loss: 0.509989857673645, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.013467401266098022, critic_loss: 0.5053811073303223, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.013400927186012268, critic_loss: 0.5011510252952576, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.013494441285729408, critic_loss: 0.496758371591568, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.013412048108875751, critic_loss: 0.492077112197876, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.013494491577148438, critic_loss: 0.4878825843334198, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.013451654464006424, critic_loss: 0.48488500714302063, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.013515518978238106, critic_loss: 0.4826669991016388, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.013478506356477737, critic_loss: 0.4805406332015991, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.013446150347590446, critic_loss: 0.47804388403892517, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.013461328111588955, critic_loss: 0.4750126302242279, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.013410398736596107, critic_loss: 0.47177982330322266, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.013444861397147179, critic_loss: 0.4689745604991913, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.013402480632066727, critic_loss: 0.46706926822662354, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.013403935357928276, critic_loss: 0.46607157588005066, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.013389949686825275, critic_loss: 0.4656027853488922, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.013384065590798855, critic_loss: 0.4652453064918518, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.0133815361186862, critic_loss: 0.46475136280059814, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.013374163769185543, critic_loss: 0.46403270959854126, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.013363556936383247, critic_loss: 0.46309250593185425, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.013360979035496712, critic_loss: 0.46196243166923523, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.013370445929467678, critic_loss: 0.4606917202472687, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.013369087129831314, critic_loss: 0.4593349099159241, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.013373120687901974, critic_loss: 0.4579569399356842, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.013368182815611362, critic_loss: 0.45662322640419006, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.01336303073912859, critic_loss: 0.4553883671760559, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.013362547382712364, critic_loss: 0.4542806148529053, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.013366245664656162, critic_loss: 0.4533034861087799, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.013378307223320007, critic_loss: 0.4524479806423187, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.013376924209296703, critic_loss: 0.4516841173171997, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.013373390771448612, critic_loss: 0.45096901059150696, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.013359569013118744, critic_loss: 0.4502740204334259, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.013353362679481506, critic_loss: 0.4495683014392853, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.013352558948099613, critic_loss: 0.44884228706359863, entropy_bonus: -16.312294006347656\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.010178854689002037, critic_loss: 0.6307003498077393, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.010176806710660458, critic_loss: 0.6274718642234802, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.01017509400844574, critic_loss: 0.6223661303520203, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.010193410329520702, critic_loss: 0.61634761095047, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.010213364847004414, critic_loss: 0.6099032759666443, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.010236392728984356, critic_loss: 0.6029472351074219, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.010251774452626705, critic_loss: 0.5949098467826843, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.010280290618538857, critic_loss: 0.5846905708312988, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.010320577770471573, critic_loss: 0.5713852047920227, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.010349087417125702, critic_loss: 0.5569142699241638, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.010378398932516575, critic_loss: 0.5443608164787292, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.010381394997239113, critic_loss: 0.5328449606895447, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.010402161628007889, critic_loss: 0.5204840898513794, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.01042407751083374, critic_loss: 0.5070650577545166, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.010447054170072079, critic_loss: 0.4952397346496582, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.010471728630363941, critic_loss: 0.4867452383041382, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.010505925863981247, critic_loss: 0.48121386766433716, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.010530988685786724, critic_loss: 0.47649258375167847, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.01056000404059887, critic_loss: 0.4723508656024933, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.010586246848106384, critic_loss: 0.46939897537231445, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.010603637434542179, critic_loss: 0.46794044971466064, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.01061780471354723, critic_loss: 0.4676760733127594, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.010614991188049316, critic_loss: 0.46814173460006714, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.010609464719891548, critic_loss: 0.4687040448188782, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.010589104145765305, critic_loss: 0.46912381052970886, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.010571690276265144, critic_loss: 0.4693763554096222, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.010553847067058086, critic_loss: 0.46954670548439026, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.010528775863349438, critic_loss: 0.46973228454589844, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.010517776943743229, critic_loss: 0.46997398138046265, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.010496036149561405, critic_loss: 0.47025489807128906, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.01049600075930357, critic_loss: 0.4705272912979126, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.01052981335669756, critic_loss: 0.4707303047180176, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.010474174283444881, critic_loss: 0.47079840302467346, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.010553533211350441, critic_loss: 0.47070714831352234, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.010482422076165676, critic_loss: 0.4704754054546356, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.010514836758375168, critic_loss: 0.4701300263404846, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.010536324232816696, critic_loss: 0.4696957468986511, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.010411681607365608, critic_loss: 0.46921205520629883, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.010477113537490368, critic_loss: 0.4687228202819824, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.010388803668320179, critic_loss: 0.4682559669017792, entropy_bonus: -16.21588134765625\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.017713582143187523, critic_loss: 0.6864517331123352, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.017711281776428223, critic_loss: 0.6817606687545776, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.01771627366542816, critic_loss: 0.6710163950920105, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.017705252394080162, critic_loss: 0.6558448076248169, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.01769779436290264, critic_loss: 0.6377648711204529, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.01771940290927887, critic_loss: 0.6181087493896484, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.01776737906038761, critic_loss: 0.5998229384422302, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.017811203375458717, critic_loss: 0.5838162899017334, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.017869558185338974, critic_loss: 0.5690507888793945, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.017921941354870796, critic_loss: 0.5567569136619568, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.01797402650117874, critic_loss: 0.5475590825080872, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.018027380108833313, critic_loss: 0.5405908226966858, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.018098188564181328, critic_loss: 0.5351346135139465, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.018148045986890793, critic_loss: 0.5310864448547363, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.018205352127552032, critic_loss: 0.5278868675231934, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.018237082287669182, critic_loss: 0.5248356461524963, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.018253762274980545, critic_loss: 0.5219528079032898, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.01825214922428131, critic_loss: 0.5196710824966431, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.018230542540550232, critic_loss: 0.5181888937950134, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.018200162798166275, critic_loss: 0.5172898769378662, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.018159495666623116, critic_loss: 0.5167008638381958, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.018104400485754013, critic_loss: 0.5163301229476929, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.018073465675115585, critic_loss: 0.5161520838737488, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.018046749755740166, critic_loss: 0.5161097645759583, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.018010590225458145, critic_loss: 0.516126811504364, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.018003378063440323, critic_loss: 0.5161274671554565, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.017995338886976242, critic_loss: 0.5160601139068604, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.017996670678257942, critic_loss: 0.5159032940864563, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.01798088476061821, critic_loss: 0.5156556963920593, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.017960229888558388, critic_loss: 0.515333354473114, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.017951752990484238, critic_loss: 0.5149651169776917, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.017922233790159225, critic_loss: 0.5145823955535889, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.017936814576387405, critic_loss: 0.5142037272453308, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.01788528449833393, critic_loss: 0.5138373970985413, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.017889132723212242, critic_loss: 0.5134764909744263, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.017863990738987923, critic_loss: 0.5131148099899292, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.01783893257379532, critic_loss: 0.5127325057983398, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.017841238528490067, critic_loss: 0.5123186707496643, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.01782410405576229, critic_loss: 0.5118710398674011, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.017809230834245682, critic_loss: 0.5113997459411621, entropy_bonus: -16.121736526489258\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007270775735378265, critic_loss: 0.572664737701416, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.007269727531820536, critic_loss: 0.5708776712417603, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.007275591604411602, critic_loss: 0.56732177734375, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.007288838736712933, critic_loss: 0.5627395510673523, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.0072820247150957584, critic_loss: 0.557875394821167, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.007287241518497467, critic_loss: 0.5531654357910156, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0073391287587583065, critic_loss: 0.5488253235816956, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.007356752175837755, critic_loss: 0.5450109839439392, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.007395290303975344, critic_loss: 0.5418471693992615, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.007443533279001713, critic_loss: 0.5391866564750671, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.0073936921544373035, critic_loss: 0.5367045402526855, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.007393832318484783, critic_loss: 0.5340923070907593, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.007411862723529339, critic_loss: 0.5311527252197266, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.007499268744140863, critic_loss: 0.5278111696243286, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.007454720325767994, critic_loss: 0.5241706967353821, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.007414905820041895, critic_loss: 0.5203897356987, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.00739729730412364, critic_loss: 0.5166771411895752, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.007420652080327272, critic_loss: 0.5131375193595886, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.007430882193148136, critic_loss: 0.509772539138794, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.007481588050723076, critic_loss: 0.5065698027610779, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.007418019697070122, critic_loss: 0.5035269856452942, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.007388748228549957, critic_loss: 0.5007326006889343, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.0075823646038770676, critic_loss: 0.49828025698661804, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.007481572683900595, critic_loss: 0.4962119162082672, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.007435643579810858, critic_loss: 0.49449753761291504, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.00748264929279685, critic_loss: 0.4930678904056549, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.007453246042132378, critic_loss: 0.4918566048145294, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.007491918746381998, critic_loss: 0.4908076524734497, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.007511432282626629, critic_loss: 0.4898760914802551, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.007435033563524485, critic_loss: 0.4890252649784088, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.007506487425416708, critic_loss: 0.48822394013404846, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.0076964558102190495, critic_loss: 0.4874591827392578, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.007419512141495943, critic_loss: 0.48673215508461, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.007797576487064362, critic_loss: 0.4860391318798065, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.007658171933144331, critic_loss: 0.4853772819042206, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.00746780214831233, critic_loss: 0.48476505279541016, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.007890432141721249, critic_loss: 0.48420947790145874, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.00745633989572525, critic_loss: 0.4837051331996918, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.007523370906710625, critic_loss: 0.4832582175731659, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.007710592821240425, critic_loss: 0.48286283016204834, entropy_bonus: -16.02975845336914\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008010005578398705, critic_loss: 0.588771641254425, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0080109229311347, critic_loss: 0.5834930539131165, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008039439097046852, critic_loss: 0.5758867859840393, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008098957128822803, critic_loss: 0.5676841139793396, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008113845251500607, critic_loss: 0.5599439144134521, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008111191913485527, critic_loss: 0.5527586936950684, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008125647902488708, critic_loss: 0.5460466742515564, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008159935474395752, critic_loss: 0.5397277474403381, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008224585093557835, critic_loss: 0.5339404940605164, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008304251357913017, critic_loss: 0.5291640758514404, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008364155888557434, critic_loss: 0.5255540609359741, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008409533649682999, critic_loss: 0.5226079225540161, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008450777269899845, critic_loss: 0.5198221802711487, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008465902879834175, critic_loss: 0.5169410109519958, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008481931872665882, critic_loss: 0.5138496160507202, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008471574634313583, critic_loss: 0.5104376077651978, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008452867157757282, critic_loss: 0.5065531134605408, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008435149677097797, critic_loss: 0.502040445804596, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008394002914428711, critic_loss: 0.49686530232429504, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.008364997804164886, critic_loss: 0.49100297689437866, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008325647562742233, critic_loss: 0.4849678575992584, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008297466672956944, critic_loss: 0.48015499114990234, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008274251595139503, critic_loss: 0.4771687686443329, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.008254996500909328, critic_loss: 0.4752950072288513, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008245578967034817, critic_loss: 0.47381287813186646, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008232604712247849, critic_loss: 0.47227999567985535, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00821743905544281, critic_loss: 0.4706443250179291, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008201041258871555, critic_loss: 0.4691135883331299, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008202042430639267, critic_loss: 0.4678288698196411, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008196797221899033, critic_loss: 0.46677327156066895, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008189202286303043, critic_loss: 0.46584147214889526, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008179388009011745, critic_loss: 0.46493449807167053, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008179194293916225, critic_loss: 0.4639885723590851, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.00817234255373478, critic_loss: 0.46295416355133057, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008158683776855469, critic_loss: 0.46180227398872375, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.00815084483474493, critic_loss: 0.4605073630809784, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008154205046594143, critic_loss: 0.4590519964694977, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008163298480212688, critic_loss: 0.45744672417640686, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008181512355804443, critic_loss: 0.4558243155479431, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008176636882126331, critic_loss: 0.4545118808746338, entropy_bonus: -15.93984603881836\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008525482378900051, critic_loss: 0.5571826100349426, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008524511009454727, critic_loss: 0.5526703000068665, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.00852521788328886, critic_loss: 0.5479727983474731, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008536126464605331, critic_loss: 0.5434767603874207, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008547487668693066, critic_loss: 0.5391050577163696, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008570301346480846, critic_loss: 0.5345380902290344, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008596913889050484, critic_loss: 0.5294778943061829, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008621146902441978, critic_loss: 0.5238472819328308, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008649056777358055, critic_loss: 0.5178583860397339, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008674153126776218, critic_loss: 0.5119023323059082, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008706253953278065, critic_loss: 0.5062586069107056, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008734351024031639, critic_loss: 0.5010159015655518, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008745864033699036, critic_loss: 0.4962504804134369, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008757493458688259, critic_loss: 0.4921267330646515, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008769501000642776, critic_loss: 0.48865067958831787, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008777291513979435, critic_loss: 0.48548147082328796, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.00878878217190504, critic_loss: 0.48215723037719727, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008800218813121319, critic_loss: 0.4783177673816681, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008808289654552937, critic_loss: 0.47393712401390076, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.008822949603199959, critic_loss: 0.4695388972759247, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.00882937852293253, critic_loss: 0.4660564064979553, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008827836252748966, critic_loss: 0.46381232142448425, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008831633254885674, critic_loss: 0.4624888002872467, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.008828800171613693, critic_loss: 0.4616445004940033, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.00881441030651331, critic_loss: 0.46094033122062683, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008795782923698425, critic_loss: 0.46013620495796204, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00877457857131958, critic_loss: 0.45910021662712097, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008754972368478775, critic_loss: 0.45783179998397827, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008742031641304493, critic_loss: 0.4564512372016907, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008728418499231339, critic_loss: 0.45512688159942627, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008718583732843399, critic_loss: 0.4540058374404907, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008717164397239685, critic_loss: 0.4531497061252594, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008714988827705383, critic_loss: 0.4525410532951355, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008714481256902218, critic_loss: 0.4521087110042572, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008705608546733856, critic_loss: 0.4517735242843628, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008700720965862274, critic_loss: 0.4514710307121277, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008690538816154003, critic_loss: 0.45116403698921204, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008690292946994305, critic_loss: 0.4508422911167145, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008672643452882767, critic_loss: 0.45050370693206787, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008671563118696213, critic_loss: 0.4501611590385437, entropy_bonus: -15.851911544799805\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.014322562143206596, critic_loss: 0.5789702534675598, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.014352557249367237, critic_loss: 0.5758303999900818, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.016432881355285645, critic_loss: 0.5707588195800781, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.016337577253580093, critic_loss: 0.5645052194595337, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.017781004309654236, critic_loss: 0.5581369996070862, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.019074756652116776, critic_loss: 0.552040159702301, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.01939813606441021, critic_loss: 0.5459940433502197, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.01881132833659649, critic_loss: 0.5399128794670105, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.017514510080218315, critic_loss: 0.534011960029602, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.016160791739821434, critic_loss: 0.5285142064094543, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.015644222497940063, critic_loss: 0.5234201550483704, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.01487067062407732, critic_loss: 0.5186710953712463, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.019734827801585197, critic_loss: 0.5142646431922913, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.015560326166450977, critic_loss: 0.5101653933525085, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.01606372743844986, critic_loss: 0.5065563917160034, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.017634298652410507, critic_loss: 0.5033957362174988, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.018741227686405182, critic_loss: 0.5006163716316223, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.01920950785279274, critic_loss: 0.4981328845024109, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.019056286662817, critic_loss: 0.4958712160587311, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.01838831789791584, critic_loss: 0.4937482476234436, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0173393152654171, critic_loss: 0.49169161915779114, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.01615181192755699, critic_loss: 0.4896555542945862, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.015575852245092392, critic_loss: 0.48762115836143494, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.015747377648949623, critic_loss: 0.4856666624546051, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.016364064067602158, critic_loss: 0.48398086428642273, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.01643972471356392, critic_loss: 0.4827452600002289, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.01626160740852356, critic_loss: 0.4819679856300354, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.01646045409142971, critic_loss: 0.48151034116744995, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.016623161733150482, critic_loss: 0.4812262952327728, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.01663275435566902, critic_loss: 0.48102134466171265, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.016778679564595222, critic_loss: 0.48085132241249084, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.016644788905978203, critic_loss: 0.480698823928833, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.016603505238890648, critic_loss: 0.4805630147457123, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.016527239233255386, critic_loss: 0.48044219613075256, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.01642555370926857, critic_loss: 0.48033374547958374, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.016176732257008553, critic_loss: 0.4802340269088745, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.01616605371236801, critic_loss: 0.48014122247695923, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.016224196180701256, critic_loss: 0.4800510108470917, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.016218042001128197, critic_loss: 0.4799591898918152, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.016152799129486084, critic_loss: 0.47986340522766113, entropy_bonus: -15.765867233276367\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.02231532149016857, critic_loss: 0.727478563785553, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.022304119542241096, critic_loss: 0.7202798128128052, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.02227724716067314, critic_loss: 0.7086632251739502, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.022269807755947113, critic_loss: 0.6957173943519592, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.022274309769272804, critic_loss: 0.6833187937736511, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.022298801690340042, critic_loss: 0.6691319346427917, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.022283069789409637, critic_loss: 0.651451826095581, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.022336669266223907, critic_loss: 0.6358901262283325, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.022263960912823677, critic_loss: 0.6251832842826843, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.02229277603328228, critic_loss: 0.6172125339508057, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.022264724597334862, critic_loss: 0.6107632517814636, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.022270992398262024, critic_loss: 0.6044562458992004, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.022271107882261276, critic_loss: 0.5994710922241211, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.02230481430888176, critic_loss: 0.5971985459327698, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.022270701825618744, critic_loss: 0.5959287881851196, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.02228461392223835, critic_loss: 0.5940490961074829, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.022313740104436874, critic_loss: 0.5911872386932373, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.022354450076818466, critic_loss: 0.5875654816627502, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.022296350449323654, critic_loss: 0.5836166143417358, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.02235221490263939, critic_loss: 0.5796088576316833, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.022354209795594215, critic_loss: 0.5756747126579285, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.022364487871527672, critic_loss: 0.5719741582870483, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.022391382604837418, critic_loss: 0.5685754418373108, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.022409701719880104, critic_loss: 0.5655069947242737, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.02243035100400448, critic_loss: 0.5627990961074829, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.022438494488596916, critic_loss: 0.5605015754699707, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.02245563641190529, critic_loss: 0.5586600303649902, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.022463511675596237, critic_loss: 0.5573303699493408, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.022476626560091972, critic_loss: 0.5565074682235718, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.022479141131043434, critic_loss: 0.5560517311096191, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.02252204902470112, critic_loss: 0.5557273626327515, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.02247699163854122, critic_loss: 0.555298924446106, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.02252291887998581, critic_loss: 0.5546247959136963, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.022505491971969604, critic_loss: 0.5536815524101257, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.02244744636118412, critic_loss: 0.5525651574134827, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.02244533598423004, critic_loss: 0.5513816475868225, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.02247280813753605, critic_loss: 0.5502160787582397, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.0224599689245224, critic_loss: 0.5491533279418945, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.022467536851763725, critic_loss: 0.5482814311981201, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.022426201030611992, critic_loss: 0.54766446352005, entropy_bonus: -15.681636810302734\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.0016936808824539185, critic_loss: 0.6584467887878418, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0016939893830567598, critic_loss: 0.6586588025093079, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.0016941622598096728, critic_loss: 0.6579914093017578, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.0016942116199061275, critic_loss: 0.6565107703208923, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.001694150734692812, critic_loss: 0.6543893814086914, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.001693989965133369, critic_loss: 0.6518396735191345, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0016941761132329702, critic_loss: 0.6490609645843506, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.0016970905708149076, critic_loss: 0.6461936235427856, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.0017039303202182055, critic_loss: 0.6433264017105103, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.0017152456566691399, critic_loss: 0.6405073404312134, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.0017263892805203795, critic_loss: 0.6377699375152588, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.001735822530463338, critic_loss: 0.6351701617240906, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0017414505127817392, critic_loss: 0.6328166723251343, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.0017438553040847182, critic_loss: 0.6308335661888123, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.0017439292278140783, critic_loss: 0.6292298436164856, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.001743193599395454, critic_loss: 0.6279259920120239, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.0017422212986275554, critic_loss: 0.6267485022544861, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.0017409388674423099, critic_loss: 0.625537633895874, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.0017408686690032482, critic_loss: 0.6242055892944336, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.001742993132211268, critic_loss: 0.6227396726608276, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0017470538150519133, critic_loss: 0.6211813688278198, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.0017529312754049897, critic_loss: 0.6195970177650452, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.0017580989515408874, critic_loss: 0.6180503964424133, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.0017626037588343024, critic_loss: 0.6165866255760193, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.0017656948184594512, critic_loss: 0.6152406334877014, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.0017667134525254369, critic_loss: 0.6140298247337341, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.0017665057675912976, critic_loss: 0.6129427552223206, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.001765151508152485, critic_loss: 0.6119449138641357, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.0017646374180912971, critic_loss: 0.6110054850578308, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.001764667103998363, critic_loss: 0.6101111769676208, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.0017669486114755273, critic_loss: 0.6092613339424133, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.0017710808897390962, critic_loss: 0.6084524393081665, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.0017764866352081299, critic_loss: 0.6076651811599731, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.0017825427930802107, critic_loss: 0.6068711876869202, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.001788636203855276, critic_loss: 0.6060404777526855, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.00179466069675982, critic_loss: 0.6051510572433472, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.001800905680283904, critic_loss: 0.6041956543922424, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.001806457876227796, critic_loss: 0.6031883955001831, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.0018114405684173107, critic_loss: 0.6021662354469299, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.001815010909922421, critic_loss: 0.6011795997619629, entropy_bonus: -15.599142074584961\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.015028228051960468, critic_loss: 0.5223923325538635, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.015021655708551407, critic_loss: 0.5191765427589417, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.01502617821097374, critic_loss: 0.5150179862976074, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.015056799165904522, critic_loss: 0.5100943446159363, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.01505469623953104, critic_loss: 0.5045697689056396, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.015050619840621948, critic_loss: 0.4985150992870331, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.01507741678506136, critic_loss: 0.49203941226005554, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.01510182861238718, critic_loss: 0.4854450821876526, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.015107276849448681, critic_loss: 0.47904178500175476, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.01509878784418106, critic_loss: 0.47292330861091614, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.015105253085494041, critic_loss: 0.4670051336288452, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.01511095929890871, critic_loss: 0.4611659348011017, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.015112687833607197, critic_loss: 0.4553542733192444, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.01513273548334837, critic_loss: 0.44978970289230347, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.015153716318309307, critic_loss: 0.4449160695075989, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.015180040150880814, critic_loss: 0.44117429852485657, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.015205162577331066, critic_loss: 0.4386417865753174, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.015217304229736328, critic_loss: 0.4370214343070984, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.015236464329063892, critic_loss: 0.4359070956707001, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.015252511017024517, critic_loss: 0.4350144863128662, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.015270142816007137, critic_loss: 0.4342047870159149, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.015275781974196434, critic_loss: 0.4334375262260437, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.015281991101801395, critic_loss: 0.43273577094078064, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.01528557762503624, critic_loss: 0.4321518540382385, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.015281164087355137, critic_loss: 0.43174028396606445, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.01528122927993536, critic_loss: 0.43150490522384644, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.015283732675015926, critic_loss: 0.4314040541648865, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.015273462049663067, critic_loss: 0.43137601017951965, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.015263772569596767, critic_loss: 0.43137073516845703, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.01525500975549221, critic_loss: 0.43134817481040955, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.015254683792591095, critic_loss: 0.4312843680381775, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.015233473852276802, critic_loss: 0.4311683773994446, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.015225603245198727, critic_loss: 0.4309989809989929, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.015219221822917461, critic_loss: 0.4307801425457001, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.015213270671665668, critic_loss: 0.43052300810813904, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.015202481299638748, critic_loss: 0.4302402138710022, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.01519013475626707, critic_loss: 0.4299447238445282, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.015184087678790092, critic_loss: 0.4296501576900482, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.0151754729449749, critic_loss: 0.42936286330223083, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.015171336941421032, critic_loss: 0.42908889055252075, entropy_bonus: -15.518314361572266\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.012428722344338894, critic_loss: 0.5896458625793457, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.012427549809217453, critic_loss: 0.5857512950897217, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.012425876222550869, critic_loss: 0.5790247321128845, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.012462847866117954, critic_loss: 0.5703441500663757, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.012510803528130054, critic_loss: 0.5609469413757324, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.012522825971245766, critic_loss: 0.5514644384384155, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.012507345527410507, critic_loss: 0.5418436527252197, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.012545081786811352, critic_loss: 0.5325058698654175, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.012586881406605244, critic_loss: 0.5242161750793457, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.012608791701495647, critic_loss: 0.5177938342094421, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.012670734897255898, critic_loss: 0.5130438804626465, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.012680744752287865, critic_loss: 0.5091581344604492, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.012633521109819412, critic_loss: 0.5058338642120361, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.01267329789698124, critic_loss: 0.5028389692306519, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.012662465684115887, critic_loss: 0.4998971223831177, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.012609225697815418, critic_loss: 0.49665600061416626, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.012600394897162914, critic_loss: 0.4928702414035797, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.01261140312999487, critic_loss: 0.4886202812194824, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.012640606611967087, critic_loss: 0.48439785838127136, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.012637818232178688, critic_loss: 0.48070967197418213, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.012652060948312283, critic_loss: 0.4776005446910858, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.012683316133916378, critic_loss: 0.4749103784561157, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.012714558281004429, critic_loss: 0.47258779406547546, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.012719943188130856, critic_loss: 0.47071656584739685, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.012737516313791275, critic_loss: 0.4693067669868469, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.012747718021273613, critic_loss: 0.4682825207710266, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.012737346813082695, critic_loss: 0.4675838053226471, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.012720579281449318, critic_loss: 0.46713322401046753, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.012696774676442146, critic_loss: 0.4668310880661011, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.012693174183368683, critic_loss: 0.4665925204753876, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.012683788314461708, critic_loss: 0.4663574993610382, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.012663144618272781, critic_loss: 0.4660952687263489, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.012652714736759663, critic_loss: 0.4657963514328003, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.012640602886676788, critic_loss: 0.4654587507247925, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.012623980641365051, critic_loss: 0.46508538722991943, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.012609907425940037, critic_loss: 0.4646795094013214, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.012597237713634968, critic_loss: 0.46424737572669983, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.012580362148582935, critic_loss: 0.46379199624061584, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.0125627676025033, critic_loss: 0.4633183777332306, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.012546293437480927, critic_loss: 0.4628317654132843, entropy_bonus: -15.439088821411133\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.004981029778718948, critic_loss: 0.5494096875190735, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.004980397876352072, critic_loss: 0.546976625919342, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.004979700781404972, critic_loss: 0.5435913801193237, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.004992059897631407, critic_loss: 0.5393187403678894, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.0050127399154007435, critic_loss: 0.5343794822692871, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.005034984089434147, critic_loss: 0.5291584730148315, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.005060622934252024, critic_loss: 0.5239931344985962, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.00509245041757822, critic_loss: 0.5189332365989685, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.005118656437844038, critic_loss: 0.5137596726417542, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.005130859557539225, critic_loss: 0.5082075595855713, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.005134766921401024, critic_loss: 0.5021697282791138, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.005135607905685902, critic_loss: 0.4956617057323456, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.005138297565281391, critic_loss: 0.48878055810928345, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.005140621680766344, critic_loss: 0.4820600748062134, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.005138077773153782, critic_loss: 0.4762534499168396, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.005134713836014271, critic_loss: 0.471261203289032, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.0051392982713878155, critic_loss: 0.4669024348258972, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.0051465691067278385, critic_loss: 0.46321237087249756, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.005156736820936203, critic_loss: 0.4598284363746643, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.005169461481273174, critic_loss: 0.45649510622024536, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.005180037580430508, critic_loss: 0.4534591734409332, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.005188636016100645, critic_loss: 0.45107752084732056, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.005198488477617502, critic_loss: 0.44941967725753784, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.005204354878515005, critic_loss: 0.4483179748058319, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.005205846857279539, critic_loss: 0.44750916957855225, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.005208888556808233, critic_loss: 0.4468255937099457, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00520734628662467, critic_loss: 0.446214884519577, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.005200475919991732, critic_loss: 0.44566911458969116, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.005200923420488834, critic_loss: 0.4451889395713806, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00519768288359046, critic_loss: 0.4447687864303589, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.00519450893625617, critic_loss: 0.44440528750419617, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.005191957578063011, critic_loss: 0.44409382343292236, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.005192270502448082, critic_loss: 0.44383254647254944, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.005183322820812464, critic_loss: 0.44361695647239685, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.005170948337763548, critic_loss: 0.44343915581703186, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.005163697525858879, critic_loss: 0.44328969717025757, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.005158295389264822, critic_loss: 0.4431600570678711, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.005151497665792704, critic_loss: 0.44303998351097107, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.005144918337464333, critic_loss: 0.4429219365119934, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.005139907822012901, critic_loss: 0.44279947876930237, entropy_bonus: -15.361400604248047\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008537784218788147, critic_loss: 0.5386386513710022, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008531568571925163, critic_loss: 0.536125659942627, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008587409742176533, critic_loss: 0.5321202874183655, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008587772026658058, critic_loss: 0.5269573330879211, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008587806485593319, critic_loss: 0.5210542678833008, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008597593754529953, critic_loss: 0.5147750973701477, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008620047941803932, critic_loss: 0.5082316398620605, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.00867976900190115, critic_loss: 0.5013359785079956, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008720426820218563, critic_loss: 0.4940851926803589, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008726879954338074, critic_loss: 0.4866725206375122, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008737802505493164, critic_loss: 0.4793741703033447, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008758730255067348, critic_loss: 0.47244521975517273, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.00879414938390255, critic_loss: 0.4661431610584259, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.00891514215618372, critic_loss: 0.46075302362442017, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.00891257543116808, critic_loss: 0.45638465881347656, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008899823762476444, critic_loss: 0.4528193175792694, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008882696740329266, critic_loss: 0.44984763860702515, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.009009438566863537, critic_loss: 0.4473611116409302, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.00892150029540062, critic_loss: 0.4452972412109375, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00913293194025755, critic_loss: 0.4436206519603729, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008917453698813915, critic_loss: 0.44225549697875977, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.009012904949486256, critic_loss: 0.4410828948020935, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008976503275334835, critic_loss: 0.4400126338005066, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.008943483233451843, critic_loss: 0.43900108337402344, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.009052994661033154, critic_loss: 0.43802228569984436, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008992398157715797, critic_loss: 0.43707430362701416, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.008941401727497578, critic_loss: 0.4361727237701416, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.009026560932397842, critic_loss: 0.4353489279747009, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.009137623012065887, critic_loss: 0.43462538719177246, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008937944658100605, critic_loss: 0.4340115785598755, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.009150942787528038, critic_loss: 0.43348780274391174, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008895160630345345, critic_loss: 0.4330148994922638, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.0090602096170187, critic_loss: 0.4325639605522156, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008869443088769913, critic_loss: 0.43211716413497925, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008936703205108643, critic_loss: 0.4316619336605072, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.009032112546265125, critic_loss: 0.43120846152305603, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008904331363737583, critic_loss: 0.43077901005744934, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.009241484105587006, critic_loss: 0.43039003014564514, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.009134159423410892, critic_loss: 0.4300476312637329, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008967404253780842, critic_loss: 0.4297667443752289, entropy_bonus: -15.285194396972656\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008502302691340446, critic_loss: 0.5437458157539368, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008502657525241375, critic_loss: 0.5417621731758118, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008525899611413479, critic_loss: 0.5376152396202087, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008550367318093777, critic_loss: 0.5320481657981873, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008581624366343021, critic_loss: 0.5258133411407471, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008601834066212177, critic_loss: 0.5193842649459839, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008584770374000072, critic_loss: 0.5130327343940735, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008638166822493076, critic_loss: 0.5067659020423889, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008628961630165577, critic_loss: 0.5005373358726501, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.00869382917881012, critic_loss: 0.494404137134552, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008663143962621689, critic_loss: 0.4883945882320404, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.00869534257799387, critic_loss: 0.48252660036087036, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008730005472898483, critic_loss: 0.4769180417060852, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.00874351430684328, critic_loss: 0.47187337279319763, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.00877310335636139, critic_loss: 0.4676325023174286, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008786715567111969, critic_loss: 0.4641634225845337, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008817730471491814, critic_loss: 0.46125152707099915, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008849285542964935, critic_loss: 0.4587216079235077, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008857162669301033, critic_loss: 0.4565405547618866, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.008867437951266766, critic_loss: 0.4547232985496521, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008863288909196854, critic_loss: 0.4532083570957184, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008867939002811909, critic_loss: 0.4518650472164154, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.00887120421975851, critic_loss: 0.4505597651004791, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.00887817982584238, critic_loss: 0.4492325484752655, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.00886896438896656, critic_loss: 0.4479536712169647, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008875489234924316, critic_loss: 0.4468664526939392, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.008853264153003693, critic_loss: 0.4460510313510895, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008852125145494938, critic_loss: 0.44547921419143677, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008842780254781246, critic_loss: 0.44506967067718506, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008835089392960072, critic_loss: 0.44473889470100403, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008822215721011162, critic_loss: 0.4444141685962677, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.00881865806877613, critic_loss: 0.4440387785434723, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008807532489299774, critic_loss: 0.44357627630233765, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008805773220956326, critic_loss: 0.4430112838745117, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008799544535577297, critic_loss: 0.44234004616737366, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008787555620074272, critic_loss: 0.44158223271369934, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.0088249072432518, critic_loss: 0.44077953696250916, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.00877641886472702, critic_loss: 0.43998831510543823, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008802825585007668, critic_loss: 0.4392696022987366, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008783306926488876, critic_loss: 0.43865612149238586, entropy_bonus: -15.210411071777344\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007714791223406792, critic_loss: 0.5794032216072083, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.007712886668741703, critic_loss: 0.5761878490447998, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.007707295939326286, critic_loss: 0.571159303188324, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.007749094627797604, critic_loss: 0.564969539642334, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.007734742481261492, critic_loss: 0.5583612322807312, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.007787636481225491, critic_loss: 0.5519025325775146, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.007869839668273926, critic_loss: 0.5459142327308655, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.007875802926719189, critic_loss: 0.5404757857322693, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.007931387051939964, critic_loss: 0.5354738831520081, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.007971733808517456, critic_loss: 0.5307971239089966, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.007982037030160427, critic_loss: 0.5263200402259827, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008012929931282997, critic_loss: 0.5218190550804138, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.007999241352081299, critic_loss: 0.5172604918479919, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.00803842768073082, critic_loss: 0.5129896402359009, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008015397936105728, critic_loss: 0.5093508362770081, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008039699867367744, critic_loss: 0.5064661502838135, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008035537786781788, critic_loss: 0.5044399499893188, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008074858225882053, critic_loss: 0.5031421780586243, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.00805320218205452, critic_loss: 0.5022198557853699, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.008097299374639988, critic_loss: 0.5013885498046875, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008053313009440899, critic_loss: 0.5005508661270142, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008056307211518288, critic_loss: 0.4997308850288391, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008050483651459217, critic_loss: 0.49895697832107544, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.008053682744503021, critic_loss: 0.49822402000427246, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008081437088549137, critic_loss: 0.49748846888542175, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008100723847746849, critic_loss: 0.49667468667030334, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.008102976717054844, critic_loss: 0.49570968747138977, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.00811191275715828, critic_loss: 0.4945576786994934, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008144174702465534, critic_loss: 0.4932368993759155, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00810313317924738, critic_loss: 0.4918209910392761, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008125138469040394, critic_loss: 0.49039092659950256, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.00810747779905796, critic_loss: 0.48899391293525696, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008083527907729149, critic_loss: 0.4876599907875061, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008122184313833714, critic_loss: 0.48641255497932434, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008114799857139587, critic_loss: 0.4852786064147949, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.00813984777778387, critic_loss: 0.48428651690483093, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008096770383417606, critic_loss: 0.48342180252075195, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008079207502305508, critic_loss: 0.48265689611434937, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008074621669948101, critic_loss: 0.4819484055042267, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.00808954332023859, critic_loss: 0.4812632203102112, entropy_bonus: -15.137001037597656\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008107434958219528, critic_loss: 0.5672601461410522, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.00810764729976654, critic_loss: 0.5638505816459656, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008125759661197662, critic_loss: 0.5591834783554077, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008118483237922192, critic_loss: 0.5540779829025269, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008106458932161331, critic_loss: 0.5491054654121399, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008111782371997833, critic_loss: 0.5442708134651184, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008131169714033604, critic_loss: 0.5393287539482117, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008136102929711342, critic_loss: 0.5339196920394897, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008145133964717388, critic_loss: 0.5277185440063477, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008179280906915665, critic_loss: 0.5208145380020142, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008228150196373463, critic_loss: 0.5141534209251404, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008276712149381638, critic_loss: 0.5086814165115356, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008327390067279339, critic_loss: 0.5044520497322083, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008357591927051544, critic_loss: 0.5008659362792969, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008385611698031425, critic_loss: 0.4971623718738556, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008433708921074867, critic_loss: 0.4928149878978729, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008475183509290218, critic_loss: 0.4872761368751526, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008516748435795307, critic_loss: 0.48002874851226807, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008557077497243881, critic_loss: 0.4720575511455536, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.008600147441029549, critic_loss: 0.46566587686538696, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008641877211630344, critic_loss: 0.46102476119995117, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008678673766553402, critic_loss: 0.4571726620197296, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008709384128451347, critic_loss: 0.45423611998558044, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.008734804578125477, critic_loss: 0.45178043842315674, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008739549666643143, critic_loss: 0.44953885674476624, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.00875835120677948, critic_loss: 0.4472145140171051, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.008762792684137821, critic_loss: 0.44495889544487, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008768795989453793, critic_loss: 0.4433017671108246, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008761652745306492, critic_loss: 0.44239819049835205, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00875679962337017, critic_loss: 0.4418705403804779, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.00875821802765131, critic_loss: 0.4413759112358093, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008756428956985474, critic_loss: 0.44076716899871826, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008745408616960049, critic_loss: 0.44000759720802307, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008731815963983536, critic_loss: 0.4391467571258545, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.00872094463557005, critic_loss: 0.43833231925964355, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008715611882507801, critic_loss: 0.4377345144748688, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008704815991222858, critic_loss: 0.4373924136161804, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008692963980138302, critic_loss: 0.437204509973526, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008683799766004086, critic_loss: 0.43705710768699646, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008662231266498566, critic_loss: 0.4368947148323059, entropy_bonus: -15.06491470336914\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007887471467256546, critic_loss: 0.5801823139190674, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.007898721843957901, critic_loss: 0.5762410163879395, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.007883886806666851, critic_loss: 0.5710253119468689, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.007952641695737839, critic_loss: 0.564984142780304, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.007967490702867508, critic_loss: 0.558613121509552, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.007896386086940765, critic_loss: 0.5525259375572205, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.007898029871284962, critic_loss: 0.5468993186950684, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.007914956659078598, critic_loss: 0.5415120124816895, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.007949775084853172, critic_loss: 0.5362569093704224, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.007952773943543434, critic_loss: 0.5310229063034058, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.007943330332636833, critic_loss: 0.5255675315856934, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.007972159422934055, critic_loss: 0.5200706720352173, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.00797408726066351, critic_loss: 0.5151799321174622, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008002471178770065, critic_loss: 0.511049211025238, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008045213297009468, critic_loss: 0.5075374245643616, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008073185570538044, critic_loss: 0.5045890808105469, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008096262812614441, critic_loss: 0.5019756555557251, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008129946887493134, critic_loss: 0.4993298053741455, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008172270841896534, critic_loss: 0.49635055661201477, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00820031575858593, critic_loss: 0.49300938844680786, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.00823892466723919, critic_loss: 0.48982954025268555, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008317998610436916, critic_loss: 0.4875165522098541, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008330843411386013, critic_loss: 0.48587504029273987, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.008328366093337536, critic_loss: 0.48435842990875244, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008347718976438046, critic_loss: 0.48271262645721436, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008358107879757881, critic_loss: 0.4808904528617859, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00836943555623293, critic_loss: 0.4789394736289978, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008394766598939896, critic_loss: 0.47696664929389954, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008398294448852539, critic_loss: 0.4750617444515228, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008440408855676651, critic_loss: 0.4733046591281891, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008434887044131756, critic_loss: 0.47175997495651245, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008422876708209515, critic_loss: 0.47045084834098816, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.00842129997909069, critic_loss: 0.4693339765071869, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008409836329519749, critic_loss: 0.468342125415802, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008391940966248512, critic_loss: 0.4674033522605896, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008369311690330505, critic_loss: 0.4664512276649475, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008358919061720371, critic_loss: 0.4654287099838257, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008367130532860756, critic_loss: 0.4642969071865082, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008359256200492382, critic_loss: 0.46307867765426636, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008329201489686966, critic_loss: 0.4618895351886749, entropy_bonus: -14.994104385375977\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.010560880415141582, critic_loss: 0.5641752481460571, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.010560783557593822, critic_loss: 0.561902642250061, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.010560107417404652, critic_loss: 0.5579286217689514, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.010558873414993286, critic_loss: 0.552139163017273, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.01056121475994587, critic_loss: 0.5443465709686279, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.010581538081169128, critic_loss: 0.5349056720733643, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.01061058696359396, critic_loss: 0.5247257351875305, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.010671500116586685, critic_loss: 0.5142525434494019, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.01074624340981245, critic_loss: 0.5056889653205872, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.01081439945846796, critic_loss: 0.4999523460865021, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.010873522609472275, critic_loss: 0.4945058226585388, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.01093250885605812, critic_loss: 0.4891766309738159, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.010961771011352539, critic_loss: 0.48486772179603577, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.01100021880120039, critic_loss: 0.48156431317329407, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.011007437482476234, critic_loss: 0.4790308475494385, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.011058563366532326, critic_loss: 0.476686954498291, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.011038844473659992, critic_loss: 0.47428905963897705, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.011048696003854275, critic_loss: 0.4718891382217407, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.011066687293350697, critic_loss: 0.4696662724018097, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.011063876561820507, critic_loss: 0.4677676558494568, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.01107817143201828, critic_loss: 0.46621599793434143, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.011060092598199844, critic_loss: 0.4649261236190796, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.011074058711528778, critic_loss: 0.4638049304485321, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.011056208051741123, critic_loss: 0.4627813994884491, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.011039312928915024, critic_loss: 0.4617880880832672, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.011025012470781803, critic_loss: 0.4607643783092499, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.010983532294631004, critic_loss: 0.4596708416938782, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.01096629910171032, critic_loss: 0.45849549770355225, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.01094274315983057, critic_loss: 0.45724719762802124, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.010927947238087654, critic_loss: 0.45593151450157166, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.010914810933172703, critic_loss: 0.45458513498306274, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.010898971930146217, critic_loss: 0.45323747396469116, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.01088640559464693, critic_loss: 0.45191308856010437, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.010875530540943146, critic_loss: 0.45063140988349915, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.010860206559300423, critic_loss: 0.449405312538147, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.010850029066205025, critic_loss: 0.44824716448783875, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.010840967297554016, critic_loss: 0.4471765160560608, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.010839189402759075, critic_loss: 0.4462215304374695, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.010826977901160717, critic_loss: 0.4454011619091034, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.010837078094482422, critic_loss: 0.44470974802970886, entropy_bonus: -14.924524307250977\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.009341479279100895, critic_loss: 0.5627780556678772, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.00934353843331337, critic_loss: 0.5584609508514404, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.009344397112727165, critic_loss: 0.5512909293174744, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.00934423878788948, critic_loss: 0.5421460270881653, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.009344585239887238, critic_loss: 0.5316198468208313, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.00934314914047718, critic_loss: 0.5200161337852478, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.009342748671770096, critic_loss: 0.5091087222099304, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.00935978814959526, critic_loss: 0.5013296008110046, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.009378515183925629, critic_loss: 0.49547168612480164, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.009398641996085644, critic_loss: 0.4904833436012268, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.009423308074474335, critic_loss: 0.486440509557724, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.009447447024285793, critic_loss: 0.4828642010688782, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.009464642032980919, critic_loss: 0.4789492189884186, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.009477713145315647, critic_loss: 0.4743505120277405, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.009497487917542458, critic_loss: 0.46939176321029663, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.009512994438409805, critic_loss: 0.46440887451171875, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.009527497924864292, critic_loss: 0.4592892825603485, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.009535354562103748, critic_loss: 0.454239159822464, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.009540997445583344, critic_loss: 0.4501281678676605, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.009545394219458103, critic_loss: 0.4474020302295685, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.009544987231492996, critic_loss: 0.4455973207950592, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.009540094062685966, critic_loss: 0.44431787729263306, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.009532644413411617, critic_loss: 0.44343534111976624, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.009527471847832203, critic_loss: 0.44279101490974426, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.00952245108783245, critic_loss: 0.44220954179763794, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.009517980739474297, critic_loss: 0.44159385561943054, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.009513027034699917, critic_loss: 0.44092270731925964, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.009505470283329487, critic_loss: 0.44020822644233704, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.00949789583683014, critic_loss: 0.43949174880981445, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.009494617581367493, critic_loss: 0.438848078250885, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.009493371471762657, critic_loss: 0.4383333921432495, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.00949518196284771, critic_loss: 0.43797728419303894, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.009497260674834251, critic_loss: 0.4377591013908386, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.009498809464275837, critic_loss: 0.4376283586025238, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.009499939158558846, critic_loss: 0.43753954768180847, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.009500863030552864, critic_loss: 0.4374620020389557, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.009498805738985538, critic_loss: 0.4373793303966522, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.00949516799300909, critic_loss: 0.43728336691856384, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.009489516727626324, critic_loss: 0.4371722936630249, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.009486361406743526, critic_loss: 0.43704766035079956, entropy_bonus: -14.856134414672852\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008133878000080585, critic_loss: 0.5494706034660339, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008135458454489708, critic_loss: 0.5458536148071289, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.00813659094274044, critic_loss: 0.5402011871337891, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008137967437505722, critic_loss: 0.5325192809104919, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008156788535416126, critic_loss: 0.5235875844955444, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008168433792889118, critic_loss: 0.5148279666900635, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008185233920812607, critic_loss: 0.5070745944976807, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008207295089960098, critic_loss: 0.5003854036331177, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008227200247347355, critic_loss: 0.4944867789745331, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008244234137237072, critic_loss: 0.48893287777900696, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008269915357232094, critic_loss: 0.4835202097892761, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008297253400087357, critic_loss: 0.4781821668148041, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.00832626223564148, critic_loss: 0.4727432429790497, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.00835511926561594, critic_loss: 0.4670686721801758, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008375153876841068, critic_loss: 0.4612199366092682, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008408171124756336, critic_loss: 0.4555169939994812, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.00843895971775055, critic_loss: 0.4500768184661865, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008447347208857536, critic_loss: 0.44488051533699036, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008450211957097054, critic_loss: 0.44020938873291016, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00845736637711525, critic_loss: 0.4368376135826111, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008463981561362743, critic_loss: 0.43509089946746826, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008465949445962906, critic_loss: 0.43450573086738586, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008463706821203232, critic_loss: 0.43434828519821167, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.00845331884920597, critic_loss: 0.43433406949043274, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008446344174444675, critic_loss: 0.43435266613960266, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.00843167956918478, critic_loss: 0.4342890679836273, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.008419687859714031, critic_loss: 0.43409785628318787, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008412154391407967, critic_loss: 0.43380045890808105, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008405538275837898, critic_loss: 0.43344345688819885, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008394512347877026, critic_loss: 0.43307313323020935, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008381325751543045, critic_loss: 0.4327244162559509, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008380454033613205, critic_loss: 0.43241751194000244, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008376037701964378, critic_loss: 0.43215543031692505, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008380032144486904, critic_loss: 0.43192851543426514, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.00837661512196064, critic_loss: 0.4317205846309662, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008366717956960201, critic_loss: 0.4315139949321747, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008356590755283833, critic_loss: 0.4312911629676819, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008344847708940506, critic_loss: 0.4310399293899536, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008329500444233418, critic_loss: 0.4307548999786377, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008323620073497295, critic_loss: 0.4304441511631012, entropy_bonus: -14.788894653320312\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008144715800881386, critic_loss: 0.5475261807441711, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008143066428601742, critic_loss: 0.5467119812965393, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008140445686876774, critic_loss: 0.5445834398269653, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.00813915953040123, critic_loss: 0.5412377119064331, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.00814588088542223, critic_loss: 0.5368195176124573, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008152764290571213, critic_loss: 0.5315212607383728, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008165362291038036, critic_loss: 0.5255695581436157, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008191607892513275, critic_loss: 0.5191830992698669, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008224975317716599, critic_loss: 0.5125541687011719, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008254817686975002, critic_loss: 0.505882978439331, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008279252797365189, critic_loss: 0.4994256794452667, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008295361883938313, critic_loss: 0.4933655858039856, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008313320577144623, critic_loss: 0.48744097352027893, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008326972834765911, critic_loss: 0.4812624752521515, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008334155194461346, critic_loss: 0.4748770296573639, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008336937986314297, critic_loss: 0.4691906273365021, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008333609439432621, critic_loss: 0.46493667364120483, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008333415724337101, critic_loss: 0.46218469738960266, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008334694430232048, critic_loss: 0.4605432152748108, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.008330585435032845, critic_loss: 0.45939984917640686, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008328297175467014, critic_loss: 0.458396315574646, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.00833027996122837, critic_loss: 0.45748186111450195, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.00832823384553194, critic_loss: 0.4566999673843384, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.008332744240760803, critic_loss: 0.4560783803462982, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008341830223798752, critic_loss: 0.45560333132743835, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008348922245204449, critic_loss: 0.45522886514663696, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.008350800722837448, critic_loss: 0.45491740107536316, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008351033553481102, critic_loss: 0.45463457703590393, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008349122479557991, critic_loss: 0.45435601472854614, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00834069773554802, critic_loss: 0.45406025648117065, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008333312347531319, critic_loss: 0.4537373185157776, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008322606794536114, critic_loss: 0.4533843994140625, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008308453485369682, critic_loss: 0.4530008137226105, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008294684812426567, critic_loss: 0.45258745551109314, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008282697759568691, critic_loss: 0.45214590430259705, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008263924159109592, critic_loss: 0.4516787827014923, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.00825163908302784, critic_loss: 0.4511896073818207, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008245086297392845, critic_loss: 0.45068711042404175, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008232779800891876, critic_loss: 0.4501805305480957, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008221827447414398, critic_loss: 0.4496825635433197, entropy_bonus: -14.722766876220703\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007293452508747578, critic_loss: 0.5398095846176147, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.007292254362255335, critic_loss: 0.5386186838150024, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.0072923945263028145, critic_loss: 0.5353654026985168, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.007300732657313347, critic_loss: 0.5304141640663147, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.007296335883438587, critic_loss: 0.5241105556488037, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.0072851842269301414, critic_loss: 0.5167257785797119, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.007293388247489929, critic_loss: 0.5084563493728638, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.007309387903660536, critic_loss: 0.4996132254600525, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.007340769283473492, critic_loss: 0.4909050762653351, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.007383126765489578, critic_loss: 0.48330289125442505, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.007413542363792658, critic_loss: 0.4772585332393646, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.007429685443639755, critic_loss: 0.472535103559494, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.007439123932272196, critic_loss: 0.4687216579914093, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.007446673698723316, critic_loss: 0.4655693769454956, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.007445750292390585, critic_loss: 0.4630528688430786, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.007431604899466038, critic_loss: 0.4612066447734833, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.007424161769449711, critic_loss: 0.459926962852478, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.00739680789411068, critic_loss: 0.45892825722694397, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.007385327015072107, critic_loss: 0.45785918831825256, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.007370869163423777, critic_loss: 0.4564272463321686, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.007358843926340342, critic_loss: 0.45448413491249084, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.007350776810199022, critic_loss: 0.45210978388786316, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.007345442660152912, critic_loss: 0.44959181547164917, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.007345177698880434, critic_loss: 0.4472452998161316, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.00735045550391078, critic_loss: 0.44522568583488464, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.007361925207078457, critic_loss: 0.4437209963798523, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.007367176003754139, critic_loss: 0.442704975605011, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.007379565387964249, critic_loss: 0.44199323654174805, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.00737610412761569, critic_loss: 0.44156038761138916, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.007377949543297291, critic_loss: 0.4413846731185913, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.007376772817224264, critic_loss: 0.441376268863678, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.007373680826276541, critic_loss: 0.4414328336715698, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.007367794401943684, critic_loss: 0.4414803981781006, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.007362990640103817, critic_loss: 0.44148150086402893, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.007359929382801056, critic_loss: 0.4414274990558624, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.007356678135693073, critic_loss: 0.4413236975669861, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.007347108796238899, critic_loss: 0.44118285179138184, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.007349187508225441, critic_loss: 0.4410196542739868, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.007334630470722914, critic_loss: 0.44084665179252625, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.007337914779782295, critic_loss: 0.4406728148460388, entropy_bonus: -14.65771484375\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00983490701764822, critic_loss: 0.5712189674377441, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.009832468815147877, critic_loss: 0.5700889825820923, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.009826925583183765, critic_loss: 0.5681976675987244, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.009823620319366455, critic_loss: 0.5657395720481873, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.009831063449382782, critic_loss: 0.5628934502601624, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.009823594242334366, critic_loss: 0.5597769021987915, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.009825214743614197, critic_loss: 0.5564165711402893, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.009830990806221962, critic_loss: 0.5527587532997131, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.009833643212914467, critic_loss: 0.5487501621246338, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.009838135913014412, critic_loss: 0.544445276260376, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.009853479452431202, critic_loss: 0.5400594472885132, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.009867124259471893, critic_loss: 0.5358443260192871, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.009877546690404415, critic_loss: 0.5319654941558838, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.00988673698157072, critic_loss: 0.5284925103187561, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.009899545460939407, critic_loss: 0.525405764579773, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.009905013255774975, critic_loss: 0.52260422706604, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.009910057298839092, critic_loss: 0.5199481248855591, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.009909975342452526, critic_loss: 0.5173259377479553, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.009909581393003464, critic_loss: 0.5147277116775513, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.009908494539558887, critic_loss: 0.5122727155685425, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.009905240498483181, critic_loss: 0.5101125240325928, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.009900834411382675, critic_loss: 0.5083059072494507, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.009898842312395573, critic_loss: 0.5068044662475586, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.009893588721752167, critic_loss: 0.5055009722709656, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.009886572137475014, critic_loss: 0.5042749047279358, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.00988355278968811, critic_loss: 0.5030147433280945, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.009880444966256618, critic_loss: 0.5016326904296875, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.009877895005047321, critic_loss: 0.5000801086425781, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.009875952266156673, critic_loss: 0.49836796522140503, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00987519696354866, critic_loss: 0.49657949805259705, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.009874493815004826, critic_loss: 0.4948559105396271, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.0098700150847435, critic_loss: 0.4933532178401947, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.009868351742625237, critic_loss: 0.4921591281890869, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.00986102782189846, critic_loss: 0.49127197265625, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.009866159409284592, critic_loss: 0.490620493888855, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.00986823532730341, critic_loss: 0.49011945724487305, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.009868149645626545, critic_loss: 0.4896911382675171, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.009863939136266708, critic_loss: 0.48928284645080566, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.009869829751551151, critic_loss: 0.48888060450553894, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.009868926368653774, critic_loss: 0.4884941279888153, entropy_bonus: -14.59370231628418\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00010106116678798571, critic_loss: 0.9635108709335327, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.00010106004629051313, critic_loss: 0.9599550366401672, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.00010123151878360659, critic_loss: 0.9526537656784058, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.00010246557940263301, critic_loss: 0.9440454244613647, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.00010512969311093912, critic_loss: 0.9372994899749756, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.00010974542965414003, critic_loss: 0.9333814978599548, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.00011462910333648324, critic_loss: 0.9312126040458679, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.00011941064440179616, critic_loss: 0.9296318292617798, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.00012377572420518845, critic_loss: 0.9278855323791504, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.00012764275015797466, critic_loss: 0.9255243539810181, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.00013098104682285339, critic_loss: 0.9221726059913635, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.00013366472558118403, critic_loss: 0.9177508354187012, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.00013572552416007966, critic_loss: 0.9128808975219727, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.00013698310067411512, critic_loss: 0.9089167714118958, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.000137009410536848, critic_loss: 0.9067081809043884, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.0001355688727926463, critic_loss: 0.905700147151947, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.00013283878797665238, critic_loss: 0.9048015475273132, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.00012879521818831563, critic_loss: 0.9032981395721436, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.0001239341654581949, critic_loss: 0.9008786082267761, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00011859234655275941, critic_loss: 0.897565484046936, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.00011347955296514556, critic_loss: 0.8938489556312561, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.00010978493810398504, critic_loss: 0.8905776143074036, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.00010738600394688547, critic_loss: 0.8883810043334961, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.00010620268585626036, critic_loss: 0.8871625065803528, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.00010714094241848215, critic_loss: 0.8865057826042175, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.00010865687363548204, critic_loss: 0.8861016631126404, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00011088332394137979, critic_loss: 0.8857917785644531, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.00011288106179563329, critic_loss: 0.8855046033859253, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.00011475668725324795, critic_loss: 0.885210394859314, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00011622926831478253, critic_loss: 0.8849017024040222, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.000117298994155135, critic_loss: 0.8845826387405396, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.0001180862236651592, critic_loss: 0.8842608332633972, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.00011861074017360806, critic_loss: 0.8839460015296936, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.00011890182213392109, critic_loss: 0.8836482167243958, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.00011891566100530326, critic_loss: 0.8833740949630737, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.00011867365537909791, critic_loss: 0.8831247091293335, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.00011823643581010401, critic_loss: 0.8829009532928467, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.00011763354268623516, critic_loss: 0.8827019929885864, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.0001168646413134411, critic_loss: 0.8825262784957886, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.00011595355317695066, critic_loss: 0.8823708295822144, entropy_bonus: -14.530698776245117\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.012096266262233257, critic_loss: 0.5946720242500305, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.012096756137907505, critic_loss: 0.591587483882904, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.012095417827367783, critic_loss: 0.5860433578491211, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.01209541317075491, critic_loss: 0.5783990621566772, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.012097757309675217, critic_loss: 0.5692779421806335, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.01209407951682806, critic_loss: 0.5593165159225464, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.012088567018508911, critic_loss: 0.5490143895149231, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.012090960517525673, critic_loss: 0.5386727452278137, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.012110177427530289, critic_loss: 0.5282682776451111, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.012133755721151829, critic_loss: 0.5190102458000183, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.012157347984611988, critic_loss: 0.5117589831352234, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.01217701006680727, critic_loss: 0.5055864453315735, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.012198029085993767, critic_loss: 0.4998493790626526, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.01222156174480915, critic_loss: 0.4941999912261963, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.012233933433890343, critic_loss: 0.4890006184577942, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.012240937910974026, critic_loss: 0.4850657880306244, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.012254944071173668, critic_loss: 0.48236870765686035, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.012264642864465714, critic_loss: 0.4805125594139099, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.01227440033107996, critic_loss: 0.4792425334453583, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.012283620424568653, critic_loss: 0.4783889651298523, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.01229126937687397, critic_loss: 0.47791802883148193, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.012296480126678944, critic_loss: 0.4778249263763428, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.012303262017667294, critic_loss: 0.4780164062976837, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.012299222871661186, critic_loss: 0.478320449590683, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.012297350913286209, critic_loss: 0.4785757064819336, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.012291524559259415, critic_loss: 0.47867560386657715, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.012286118231713772, critic_loss: 0.4785757064819336, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.012275892309844494, critic_loss: 0.4782769978046417, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.012265235185623169, critic_loss: 0.4778068959712982, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.012257681228220463, critic_loss: 0.4772096872329712, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.012247166596353054, critic_loss: 0.4765302836894989, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.01223782915621996, critic_loss: 0.47581079602241516, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.01222517341375351, critic_loss: 0.4750908315181732, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.012215969152748585, critic_loss: 0.4743986427783966, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.012202057056128979, critic_loss: 0.4737617075443268, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.012189481407403946, critic_loss: 0.47319385409355164, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.012173891067504883, critic_loss: 0.4726967215538025, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.012157689779996872, critic_loss: 0.47226187586784363, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.012143862433731556, critic_loss: 0.47187474370002747, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.012133749201893806, critic_loss: 0.4715152382850647, entropy_bonus: -14.468673706054688\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.011542612686753273, critic_loss: 0.5255880951881409, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.011539898812770844, critic_loss: 0.5236579179763794, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.011544397100806236, critic_loss: 0.5196092128753662, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.011540036648511887, critic_loss: 0.5139794945716858, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.011535177938640118, critic_loss: 0.5073680281639099, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.011533306911587715, critic_loss: 0.5004100203514099, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0115426080301404, critic_loss: 0.49410757422447205, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.011545494198799133, critic_loss: 0.4893310070037842, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.01157546229660511, critic_loss: 0.48589378595352173, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.011569092981517315, critic_loss: 0.48311713337898254, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.011602872051298618, critic_loss: 0.48083820939064026, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.011595534160733223, critic_loss: 0.4791727662086487, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.011631133034825325, critic_loss: 0.47797656059265137, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.01162079069763422, critic_loss: 0.4769776165485382, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.011628182604908943, critic_loss: 0.47602328658103943, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.011647307313978672, critic_loss: 0.47501543164253235, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.011642489582300186, critic_loss: 0.47383856773376465, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.011642612516880035, critic_loss: 0.47234344482421875, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.011643891222774982, critic_loss: 0.47034499049186707, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.011647094041109085, critic_loss: 0.4676170349121094, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.011653686873614788, critic_loss: 0.46399518847465515, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.011638633906841278, critic_loss: 0.45965105295181274, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.011637981049716473, critic_loss: 0.4552488327026367, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.011639902368187904, critic_loss: 0.45134150981903076, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.011632989160716534, critic_loss: 0.4480878412723541, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.011622443795204163, critic_loss: 0.4454609453678131, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.011616871692240238, critic_loss: 0.44322270154953003, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.011607740074396133, critic_loss: 0.44114646315574646, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.011608641594648361, critic_loss: 0.4391250014305115, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.011606323532760143, critic_loss: 0.4373232424259186, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.011603501625359058, critic_loss: 0.436024934053421, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.01160662341862917, critic_loss: 0.4352644979953766, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.011591695249080658, critic_loss: 0.4349043369293213, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.011587175540626049, critic_loss: 0.4348105192184448, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.0115831783041358, critic_loss: 0.43484169244766235, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.011582345701754093, critic_loss: 0.43485143780708313, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.011574986390769482, critic_loss: 0.43472957611083984, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.01158225629478693, critic_loss: 0.4344235360622406, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.011572075076401234, critic_loss: 0.43394187092781067, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.01158418320119381, critic_loss: 0.43335649371147156, entropy_bonus: -14.407594680786133\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.011976441368460655, critic_loss: 0.5901398062705994, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.01196229923516512, critic_loss: 0.5828339457511902, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.011977371759712696, critic_loss: 0.5730560421943665, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.011994833126664162, critic_loss: 0.5620840787887573, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.012096253223717213, critic_loss: 0.5507456064224243, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.012185894884169102, critic_loss: 0.5392189025878906, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.012211873196065426, critic_loss: 0.5274004936218262, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.012251622974872589, critic_loss: 0.516194760799408, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.012306176126003265, critic_loss: 0.5070791244506836, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.012224381789565086, critic_loss: 0.49996787309646606, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.012173336930572987, critic_loss: 0.4941103756427765, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.01215131301432848, critic_loss: 0.48892346024513245, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.012167486362159252, critic_loss: 0.4843653440475464, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.012181857600808144, critic_loss: 0.4805392920970917, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.012201689183712006, critic_loss: 0.4773828685283661, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.012234779074788094, critic_loss: 0.47487613558769226, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.012276967987418175, critic_loss: 0.47302335500717163, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.012177172116935253, critic_loss: 0.4717264771461487, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.012221953831613064, critic_loss: 0.47078657150268555, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.012261680327355862, critic_loss: 0.470111221075058, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.012131866998970509, critic_loss: 0.46971267461776733, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.012294666841626167, critic_loss: 0.469573438167572, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.012208957225084305, critic_loss: 0.4696189761161804, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.012238229624927044, critic_loss: 0.46977129578590393, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.012208164669573307, critic_loss: 0.46995019912719727, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.012084784917533398, critic_loss: 0.4700947105884552, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.012163743376731873, critic_loss: 0.4701751172542572, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.01208803802728653, critic_loss: 0.47017571330070496, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.012136872857809067, critic_loss: 0.4700908362865448, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.012095659039914608, critic_loss: 0.4699191451072693, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.01210661232471466, critic_loss: 0.46966812014579773, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.012091581709682941, critic_loss: 0.4693484902381897, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.012044855393469334, critic_loss: 0.4689723253250122, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.0120390010997653, critic_loss: 0.46855586767196655, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.012046818621456623, critic_loss: 0.46811702847480774, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.012037119828164577, critic_loss: 0.4676610827445984, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.012037815526127815, critic_loss: 0.46719929575920105, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.012089689262211323, critic_loss: 0.4667433202266693, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.012035636231303215, critic_loss: 0.46630722284317017, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.012111582793295383, critic_loss: 0.46589165925979614, entropy_bonus: -14.347433090209961\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.005472222808748484, critic_loss: 0.5400763154029846, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.005517465993762016, critic_loss: 0.5399017333984375, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.005573843140155077, critic_loss: 0.5380256175994873, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.005508715752512217, critic_loss: 0.5347381830215454, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.0055092270486056805, critic_loss: 0.53047114610672, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.005603369325399399, critic_loss: 0.5256701707839966, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0056647202000021935, critic_loss: 0.520574152469635, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.005650833249092102, critic_loss: 0.5150768160820007, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.0055998703464865685, critic_loss: 0.5090000629425049, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.005590353161096573, critic_loss: 0.5024272203445435, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.005613704212009907, critic_loss: 0.4957388937473297, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.005594142712652683, critic_loss: 0.4895523488521576, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.0055658272467553616, critic_loss: 0.48431283235549927, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.005622898228466511, critic_loss: 0.4798188805580139, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.005639986600726843, critic_loss: 0.4757925570011139, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.005619768053293228, critic_loss: 0.4721297323703766, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.005622632801532745, critic_loss: 0.4687686562538147, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.005633427761495113, critic_loss: 0.46567779779434204, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.005619828123599291, critic_loss: 0.46279850602149963, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.005616307258605957, critic_loss: 0.46017128229141235, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.005620711483061314, critic_loss: 0.4580075144767761, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.005617485381662846, critic_loss: 0.45640844106674194, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.005620190873742104, critic_loss: 0.4553014934062958, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.005626785568892956, critic_loss: 0.4545707702636719, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.005624930839985609, critic_loss: 0.454109787940979, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.005620614625513554, critic_loss: 0.4538365304470062, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.005621245596557856, critic_loss: 0.45368486642837524, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.005619933363050222, critic_loss: 0.4536029100418091, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.005619000177830458, critic_loss: 0.453553706407547, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.005610954947769642, critic_loss: 0.45351341366767883, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.005611162167042494, critic_loss: 0.45346611738204956, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.005619741976261139, critic_loss: 0.45340344309806824, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.005620731506496668, critic_loss: 0.4533202648162842, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.005614288151264191, critic_loss: 0.4532146453857422, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.00560472859069705, critic_loss: 0.45308637619018555, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.00560900429263711, critic_loss: 0.45293697714805603, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.005607545841485262, critic_loss: 0.45276761054992676, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.005596396513283253, critic_loss: 0.452581524848938, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.005592330824583769, critic_loss: 0.4523797929286957, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.0055948300287127495, critic_loss: 0.4521675705909729, entropy_bonus: -14.288164138793945\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007276379968971014, critic_loss: 0.5108245611190796, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0072744763456285, critic_loss: 0.5093829035758972, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.007274675648659468, critic_loss: 0.5069011449813843, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.007274873089045286, critic_loss: 0.5036364793777466, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.0072713796980679035, critic_loss: 0.49979209899902344, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.0072751701809465885, critic_loss: 0.49545222520828247, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.007295458111912012, critic_loss: 0.4906257092952728, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.007317875511944294, critic_loss: 0.48535168170928955, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.007335844915360212, critic_loss: 0.48002082109451294, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.007351155858486891, critic_loss: 0.47520312666893005, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.007374211680144072, critic_loss: 0.471181184053421, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.007397936191409826, critic_loss: 0.4677184224128723, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.007414471358060837, critic_loss: 0.4644486606121063, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.007419808767735958, critic_loss: 0.4611321687698364, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.007412084843963385, critic_loss: 0.45775365829467773, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.007408993784338236, critic_loss: 0.45447489619255066, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.007383229210972786, critic_loss: 0.45147207379341125, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.007373361848294735, critic_loss: 0.4488694369792938, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.007366620469838381, critic_loss: 0.44668734073638916, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.007357520516961813, critic_loss: 0.44492992758750916, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0073534236289560795, critic_loss: 0.4435861110687256, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.007356715388596058, critic_loss: 0.44260281324386597, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.007360820192843676, critic_loss: 0.4418962895870209, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.007371420972049236, critic_loss: 0.4413856565952301, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.007373097352683544, critic_loss: 0.44100502133369446, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.007374939974397421, critic_loss: 0.44069698452949524, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.007382445968687534, critic_loss: 0.4404193162918091, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.00738045247271657, critic_loss: 0.4401411712169647, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.007380956318229437, critic_loss: 0.43984556198120117, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.007381351664662361, critic_loss: 0.4395250082015991, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.007385854609310627, critic_loss: 0.4391831159591675, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.007385661825537682, critic_loss: 0.4388313293457031, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.007376260124146938, critic_loss: 0.43848079442977905, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.007382427342236042, critic_loss: 0.43814364075660706, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.007369262166321278, critic_loss: 0.43783050775527954, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.007367474026978016, critic_loss: 0.43754762411117554, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.007374159526079893, critic_loss: 0.4372987151145935, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.00736255245283246, critic_loss: 0.43708536028862, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.007369756232947111, critic_loss: 0.43690693378448486, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.0073564862832427025, critic_loss: 0.4367629587650299, entropy_bonus: -14.229761123657227\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008616802282631397, critic_loss: 0.52366042137146, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008616328239440918, critic_loss: 0.522340714931488, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008615406230092049, critic_loss: 0.5199421644210815, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008617797866463661, critic_loss: 0.5167086720466614, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008623127825558186, critic_loss: 0.5128989815711975, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008625073358416557, critic_loss: 0.5087686777114868, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008628524839878082, critic_loss: 0.5045099258422852, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008637205697596073, critic_loss: 0.5002994537353516, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008645999245345592, critic_loss: 0.4963395297527313, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008654442615807056, critic_loss: 0.4928751587867737, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008658811450004578, critic_loss: 0.49003610014915466, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.00865902565419674, critic_loss: 0.4877086579799652, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008657272905111313, critic_loss: 0.48563289642333984, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008656367659568787, critic_loss: 0.48356178402900696, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008659965358674526, critic_loss: 0.4813337028026581, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.008657516911625862, critic_loss: 0.4788963794708252, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008650021627545357, critic_loss: 0.47631773352622986, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008648454211652279, critic_loss: 0.47366011142730713, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.00864490494132042, critic_loss: 0.47096726298332214, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.008642011322081089, critic_loss: 0.46840226650238037, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008643527515232563, critic_loss: 0.4662029445171356, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008645867928862572, critic_loss: 0.46447044610977173, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008646140806376934, critic_loss: 0.46314316987991333, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.008648646995425224, critic_loss: 0.4621349573135376, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008653712458908558, critic_loss: 0.4613986909389496, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.00865982472896576, critic_loss: 0.4608776271343231, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00866316445171833, critic_loss: 0.46047165989875793, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008667480200529099, critic_loss: 0.4600815773010254, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008667041547596455, critic_loss: 0.45964327454566956, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008667761459946632, critic_loss: 0.45912447571754456, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.00866832584142685, critic_loss: 0.45851537585258484, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008666954934597015, critic_loss: 0.45781296491622925, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008667991496622562, critic_loss: 0.4570176601409912, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008669188246130943, critic_loss: 0.4561338722705841, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008668552152812481, critic_loss: 0.45517921447753906, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008669549599289894, critic_loss: 0.4541919231414795, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008671403862535954, critic_loss: 0.4532240927219391, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008671066723763943, critic_loss: 0.45232006907463074, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008669780567288399, critic_loss: 0.45148998498916626, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008667447604238987, critic_loss: 0.45071300864219666, entropy_bonus: -14.172197341918945\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007666002493351698, critic_loss: 0.550004780292511, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.007664752192795277, critic_loss: 0.5464197397232056, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.007662620861083269, critic_loss: 0.5412170886993408, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.007659669499844313, critic_loss: 0.5347285270690918, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.007659462746232748, critic_loss: 0.5274571776390076, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.007682946044951677, critic_loss: 0.5199251770973206, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0077088684774935246, critic_loss: 0.5122511982917786, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.007733992300927639, critic_loss: 0.5042622685432434, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.007753012236207724, critic_loss: 0.4959526062011719, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.007763860747218132, critic_loss: 0.48796746134757996, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.007765978574752808, critic_loss: 0.4813086986541748, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.007754786871373653, critic_loss: 0.4762754738330841, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.007746325805783272, critic_loss: 0.472625195980072, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.007753035053610802, critic_loss: 0.4699704051017761, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.007772031705826521, critic_loss: 0.46787700057029724, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.007790680043399334, critic_loss: 0.46605396270751953, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.007803329732269049, critic_loss: 0.46441808342933655, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.007810511626303196, critic_loss: 0.4629839062690735, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.007817456498742104, critic_loss: 0.46174371242523193, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.007813291624188423, critic_loss: 0.46063855290412903, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.007808398921042681, critic_loss: 0.45967796444892883, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.007811859715729952, critic_loss: 0.45893406867980957, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.007814331911504269, critic_loss: 0.45836928486824036, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.007815550081431866, critic_loss: 0.4578391909599304, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.007810736540704966, critic_loss: 0.4572536051273346, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.007803049404174089, critic_loss: 0.45668986439704895, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.007793649099767208, critic_loss: 0.45626676082611084, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.007790526375174522, critic_loss: 0.45594966411590576, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.007787620648741722, critic_loss: 0.4556314945220947, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.007779095321893692, critic_loss: 0.45524120330810547, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.007768146228045225, critic_loss: 0.45476362109184265, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.007762578781694174, critic_loss: 0.45420512557029724, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.007758453022688627, critic_loss: 0.45359352231025696, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.007753013167530298, critic_loss: 0.45295649766921997, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.007749573793262243, critic_loss: 0.45231544971466064, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.007745747920125723, critic_loss: 0.4516821503639221, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.007736148312687874, critic_loss: 0.45106348395347595, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.007735808379948139, critic_loss: 0.4504569470882416, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.007730242796242237, critic_loss: 0.4498550593852997, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.0077266087755560875, critic_loss: 0.4492509067058563, entropy_bonus: -14.11545181274414\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.012757622636854649, critic_loss: 0.5110110640525818, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0127567732706666, critic_loss: 0.5074083209037781, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.012752336449921131, critic_loss: 0.5024073719978333, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.012744881212711334, critic_loss: 0.4969255030155182, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.012736018747091293, critic_loss: 0.4915565550327301, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.012729941867291927, critic_loss: 0.486426442861557, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.012729963287711143, critic_loss: 0.48154935240745544, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.012732469476759434, critic_loss: 0.47681233286857605, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.012737610377371311, critic_loss: 0.47201430797576904, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.012746612541377544, critic_loss: 0.4673125147819519, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.01276914868503809, critic_loss: 0.4630066752433777, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.012781674042344093, critic_loss: 0.4590924084186554, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.012784487567842007, critic_loss: 0.4554961919784546, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.012789580039680004, critic_loss: 0.4522589147090912, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.012798367068171501, critic_loss: 0.4495452642440796, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.01280197873711586, critic_loss: 0.4474308490753174, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.012803005054593086, critic_loss: 0.44580259919166565, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.012798788025975227, critic_loss: 0.444523423910141, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.012788400985300541, critic_loss: 0.44360092282295227, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.012780590914189816, critic_loss: 0.4431236982345581, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.01278300117701292, critic_loss: 0.44301867485046387, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.012786110863089561, critic_loss: 0.443135529756546, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.01278709713369608, critic_loss: 0.443354994058609, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.012784573249518871, critic_loss: 0.4435933232307434, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.012781360186636448, critic_loss: 0.44379034638404846, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.012779444456100464, critic_loss: 0.44390806555747986, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.01277949195355177, critic_loss: 0.4439278244972229, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.01278326753526926, critic_loss: 0.44384604692459106, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.012781167402863503, critic_loss: 0.443666934967041, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.012775719165802002, critic_loss: 0.4434010684490204, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.012770210392773151, critic_loss: 0.44306302070617676, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.012765370309352875, critic_loss: 0.44266536831855774, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.012762879021465778, critic_loss: 0.44222092628479004, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.012758529745042324, critic_loss: 0.44174423813819885, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.012751515954732895, critic_loss: 0.4412519037723541, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.012743387371301651, critic_loss: 0.44075852632522583, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.012741646729409695, critic_loss: 0.4402773678302765, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.012735310941934586, critic_loss: 0.439820259809494, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.012727310881018639, critic_loss: 0.43939653038978577, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.012720104306936264, critic_loss: 0.4390108287334442, entropy_bonus: -14.059497833251953\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.006765125785022974, critic_loss: 0.5428340435028076, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.0067661600187420845, critic_loss: 0.5411803722381592, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.006765394937247038, critic_loss: 0.5363974571228027, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.00676336232572794, critic_loss: 0.5288418531417847, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.006770238745957613, critic_loss: 0.5191589593887329, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.00677725113928318, critic_loss: 0.5081941485404968, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.006786639336496592, critic_loss: 0.49716538190841675, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.00679670600220561, critic_loss: 0.4876405596733093, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.006825055927038193, critic_loss: 0.4799521267414093, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.006857164669781923, critic_loss: 0.4733828604221344, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.0068894741125404835, critic_loss: 0.46665334701538086, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.006924871820956469, critic_loss: 0.4596891403198242, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.00695656705647707, critic_loss: 0.45432761311531067, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.006975255440920591, critic_loss: 0.45094358921051025, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.006978237070143223, critic_loss: 0.4490390121936798, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.006981462240219116, critic_loss: 0.44802358746528625, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.006977194454520941, critic_loss: 0.4475644528865814, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.006970898248255253, critic_loss: 0.4476059377193451, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.006967579014599323, critic_loss: 0.4479209780693054, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00696267606690526, critic_loss: 0.44833076000213623, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0069638462737202644, critic_loss: 0.44873863458633423, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.006962843704968691, critic_loss: 0.44902360439300537, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.006961504928767681, critic_loss: 0.4490896463394165, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.006961899343878031, critic_loss: 0.4489384591579437, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.006958270911127329, critic_loss: 0.4486061930656433, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.006953227799385786, critic_loss: 0.44813722372055054, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.006952876225113869, critic_loss: 0.44757330417633057, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.006953961681574583, critic_loss: 0.44694820046424866, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.006944349035620689, critic_loss: 0.4462983012199402, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.006926484405994415, critic_loss: 0.4456557035446167, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.006914097815752029, critic_loss: 0.4450449049472809, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.006907652132213116, critic_loss: 0.4444935917854309, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.006897591985762119, critic_loss: 0.44401443004608154, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.006891549099236727, critic_loss: 0.4436008930206299, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.006883528083562851, critic_loss: 0.44323286414146423, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.006866042967885733, critic_loss: 0.4428904950618744, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.006855016574263573, critic_loss: 0.44255563616752625, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.006848689168691635, critic_loss: 0.442225843667984, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.006842444185167551, critic_loss: 0.4419088065624237, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.006837612017989159, critic_loss: 0.44161906838417053, entropy_bonus: -14.004316329956055\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.010046909563243389, critic_loss: 0.5595962405204773, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.010047556832432747, critic_loss: 0.5579653382301331, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.010047407820820808, critic_loss: 0.5549262762069702, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.01004646997898817, critic_loss: 0.5505295395851135, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.010044832713901997, critic_loss: 0.5448561906814575, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.010042783804237843, critic_loss: 0.5382692813873291, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.010045291855931282, critic_loss: 0.5315228700637817, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.010061532258987427, critic_loss: 0.525375247001648, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.010078132152557373, critic_loss: 0.5199155211448669, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.010086080059409142, critic_loss: 0.5149469375610352, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.01009270641952753, critic_loss: 0.5103704929351807, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.010107290931046009, critic_loss: 0.5061033368110657, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.010108350776135921, critic_loss: 0.5019318461418152, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.01010665949434042, critic_loss: 0.4976491332054138, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.010120589286088943, critic_loss: 0.4935464560985565, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.010118500329554081, critic_loss: 0.49000295996665955, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.01012295950204134, critic_loss: 0.486930251121521, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.010134895332157612, critic_loss: 0.48411673307418823, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.010140851140022278, critic_loss: 0.4814997613430023, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.010159946046769619, critic_loss: 0.4791092574596405, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.010167441330850124, critic_loss: 0.4769025146961212, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.010174178518354893, critic_loss: 0.47486352920532227, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.010188102722167969, critic_loss: 0.4730771780014038, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.010203903540968895, critic_loss: 0.4716194272041321, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.010217779316008091, critic_loss: 0.4703617990016937, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.010214904323220253, critic_loss: 0.4690802991390228, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.01022629626095295, critic_loss: 0.4676772654056549, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.010230880230665207, critic_loss: 0.46618813276290894, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.010232299566268921, critic_loss: 0.4646894037723541, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.010237889364361763, critic_loss: 0.4634479880332947, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.010240212082862854, critic_loss: 0.4626536965370178, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.010237316600978374, critic_loss: 0.46209773421287537, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.010233888402581215, critic_loss: 0.4616037607192993, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.010224844329059124, critic_loss: 0.461149126291275, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.010216709226369858, critic_loss: 0.4607137143611908, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.010209085419774055, critic_loss: 0.46025899052619934, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.010195780545473099, critic_loss: 0.459769070148468, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.010184177197515965, critic_loss: 0.4592472016811371, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.010170461609959602, critic_loss: 0.4587031602859497, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.010160818696022034, critic_loss: 0.4581506848335266, entropy_bonus: -13.949886322021484\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.011760150082409382, critic_loss: 0.5765975117683411, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.011756310239434242, critic_loss: 0.5741556882858276, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.011750565841794014, critic_loss: 0.5699000358581543, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.011743864044547081, critic_loss: 0.56388920545578, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.011766204610466957, critic_loss: 0.5559587478637695, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.011754162609577179, critic_loss: 0.5461542010307312, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.011768036521971226, critic_loss: 0.5357227325439453, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.011795278638601303, critic_loss: 0.526669442653656, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.011832654476165771, critic_loss: 0.5191649794578552, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.011815969832241535, critic_loss: 0.5122507810592651, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.011865830980241299, critic_loss: 0.5056942701339722, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.0118508730083704, critic_loss: 0.4997115135192871, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.011869309470057487, critic_loss: 0.4941265881061554, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.011889809742569923, critic_loss: 0.4888264238834381, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.011890818364918232, critic_loss: 0.4840030074119568, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.011892763897776604, critic_loss: 0.4796626567840576, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.011907865293323994, critic_loss: 0.4758221209049225, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.011911504901945591, critic_loss: 0.47254303097724915, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.011928285472095013, critic_loss: 0.4698255956172943, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.011913351714611053, critic_loss: 0.46756860613822937, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.011923026293516159, critic_loss: 0.4656493067741394, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.011915103532373905, critic_loss: 0.4639929533004761, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.011945831589400768, critic_loss: 0.4626378118991852, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.011928420513868332, critic_loss: 0.46167269349098206, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.011937340721487999, critic_loss: 0.4611055552959442, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.011930644512176514, critic_loss: 0.46081870794296265, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.011932170949876308, critic_loss: 0.46066299080848694, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.011944392696022987, critic_loss: 0.46052393317222595, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.011926155537366867, critic_loss: 0.4603562355041504, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.011927737854421139, critic_loss: 0.46013927459716797, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.011927329935133457, critic_loss: 0.4598720073699951, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.011912045069038868, critic_loss: 0.4595574140548706, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.01190816517919302, critic_loss: 0.45920485258102417, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.011898360215127468, critic_loss: 0.45882824063301086, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.011893217451870441, critic_loss: 0.45844340324401855, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.01189128216356039, critic_loss: 0.4580753743648529, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.011884776875376701, critic_loss: 0.4577494263648987, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.011883117258548737, critic_loss: 0.4574814438819885, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.011880599893629551, critic_loss: 0.45727360248565674, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.011861378327012062, critic_loss: 0.45711544156074524, entropy_bonus: -13.896188735961914\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008323702961206436, critic_loss: 0.5475094318389893, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.008323564194142818, critic_loss: 0.5457134246826172, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.008323268964886665, critic_loss: 0.5422863960266113, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.008322789333760738, critic_loss: 0.5374765992164612, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008327784948050976, critic_loss: 0.5317723751068115, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.0083311777561903, critic_loss: 0.5257440805435181, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008330169133841991, critic_loss: 0.5195947289466858, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008333736099302769, critic_loss: 0.5130976438522339, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.008345704525709152, critic_loss: 0.50611412525177, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008354698307812214, critic_loss: 0.4993641972541809, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008363327942788601, critic_loss: 0.49384546279907227, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008373909629881382, critic_loss: 0.489963173866272, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.008382203988730907, critic_loss: 0.48781511187553406, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008387372829020023, critic_loss: 0.4869615137577057, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008386249653995037, critic_loss: 0.4865978956222534, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.00838440004736185, critic_loss: 0.4861423671245575, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.008385109715163708, critic_loss: 0.4852999150753021, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.008383908309042454, critic_loss: 0.4839251637458801, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.008382991887629032, critic_loss: 0.4820849895477295, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00838156882673502, critic_loss: 0.4799416661262512, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.008380602113902569, critic_loss: 0.47753801941871643, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.008376788347959518, critic_loss: 0.4748496413230896, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.008373960852622986, critic_loss: 0.471794068813324, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.00837203674018383, critic_loss: 0.46816837787628174, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008372011594474316, critic_loss: 0.46405676007270813, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008371761068701744, critic_loss: 0.4602855145931244, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.008374993689358234, critic_loss: 0.4574682414531708, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.00837981142103672, critic_loss: 0.4551844894886017, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008385784924030304, critic_loss: 0.452856183052063, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.008393120020627975, critic_loss: 0.45026907324790955, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008400789462029934, critic_loss: 0.44769325852394104, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.008408349007368088, critic_loss: 0.4455423057079315, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.00841628760099411, critic_loss: 0.44382044672966003, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008423952385783195, critic_loss: 0.44228246808052063, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.008431931026279926, critic_loss: 0.4408853054046631, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008439552038908005, critic_loss: 0.4397384524345398, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.00844606850296259, critic_loss: 0.43882957100868225, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.00845200102776289, critic_loss: 0.438040167093277, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008457126095890999, critic_loss: 0.43731892108917236, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008462147787213326, critic_loss: 0.43667539954185486, entropy_bonus: -13.84320068359375\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.007192649412900209, critic_loss: 0.5516334176063538, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.007193358615040779, critic_loss: 0.5474200248718262, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.007194249890744686, critic_loss: 0.54031902551651, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.007194924633949995, critic_loss: 0.5310968160629272, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.00720698619261384, critic_loss: 0.5206367373466492, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.007224659435451031, critic_loss: 0.5110791921615601, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.007227016147226095, critic_loss: 0.5049092769622803, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.007240921258926392, critic_loss: 0.5022457242012024, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.007255944423377514, critic_loss: 0.5019083619117737, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.007264540530741215, critic_loss: 0.5025902390480042, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.007260674145072699, critic_loss: 0.5032174587249756, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.007251240778714418, critic_loss: 0.5031540393829346, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.00724555179476738, critic_loss: 0.502211332321167, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.007244800683110952, critic_loss: 0.5005325675010681, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.007250587921589613, critic_loss: 0.4983881115913391, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.0072661940939724445, critic_loss: 0.4958713948726654, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.007277867756783962, critic_loss: 0.4927854537963867, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.007281713653355837, critic_loss: 0.48873835802078247, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.0072748432867228985, critic_loss: 0.4834356904029846, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.007258124649524689, critic_loss: 0.4774564504623413, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.007249661721289158, critic_loss: 0.4719603359699249, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.00724640442058444, critic_loss: 0.46666282415390015, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.007247020956128836, critic_loss: 0.4613187909126282, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.0072487290017306805, critic_loss: 0.45785412192344666, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.007252814248204231, critic_loss: 0.45704227685928345, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.007256610784679651, critic_loss: 0.45679348707199097, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.007268157321959734, critic_loss: 0.45617949962615967, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.0072741396725177765, critic_loss: 0.45510339736938477, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.007273414172232151, critic_loss: 0.4533284902572632, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.007271951530128717, critic_loss: 0.45086073875427246, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.007279784884303808, critic_loss: 0.4481365978717804, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.007277011405676603, critic_loss: 0.44575560092926025, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.007278249133378267, critic_loss: 0.44412997364997864, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.007275219075381756, critic_loss: 0.4432867765426636, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.007270814850926399, critic_loss: 0.4430152177810669, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.007267497945576906, critic_loss: 0.4430575966835022, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.00727124186232686, critic_loss: 0.4431896209716797, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.007270532660186291, critic_loss: 0.4432501196861267, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.007271820213645697, critic_loss: 0.44313278794288635, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.007272079586982727, critic_loss: 0.44278430938720703, entropy_bonus: -13.790904998779297\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.008884325623512268, critic_loss: 0.5220928192138672, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.00888516940176487, critic_loss: 0.5180989503860474, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.00888634379953146, critic_loss: 0.5127978324890137, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.00888779480010271, critic_loss: 0.5068961977958679, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.008890760131180286, critic_loss: 0.500926673412323, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.008893336169421673, critic_loss: 0.49514371156692505, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.008898329921066761, critic_loss: 0.48957353830337524, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.008906969800591469, critic_loss: 0.48410308361053467, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.00892072543501854, critic_loss: 0.4786081314086914, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.008933596312999725, critic_loss: 0.473145455121994, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.008948310278356075, critic_loss: 0.46801185607910156, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.008962373249232769, critic_loss: 0.4635312557220459, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.00897489208728075, critic_loss: 0.45979106426239014, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.008985227905213833, critic_loss: 0.4566947817802429, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.008994386531412601, critic_loss: 0.45414644479751587, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.00899950135499239, critic_loss: 0.4520591199398041, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.009003843180835247, critic_loss: 0.4502772092819214, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.009008201770484447, critic_loss: 0.44866037368774414, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.009009435772895813, critic_loss: 0.44711557030677795, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.009010015986859798, critic_loss: 0.44560912251472473, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.009005577303469181, critic_loss: 0.4441468417644501, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.00900334119796753, critic_loss: 0.4427664875984192, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.009003815241158009, critic_loss: 0.44153741002082825, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.00900222733616829, critic_loss: 0.44053128361701965, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.008998238481581211, critic_loss: 0.4397771954536438, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.008993612602353096, critic_loss: 0.43924030661582947, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.0089881531894207, critic_loss: 0.43885067105293274, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.008981086313724518, critic_loss: 0.4385465383529663, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.008974160067737103, critic_loss: 0.43829286098480225, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.00896622147411108, critic_loss: 0.4380744397640228, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.008960350416600704, critic_loss: 0.4378829598426819, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.00895621906965971, critic_loss: 0.43771278858184814, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.008951008319854736, critic_loss: 0.4375567138195038, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.008945265784859657, critic_loss: 0.4374077022075653, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.00893995352089405, critic_loss: 0.4372587502002716, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.008934004232287407, critic_loss: 0.43710243701934814, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.008928551338613033, critic_loss: 0.43693533539772034, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.008923497051000595, critic_loss: 0.43675529956817627, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.008917695842683315, critic_loss: 0.43656301498413086, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.008912903256714344, critic_loss: 0.4363623261451721, entropy_bonus: -13.73928451538086\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.00981051567941904, critic_loss: 0.5297262072563171, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.009810691699385643, critic_loss: 0.5284774303436279, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.009810719639062881, critic_loss: 0.526517927646637, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.009810606017708778, critic_loss: 0.5238943099975586, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.009810386225581169, critic_loss: 0.520717978477478, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.009810075163841248, critic_loss: 0.5172441005706787, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.009809663519263268, critic_loss: 0.5138399600982666, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.009810574352741241, critic_loss: 0.5107507109642029, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.009811682626605034, critic_loss: 0.507949948310852, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.009810304269194603, critic_loss: 0.5052618980407715, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.009809843264520168, critic_loss: 0.5025171637535095, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.00981078390032053, critic_loss: 0.49959632754325867, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.009812560863792896, critic_loss: 0.49645930528640747, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.009813347831368446, critic_loss: 0.49312567710876465, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.009813659824430943, critic_loss: 0.4896208345890045, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.009813547134399414, critic_loss: 0.4859492778778076, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.009813136421144009, critic_loss: 0.482206255197525, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.009813516400754452, critic_loss: 0.47867658734321594, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.009814114309847355, critic_loss: 0.47568392753601074, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.009814002551138401, critic_loss: 0.47330304980278015, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.0098147913813591, critic_loss: 0.4714192748069763, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.009816324338316917, critic_loss: 0.46988970041275024, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.009816957637667656, critic_loss: 0.4686073362827301, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.009817115031182766, critic_loss: 0.46750402450561523, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.00981743074953556, critic_loss: 0.4665527045726776, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.009819182567298412, critic_loss: 0.4657522439956665, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.00982028990983963, critic_loss: 0.46509191393852234, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.009821188636124134, critic_loss: 0.46454837918281555, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.00982153881341219, critic_loss: 0.4640803337097168, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.009821592830121517, critic_loss: 0.4636384844779968, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.009822358377277851, critic_loss: 0.4631790816783905, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.009823509491980076, critic_loss: 0.46266937255859375, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.009824434295296669, critic_loss: 0.46208277344703674, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.009824695065617561, critic_loss: 0.46139827370643616, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.009824673645198345, critic_loss: 0.46060025691986084, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.009825726971030235, critic_loss: 0.45968204736709595, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.009825831279158592, critic_loss: 0.45865118503570557, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.009825171902775764, critic_loss: 0.45753568410873413, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.009825515560805798, critic_loss: 0.45638787746429443, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.009825554676353931, critic_loss: 0.4552745819091797, entropy_bonus: -13.688322067260742\n",
      "DEBUG:trainer:\tUpdating the nework ...\n",
      "DEBUG:trainer:\tEpoch: 0, actor_loss: 0.004658529534935951, critic_loss: 0.5277884602546692, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 1, actor_loss: 0.00465845363214612, critic_loss: 0.525087833404541, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 2, actor_loss: 0.004658267367631197, critic_loss: 0.5211636424064636, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 3, actor_loss: 0.004658229649066925, critic_loss: 0.516211211681366, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 4, actor_loss: 0.004658097866922617, critic_loss: 0.5104010105133057, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 5, actor_loss: 0.004658789839595556, critic_loss: 0.5039392709732056, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 6, actor_loss: 0.0046621328219771385, critic_loss: 0.49719884991645813, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 7, actor_loss: 0.004666994791477919, critic_loss: 0.49071282148361206, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 8, actor_loss: 0.004670051392167807, critic_loss: 0.48496323823928833, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 9, actor_loss: 0.004672772716730833, critic_loss: 0.48009783029556274, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 10, actor_loss: 0.004678607452660799, critic_loss: 0.4760274291038513, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 11, actor_loss: 0.004687623120844364, critic_loss: 0.47263962030410767, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 12, actor_loss: 0.004697126802057028, critic_loss: 0.46985870599746704, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 13, actor_loss: 0.004705606959760189, critic_loss: 0.467441201210022, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 14, actor_loss: 0.00471492949873209, critic_loss: 0.4650201201438904, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 15, actor_loss: 0.0047244844026863575, critic_loss: 0.4623118042945862, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 16, actor_loss: 0.0047371890395879745, critic_loss: 0.45927780866622925, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 17, actor_loss: 0.004750825930386782, critic_loss: 0.4562760293483734, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 18, actor_loss: 0.0047650584019720554, critic_loss: 0.45385196805000305, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 19, actor_loss: 0.00477639539167285, critic_loss: 0.4522084593772888, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 20, actor_loss: 0.004785128869116306, critic_loss: 0.4511463940143585, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 21, actor_loss: 0.004792369436472654, critic_loss: 0.45036423206329346, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 22, actor_loss: 0.004798451904207468, critic_loss: 0.4496496915817261, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 23, actor_loss: 0.004802064970135689, critic_loss: 0.4489220380783081, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 24, actor_loss: 0.004803284537047148, critic_loss: 0.44820481538772583, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 25, actor_loss: 0.004803570453077555, critic_loss: 0.4475495517253876, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 26, actor_loss: 0.004801785107702017, critic_loss: 0.4469662606716156, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 27, actor_loss: 0.004800105467438698, critic_loss: 0.4464496374130249, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 28, actor_loss: 0.004797403700649738, critic_loss: 0.4460097849369049, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 29, actor_loss: 0.004792718682438135, critic_loss: 0.44567281007766724, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 30, actor_loss: 0.004791233688592911, critic_loss: 0.44545382261276245, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 31, actor_loss: 0.004789300728589296, critic_loss: 0.44534116983413696, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 32, actor_loss: 0.0047869267873466015, critic_loss: 0.4452979266643524, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 33, actor_loss: 0.00478323083370924, critic_loss: 0.44527679681777954, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 34, actor_loss: 0.004778278060257435, critic_loss: 0.44523078203201294, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 35, actor_loss: 0.0047725411131978035, critic_loss: 0.4451283812522888, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 36, actor_loss: 0.004766459111124277, critic_loss: 0.44495946168899536, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 37, actor_loss: 0.004760416690260172, critic_loss: 0.4447328746318817, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 38, actor_loss: 0.004755511414259672, critic_loss: 0.4444684386253357, entropy_bonus: -13.63800048828125\n",
      "DEBUG:trainer:\tEpoch: 39, actor_loss: 0.004749950487166643, critic_loss: 0.4441881775856018, entropy_bonus: -13.63800048828125\n",
      "INFO:trainer:\tTraining Interrupted at episode 43\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = PPOTrainer(agent, gamma=0.99, epsilon_clip=0.1, training_epochs=40, use_generalized_advantage=True)\n",
    "trainer.toggle_debug()\n",
    "scores = trainer.train(n_episodes=1000, max_t=3000, update_every=512)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(scores)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claudiocoppola/code/RL_repos/DeepRL_Continuous_Control/src/model/ppo/trainer.py:169: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(self.gae_lambda is not None, \"If compute_general_advantage is set to True a gae_lambda value should be provided\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(scores)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(1.00000e-20 *\n",
       "         [ 6.9490]),\n",
       "  tensor(1.00000e-23 *\n",
       "         [ 3.9557]),\n",
       "  tensor(1.00000e-26 *\n",
       "         [ 7.3823]),\n",
       "  tensor(1.00000e-26 *\n",
       "         [ 4.6146]),\n",
       "  tensor(1.00000e-24 *\n",
       "         [ 5.8462]),\n",
       "  tensor(1.00000e-23 *\n",
       "         [ 5.9610]),\n",
       "  tensor(1.00000e-22 *\n",
       "         [ 7.2304]),\n",
       "  tensor(1.00000e-18 *\n",
       "         [ 1.5306]),\n",
       "  tensor(1.00000e-17 *\n",
       "         [ 3.6076]),\n",
       "  tensor(1.00000e-16 *\n",
       "         [ 5.7379]),\n",
       "  tensor(1.00000e-18 *\n",
       "         [ 1.2030]),\n",
       "  tensor(1.00000e-19 *\n",
       "         [ 1.1173]),\n",
       "  tensor(1.00000e-22 *\n",
       "         [ 1.1839]),\n",
       "  tensor(1.00000e-25 *\n",
       "         [ 3.8378]),\n",
       "  tensor(1.00000e-20 *\n",
       "         [ 3.0209]),\n",
       "  tensor(1.00000e-16 *\n",
       "         [ 3.0920]),\n",
       "  tensor(1.00000e-18 *\n",
       "         [ 3.7784]),\n",
       "  tensor(1.00000e-16 *\n",
       "         [ 1.8243]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 3.4179]),\n",
       "  tensor(1.00000e-11 *\n",
       "         [ 1.5415]),\n",
       "  tensor(1.00000e-11 *\n",
       "         [ 1.2779]),\n",
       "  tensor(1.00000e-12 *\n",
       "         [ 3.5160]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 3.4102]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 1.2927]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 2.0083]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 1.5386]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 9.2941]),\n",
       "  tensor(1.00000e-14 *\n",
       "         [ 6.7824]),\n",
       "  tensor(1.00000e-14 *\n",
       "         [ 3.6435]),\n",
       "  tensor(1.00000e-14 *\n",
       "         [ 6.0564]),\n",
       "  tensor(1.00000e-15 *\n",
       "         [ 4.8114]),\n",
       "  tensor(1.00000e-17 *\n",
       "         [ 2.3590]),\n",
       "  tensor(1.00000e-20 *\n",
       "         [ 1.8915]),\n",
       "  tensor(1.00000e-22 *\n",
       "         [ 7.0379]),\n",
       "  tensor(1.00000e-23 *\n",
       "         [ 3.2595]),\n",
       "  tensor(1.00000e-21 *\n",
       "         [ 2.2637]),\n",
       "  tensor(1.00000e-22 *\n",
       "         [ 2.7546]),\n",
       "  tensor(1.00000e-26 *\n",
       "         [ 8.3775]),\n",
       "  tensor(1.00000e-28 *\n",
       "         [ 9.0585]),\n",
       "  tensor(1.00000e-30 *\n",
       "         [ 6.6324]),\n",
       "  tensor(1.00000e-33 *\n",
       "         [ 6.0558]),\n",
       "  tensor(1.00000e-35 *\n",
       "         [ 5.4374]),\n",
       "  tensor(1.00000e-38 *\n",
       "         [ 6.6460]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor(1.00000e-39 *\n",
       "         [ 8.2072]),\n",
       "  tensor(1.00000e-35 *\n",
       "         [ 1.2902]),\n",
       "  tensor(1.00000e-35 *\n",
       "         [ 1.6092]),\n",
       "  tensor(1.00000e-38 *\n",
       "         [ 4.8702]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor(1.00000e-38 *\n",
       "         [ 3.4167]),\n",
       "  tensor(1.00000e-37 *\n",
       "         [ 1.9420]),\n",
       "  tensor(1.00000e-35 *\n",
       "         [ 5.4438]),\n",
       "  tensor(1.00000e-33 *\n",
       "         [ 5.0404]),\n",
       "  tensor(1.00000e-32 *\n",
       "         [ 2.8104]),\n",
       "  tensor(1.00000e-31 *\n",
       "         [ 2.0633]),\n",
       "  tensor(1.00000e-31 *\n",
       "         [ 1.2973]),\n",
       "  tensor(1.00000e-32 *\n",
       "         [ 7.1594]),\n",
       "  tensor(1.00000e-31 *\n",
       "         [ 3.8758]),\n",
       "  tensor(1.00000e-28 *\n",
       "         [ 2.3864]),\n",
       "  tensor(1.00000e-28 *\n",
       "         [ 8.5608]),\n",
       "  tensor(1.00000e-29 *\n",
       "         [ 5.9330]),\n",
       "  tensor(1.00000e-31 *\n",
       "         [ 9.4917]),\n",
       "  tensor(1.00000e-30 *\n",
       "         [ 2.6524]),\n",
       "  tensor(1.00000e-31 *\n",
       "         [ 3.7541]),\n",
       "  tensor(1.00000e-32 *\n",
       "         [ 4.2129]),\n",
       "  tensor(1.00000e-31 *\n",
       "         [ 1.9236]),\n",
       "  tensor(1.00000e-29 *\n",
       "         [ 5.3723]),\n",
       "  tensor(1.00000e-27 *\n",
       "         [ 5.6294]),\n",
       "  tensor(1.00000e-20 *\n",
       "         [ 2.7233]),\n",
       "  tensor(1.00000e-20 *\n",
       "         [ 6.1418]),\n",
       "  tensor(1.00000e-20 *\n",
       "         [ 4.8549]),\n",
       "  tensor(1.00000e-20 *\n",
       "         [ 4.9819]),\n",
       "  tensor(1.00000e-20 *\n",
       "         [ 1.3734]),\n",
       "  tensor(1.00000e-18 *\n",
       "         [ 6.2682]),\n",
       "  tensor(1.00000e-16 *\n",
       "         [ 1.3893]),\n",
       "  tensor(1.00000e-15 *\n",
       "         [ 6.3920]),\n",
       "  tensor(1.00000e-14 *\n",
       "         [ 3.3321]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 2.1217]),\n",
       "  tensor(1.00000e-12 *\n",
       "         [ 1.0368]),\n",
       "  tensor(1.00000e-12 *\n",
       "         [ 3.9447]),\n",
       "  tensor(1.00000e-12 *\n",
       "         [ 9.4051]),\n",
       "  tensor(1.00000e-11 *\n",
       "         [ 6.2954]),\n",
       "  tensor(1.00000e-11 *\n",
       "         [ 9.6303]),\n",
       "  tensor(1.00000e-10 *\n",
       "         [ 3.8674]),\n",
       "  tensor(1.00000e-10 *\n",
       "         [ 9.7755]),\n",
       "  tensor(1.00000e-10 *\n",
       "         [ 7.1467]),\n",
       "  tensor(1.00000e-10 *\n",
       "         [ 5.4942]),\n",
       "  tensor(1.00000e-10 *\n",
       "         [ 4.3957]),\n",
       "  tensor(1.00000e-10 *\n",
       "         [ 4.7300]),\n",
       "  tensor(1.00000e-10 *\n",
       "         [ 1.3766]),\n",
       "  tensor(1.00000e-11 *\n",
       "         [ 2.7552]),\n",
       "  tensor(1.00000e-11 *\n",
       "         [ 2.9423]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 8.4866]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 1.3852]),\n",
       "  tensor(1.00000e-16 *\n",
       "         [ 1.9596]),\n",
       "  tensor(1.00000e-16 *\n",
       "         [ 1.2982]),\n",
       "  tensor(1.00000e-17 *\n",
       "         [ 5.6462]),\n",
       "  tensor(1.00000e-15 *\n",
       "         [ 3.6162]),\n",
       "  tensor(1.00000e-15 *\n",
       "         [ 3.9410]),\n",
       "  tensor(1.00000e-15 *\n",
       "         [ 4.9224]),\n",
       "  tensor(1.00000e-14 *\n",
       "         [ 6.9944]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 1.4131]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 2.5957]),\n",
       "  tensor(1.00000e-13 *\n",
       "         [ 3.2201]),\n",
       "  tensor(1.00000e-14 *\n",
       "         [ 1.5508]),\n",
       "  tensor(1.00000e-15 *\n",
       "         [ 1.7209]),\n",
       "  tensor(1.00000e-18 *\n",
       "         [ 6.1390]),\n",
       "  tensor(1.00000e-19 *\n",
       "         [ 4.5301]),\n",
       "  tensor(1.00000e-21 *\n",
       "         [ 7.8436]),\n",
       "  tensor(1.00000e-21 *\n",
       "         [ 3.3526]),\n",
       "  tensor(1.00000e-22 *\n",
       "         [ 1.3184]),\n",
       "  tensor(1.00000e-25 *\n",
       "         [ 1.5781]),\n",
       "  tensor(1.00000e-28 *\n",
       "         [ 4.1964]),\n",
       "  tensor(1.00000e-31 *\n",
       "         [ 1.5279]),\n",
       "  tensor(1.00000e-34 *\n",
       "         [ 2.4718]),\n",
       "  tensor(1.00000e-38 *\n",
       "         [ 2.2604]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.])],\n",
       " [tensor([  0.0000,  -4.0000,   0.0000,   1.0000,  -0.0000,  -0.0000,\n",
       "           -0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000, -10.0000,   0.0000,   1.0000,  -0.0000,\n",
       "           -0.0000,  -0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   7.8252,  -1.0000,  -1.6633,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ 0.1360, -3.9820, -0.3723,  0.9988,  0.0169,  0.0007, -0.0464,\n",
       "           1.3629, -0.0302,  0.4569,  1.8410,  0.4071, -5.4641, -0.0517,\n",
       "          -9.9052, -0.0607,  0.9939, -0.0476,  0.0088,  0.0988, -2.9262,\n",
       "          -0.3966, -1.3822, -3.1267,  2.9538,  3.2411,  7.7175, -1.0000,\n",
       "          -2.1071,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.2671, -3.9039, -0.8407,  0.9939,  0.0331,  0.0034, -0.1053,\n",
       "           1.5491, -0.0669,  0.3645,  1.4880,  1.2096, -6.1014, -0.1949,\n",
       "          -9.4629, -0.1575,  0.9667, -0.1033,  0.0454,  0.2295, -3.6080,\n",
       "          -1.0647, -1.3336, -4.5963,  9.2965,  3.0754,  7.5847, -1.0000,\n",
       "          -2.5440,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([  0.2295,  -3.7884,  -1.2710,   0.9867,   0.0282,   0.0046,\n",
       "           -0.1603,   1.3688,   0.0954,  -0.3128,  -1.3125,   1.5219,\n",
       "           -5.2790,  -0.4403,  -8.7557,  -0.2600,   0.9204,  -0.1223,\n",
       "            0.0759,   0.3635,  -3.5843,  -0.1665,  -0.3553,  -3.9309,\n",
       "           12.6959,   2.6166,   7.4272,  -1.0000,  -2.9726,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.0316,  -3.6681,  -1.6021,   0.9791,   0.0038,   0.0009,\n",
       "           -0.2035,   1.0181,   0.2788,  -0.6774,  -2.9447,   1.4957,\n",
       "           -3.8105,  -0.7427,  -7.9516,  -0.3332,   0.8659,  -0.1149,\n",
       "            0.0688,   0.4820,  -3.1108,   0.7530,  -0.3176,  -3.3073,\n",
       "           13.8582,   2.0443,   7.2455,  -1.0000,  -3.3916,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -0.2298,  -3.5478,  -1.8401,   0.9714,  -0.0278,  -0.0067,\n",
       "           -0.2357,   0.7812,   0.3689,  -0.7419,  -3.3289,   1.5181,\n",
       "           -2.7504,  -1.0427,  -7.0592,  -0.3977,   0.7996,  -0.1030,\n",
       "            0.0409,   0.5902,  -3.1565,   0.9828,  -0.4894,  -2.5622,\n",
       "           15.9917,   1.0243,   7.0402,  -1.0000,  -3.7994,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -0.5042,  -3.4490,  -1.9692,   0.9650,  -0.0608,  -0.0160,\n",
       "           -0.2548,   0.3973,   0.4132,  -0.7396,  -3.3863,   1.0965,\n",
       "           -1.2063,  -1.3174,  -6.0795,  -0.4586,   0.7119,  -0.0912,\n",
       "            0.0110,   0.6962,  -3.5208,   0.9251,  -0.5167,  -2.0492,\n",
       "           17.7451,  -0.0902,   6.8119,  -1.0000,  -4.1950,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -0.7429,  -3.3876,  -2.0000,   0.9608,  -0.0895,  -0.0243,\n",
       "           -0.2611,   0.1682,   0.3455,  -0.5921,  -2.7156,   0.7431,\n",
       "           -0.3379,  -1.5808,  -5.2393,  -0.5797,   0.6205,  -0.0831,\n",
       "           -0.0057,   0.7797,  -2.7507,   0.4421,  -0.2858,  -2.5874,\n",
       "           13.4479,  -2.5338,   6.5615,  -1.0000,  -4.5768,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -0.9272,  -3.4006,  -1.8985,   0.9615,  -0.1124,  -0.0291,\n",
       "           -0.2490,  -0.5439,   0.2575,  -0.4511,  -2.0372,  -0.6580,\n",
       "            2.0803,  -1.8240,  -4.4909,  -0.6884,   0.5073,  -0.0721,\n",
       "           -0.0026,   0.8587,  -3.8460,   0.3123,   0.1666,  -2.6028,\n",
       "           14.3635,  -3.4128,   6.2896,  -1.0000,  -4.9437,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -1.0992,  -3.4711,  -1.6646,   0.9660,  -0.1346,  -0.0305,\n",
       "           -0.2185,  -0.8321,   0.2331,  -0.4675,  -2.0267,  -0.9462,\n",
       "            3.1351,  -2.0850,  -3.8962,  -0.8342,   0.3716,  -0.0519,\n",
       "            0.0093,   0.9269,  -3.7702,   0.3981,   0.3579,  -3.2918,\n",
       "           10.7297,  -5.6976,   5.9973,  -1.0000,  -5.2945,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([-1.3654, -3.5525, -1.2477,  0.9711, -0.1699, -0.0290, -0.1648,\n",
       "          -1.6095,  0.3741, -0.9670, -3.9525, -0.9721,  6.2026, -2.3957,\n",
       "          -3.4370, -0.9968,  0.1995, -0.0133,  0.0000,  0.9798, -4.8820,\n",
       "           1.2882, -0.3688, -2.6935,  8.8001, -8.1924,  5.6854, -1.0000,\n",
       "          -5.6281,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ -1.6616,  -3.5743,  -0.7103,   0.9727,  -0.2104,  -0.0208,\n",
       "           -0.0953,  -1.8416,   0.2062,  -0.8732,  -3.3149,  -0.1722,\n",
       "            6.9507,  -2.7930,  -3.2345,  -1.2429,   0.0004,   0.0426,\n",
       "           -0.0169,   0.9989,  -5.1489,   1.5485,   0.0088,  -5.1153,\n",
       "            2.0633, -10.9952,   5.3550,  -1.0000,  -5.9434,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.0001,  -3.4679,  -0.1508,   0.9661,  -0.2573,  -0.0059,\n",
       "           -0.0211,  -1.9375,   0.1026,  -1.2635,  -4.4911,   1.8578,\n",
       "            7.0375,  -3.3094,  -3.3406,  -1.5623,  -0.2147,   0.1173,\n",
       "           -0.0554,   0.9680,  -5.6341,   2.1047,  -1.0632,  -6.3925,\n",
       "           -5.1793, -12.0541,   5.0072,  -1.0000,  -6.2392,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.4297,  -3.1738,   0.2924,   0.9469,  -0.3183,   0.0142,\n",
       "            0.0430,  -1.5956,  -0.1042,  -1.7053,  -5.6210,   4.2746,\n",
       "            4.9981,  -3.9965,  -3.7079,  -1.8769,  -0.4182,   0.2016,\n",
       "           -0.1402,   0.8745,  -5.6329,   2.0451,  -2.3582,  -8.9642,\n",
       "          -11.3288,  -9.5942,   4.6430,  -1.0000,  -6.5148,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.7575,  -2.8765,   0.4186,   0.9271,  -0.3680,   0.0264,\n",
       "            0.0666,  -0.3644,  -0.1518,  -1.0903,  -3.2886,   3.0854,\n",
       "            0.6694,  -4.6991,  -4.2035,  -2.1651,  -0.5591,   0.2652,\n",
       "           -0.2206,   0.7539,  -4.0903,   1.5843,  -1.8483,  -9.4119,\n",
       "          -12.1307,  -5.7250,   4.2638,  -1.0000,  -6.7691,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.9190,  -2.7239,   0.3367,   0.9169,  -0.3945,   0.0242,\n",
       "            0.0561,   0.4167,  -0.0680,  -0.5116,  -1.4423,   1.3254,\n",
       "           -1.3510,  -5.2628,  -4.7326,  -2.4165,  -0.6526,   0.2997,\n",
       "           -0.2597,   0.6457,  -3.0066,   1.3215,  -0.8771,  -8.1173,\n",
       "          -10.9509,  -3.1537,   3.8706,  -1.0000,  -7.0013,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -3.0936,  -2.5445,   0.1481,   0.9048,  -0.4248,   0.0125,\n",
       "            0.0263,   0.9571,  -0.0756,  -0.9441,  -2.4873,   2.6750,\n",
       "           -2.7357,  -5.8139,  -5.2911,  -2.6100,  -0.7429,   0.2985,\n",
       "           -0.2932,   0.5224,  -4.0849,   0.8428,  -0.4627,  -8.4175,\n",
       "          -12.8461,  -0.7122,   3.4648,  -1.0000,  -7.2108,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -3.2252,  -2.3740,  -0.1978,   0.8928,  -0.4485,  -0.0183,\n",
       "           -0.0366,   1.9673,   0.0197,  -0.5030,  -1.2241,   1.8009,\n",
       "           -4.7169,  -6.2927,  -5.8811,  -2.7346,  -0.8448,   0.2514,\n",
       "           -0.2678,   0.3891,  -3.8379,   2.1257,   1.4976,  -6.7916,\n",
       "          -12.6417,   2.2422,   3.0477,  -1.0000,  -7.3967,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([-3.1981, -2.3548, -0.5475,  0.8903, -0.4410, -0.0503, -0.1014,\n",
       "           1.4385, -0.0714,  0.3582,  0.8806, -0.4757, -3.6312, -6.5444,\n",
       "          -6.3983, -2.6846, -0.9279,  0.2092, -0.1303,  0.2798, -2.1176,\n",
       "           3.9934,  1.6465, -4.4077, -8.9327,  5.6648,  2.6207, -1.0000,\n",
       "          -7.5586,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-3.0573, -2.4836, -0.7416,  0.8987, -0.4143, -0.0601, -0.1304,\n",
       "           0.3064, -0.2246,  0.7765,  2.0690, -2.1899, -1.4499, -6.6293,\n",
       "          -6.8400, -2.3863, -0.9560,  0.2248, -0.0052,  0.1883, -1.5155,\n",
       "           2.9680, -0.2687, -2.8330, -6.1345,  8.3021,  2.1851, -1.0000,\n",
       "          -7.6958,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ -2.8469,  -2.6935,  -0.8362,   0.9133,  -0.3790,  -0.0571,\n",
       "           -0.1375,   0.0130,  -0.2991,   0.9713,   2.8247,  -2.8112,\n",
       "           -0.9038,  -6.6014,  -7.2091,  -1.8998,  -0.9537,   0.2770,\n",
       "            0.0676,   0.0961,  -1.9426,   2.2600,  -1.1399,  -1.3487,\n",
       "           -4.0467,  10.8350,   1.7425,  -1.0000,  -7.8079,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.5941,  -2.9443,  -0.8079,   0.9309,  -0.3405,  -0.0455,\n",
       "           -0.1245,  -0.6170,  -0.2867,   1.0019,   3.1443,  -3.1754,\n",
       "            1.0279,  -6.4560,  -7.4595,  -1.2499,  -0.9354,   0.3422,\n",
       "            0.0885,   0.0039,  -2.1656,   0.9711,  -1.4748,   0.3531,\n",
       "           -1.3974,  12.0688,   1.2941,  -1.0000,  -7.8946,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.2861,  -3.2229,  -0.6569,   0.9499,  -0.2963,  -0.0295,\n",
       "           -0.0951,  -0.9124,  -0.2764,   1.2452,   4.1455,  -3.5931,\n",
       "            2.2400,  -6.2141,  -7.5581,  -0.4802,  -0.9017,   0.4170,\n",
       "            0.0713,  -0.0894,  -2.6839,   0.3006,  -1.9963,   1.4615,\n",
       "            2.2742,  12.9637,   0.8415,  -1.0000,  -7.9556,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -1.9982,  -3.4465,  -0.4034,   0.9648,  -0.2567,  -0.0148,\n",
       "           -0.0559,  -1.0577,  -0.1330,   0.9628,   3.3544,  -2.4881,\n",
       "            3.3414,  -5.9044,  -7.4768,   0.3530,  -0.8596,   0.4743,\n",
       "            0.0299,  -0.1875,  -2.9323,   0.0420,  -1.2763,   2.9601,\n",
       "            4.3719,  12.7754,   0.3862,  -1.0000,  -7.9907,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -1.8134,  -3.5667,  -0.1198,   0.9726,  -0.2318,  -0.0038,\n",
       "           -0.0162,  -0.9747,  -0.0278,   0.5238,   1.8727,  -1.1544,\n",
       "            3.4230,  -5.6088,  -7.3141,   1.1725,  -0.8233,   0.4897,\n",
       "           -0.0131,  -0.2868,  -2.7450,   0.3652,  -0.2260,   3.5891,\n",
       "            4.1121,  12.0013,  -0.0703,  -1.0000,  -7.9997,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -1.7069,  -3.6158,   0.1865,   0.9757,  -0.2174,   0.0056,\n",
       "            0.0250,  -1.0792,   0.0088,   0.2973,   1.0798,  -0.3987,\n",
       "            3.9313,  -5.3473,  -7.1147,   1.9979,  -0.7926,   0.4749,\n",
       "           -0.0474,  -0.3795,  -2.4460,   0.6324,   0.2513,   3.7069,\n",
       "            4.2274,  12.2019,  -0.5267,  -1.0000,  -7.9826,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -1.6615,  -3.6068,   0.5022,   0.9751,  -0.2109,   0.0145,\n",
       "            0.0672,  -1.0487,   0.0075,   0.0641,   0.2361,   0.3388,\n",
       "            3.8240,  -5.1442,  -6.8470,   2.8000,  -0.7642,   0.4482,\n",
       "           -0.0680,  -0.4588,  -1.9855,   0.8280,   0.2815,   2.9502,\n",
       "            5.1308,  11.2283,  -0.9813,  -1.0000,  -7.9396,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -1.6142,  -3.5598,   0.8661,   0.9718,  -0.2037,   0.0243,\n",
       "            0.1159,  -1.3463,   0.0458,   0.2148,   0.8073,   0.6823,\n",
       "            4.9144,  -4.9409,  -6.4664,   3.6231,  -0.7288,   0.4206,\n",
       "           -0.0884,  -0.5330,  -2.2274,   0.6095,   0.2132,   3.3845,\n",
       "            7.3611,  11.5751,  -1.4327,  -1.0000,  -7.8707,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([-1.5801, -3.4786,  1.1956,  0.9664, -0.1979,  0.0329,  0.1606,\n",
       "          -1.0189,  0.0170,  0.0535,  0.2074,  1.0587,  3.6145, -4.7028,\n",
       "          -5.9778,  4.3747, -0.6868,  0.3851, -0.0975, -0.6087, -2.1149,\n",
       "           1.2157,  0.0867,  4.4031,  8.6258,  9.8510, -1.8795, -1.0000,\n",
       "          -7.7761,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.6349, -3.3394,  1.4864,  0.9570, -0.2034,  0.0429,  0.2022,\n",
       "          -1.0969, -0.1306, -0.3141, -1.2536,  2.0577,  3.5216, -4.5147,\n",
       "          -5.3980,  5.0587, -0.6473,  0.3448, -0.0788, -0.6752, -1.4675,\n",
       "           1.6346, -0.2946,  3.8415,  9.6238,  9.5723, -2.3201, -1.0000,\n",
       "          -7.6562,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ -1.7707,  -3.1458,   1.7351,   0.9437,  -0.2190,   0.0560,\n",
       "            0.2416,  -1.0024,  -0.2483,  -0.4764,  -1.9495,   2.5066,\n",
       "            2.7957,  -4.3494,  -4.7078,   5.6396,  -0.6047,   0.3058,\n",
       "           -0.0331,  -0.7347,  -1.3955,   1.9363,  -0.8032,   4.8528,\n",
       "           11.3510,   7.3500,  -2.7532,  -1.0000,  -7.5113,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -1.9275,  -2.9163,   1.9574,   0.9274,  -0.2368,   0.0716,\n",
       "            0.2807,  -1.0726,  -0.2980,  -0.4696,  -1.9744,   2.9274,\n",
       "            2.6521,  -4.1340,  -3.9202,   6.0714,  -0.5493,   0.2727,\n",
       "            0.0279,  -0.7894,  -1.4959,   1.9121,  -1.2185,   6.0540,\n",
       "           12.6262,   4.7584,  -3.1773,  -1.0000,  -7.3420,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.0958,  -2.6367,   2.1726,   0.9067,  -0.2551,   0.0909,\n",
       "            0.3235,  -1.2366,  -0.3860,  -0.4979,  -2.1784,   3.6426,\n",
       "            2.5868,  -3.8681,  -3.0519,   6.3525,  -0.4788,   0.2495,\n",
       "            0.1016,  -0.8356,  -1.5912,   1.8189,  -1.7457,   7.0263,\n",
       "           13.4073,   1.9885,  -3.5910,  -1.0000,  -7.1487,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.1504,  -2.3470,   2.4380,   0.8846,  -0.2565,   0.1085,\n",
       "            0.3741,  -1.4408,   0.0304,   0.0313,   0.1480,   3.3405,\n",
       "            3.5757,  -3.5235,  -2.1634,   6.5338,  -0.3914,   0.2376,\n",
       "            0.1502,  -0.8762,  -2.2488,   1.1312,  -0.9632,   6.8730,\n",
       "           13.5224,  -0.1688,  -3.9931,  -1.0000,  -6.9322,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.0091,  -2.1173,   2.7510,   0.8676,  -0.2323,   0.1138,\n",
       "            0.4247,  -1.2780,   0.5852,   0.4795,   2.6119,   2.4233,\n",
       "            4.0038,  -3.0924,  -1.3535,   6.6216,  -0.2935,   0.2246,\n",
       "            0.1471,  -0.9175,  -2.6782,   0.8228,   0.2196,   6.2028,\n",
       "           12.0986,  -2.4567,  -4.3821,  -1.0000,  -6.6931,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([-1.7552, -1.9144,  3.0579,  0.8537, -0.1961,  0.1081,  0.4702,\n",
       "          -1.1085,  0.8138,  0.5405,  3.5004,  2.3211,  3.6842, -2.6749,\n",
       "          -0.7008,  6.6862, -0.2119,  0.2024,  0.1133, -0.9494, -2.0095,\n",
       "           0.7160,  0.8485,  4.3934,  8.9208, -1.7440, -4.7569, -1.0000,\n",
       "          -6.4321,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.5275, -1.7057,  3.2950,  0.8393, -0.1656,  0.1003,  0.5079,\n",
       "          -0.9435,  0.5699,  0.3124,  2.4043,  2.5683,  2.5762, -2.3193,\n",
       "          -0.1702,  6.7135, -0.1489,  0.1793,  0.0873, -0.9685, -1.5029,\n",
       "           0.6299,  0.2579,  4.1095,  6.9569, -2.0568, -5.1161, -1.0000,\n",
       "          -6.1502,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.3254, -1.4907,  3.4827,  0.8243, -0.1397,  0.0918,  0.5410,\n",
       "          -0.8908,  0.6137,  0.2793,  2.5473,  2.6781,  2.2394, -1.9619,\n",
       "           0.3092,  6.6505, -0.0848,  0.1567,  0.0733, -0.9813, -1.7002,\n",
       "           0.7163,  0.1008,  4.7284,  6.4262, -3.7933, -5.4587, -1.0000,\n",
       "          -5.8483,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.1463, -1.2765,  3.6292,  0.8089, -0.1177,  0.0830,  0.5700,\n",
       "          -0.7741,  0.4940,  0.1852,  2.0266,  2.5645,  1.6307, -1.6102,\n",
       "           0.7280,  6.5044, -0.0187,  0.1360,  0.0685, -0.9882, -1.5930,\n",
       "           0.5931, -0.1858,  4.5912,  5.0029, -4.5005, -5.7835, -1.0000,\n",
       "          -5.5273,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.9296, -1.0806,  3.7539,  0.7950, -0.0931,  0.0698,  0.5954,\n",
       "          -0.6849,  0.7447,  0.2296,  3.0366,  2.3229,  1.5242, -1.2817,\n",
       "           1.0692,  6.2776,  0.0523,  0.1105,  0.0513, -0.9912, -1.8828,\n",
       "           0.8629,  0.4037,  3.3147,  3.8317, -6.1277, -6.0895, -1.0000,\n",
       "          -5.1883,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.6123, -0.8812,  3.8710,  0.7809, -0.0598,  0.0476,  0.6200,\n",
       "          -0.7076,  1.0806,  0.2683,  4.4089,  2.5313,  1.4327, -0.9886,\n",
       "           1.3418,  5.9535,  0.1357,  0.0684,  0.0038, -0.9884, -2.3146,\n",
       "           1.4067,  1.1448,  1.3369,  2.4146, -7.8959, -6.3756, -1.0000,\n",
       "          -4.8324,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.2926, -0.6476,  3.9546,  0.7632, -0.0278,  0.0236,  0.6452,\n",
       "          -0.7591,  0.9143,  0.1692,  3.7235,  2.9267,  0.8889, -0.7611,\n",
       "           1.5357,  5.5687,  0.2275,  0.0194, -0.0477, -0.9724, -2.4561,\n",
       "           1.3113,  0.8754,  0.5831,  0.4890, -8.1303, -6.6409, -1.0000,\n",
       "          -4.4607,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.0010, -0.3625,  4.0032,  0.7400, -0.0000,  0.0002,  0.6726,\n",
       "          -0.9420,  0.8793,  0.1014,  3.5587,  3.7553,  0.4972, -0.6077,\n",
       "           1.6487,  5.1428,  0.3303, -0.0335, -0.0960, -0.9384, -2.9628,\n",
       "           1.4655,  0.8867, -0.7023, -1.6845, -8.6194, -6.8846, -1.0000,\n",
       "          -4.0745,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.2685,  0.0193,  4.0129,  0.7068,  0.0237, -0.0236,  0.7066,\n",
       "          -1.2708,  0.8053,  0.0214,  3.2357,  5.1067, -0.0296, -0.5241,\n",
       "           1.6972,  4.7114,  0.4488, -0.0937, -0.1407, -0.8775, -3.6117,\n",
       "           1.5748,  0.7848, -1.6345, -3.8765, -7.9028, -7.1059, -1.0000,\n",
       "          -3.6751,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.5028,  0.5475,  3.9566,  0.6575,  0.0414, -0.0471,  0.7509,\n",
       "          -1.8242,  0.7022, -0.0669,  2.8197,  7.2296, -1.0069, -0.4646,\n",
       "           1.7178,  4.3203,  0.5854, -0.1583, -0.1685, -0.7771, -4.6401,\n",
       "           1.4339,  0.5193, -1.2594, -5.7883, -6.1619, -7.3040, -1.0000,\n",
       "          -3.2636,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.6174,  1.1424,  3.8135,  0.5973,  0.0462, -0.0617,  0.7983,\n",
       "          -1.8865,  0.2066, -0.0523,  0.8474,  7.2426, -1.9654, -0.4280,\n",
       "           1.6557,  4.0620,  0.7260, -0.2030, -0.1623, -0.6367, -5.1252,\n",
       "           0.4417,  0.4214, -0.2120, -8.2059, -2.1477, -7.4783, -1.0000,\n",
       "          -2.8416,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.5776,  1.6753,  3.6200,  0.5390,  0.0389, -0.0606,  0.8392,\n",
       "          -1.6579, -0.2159,  0.0902, -0.9306,  6.1379, -2.4134, -0.3801,\n",
       "           1.4776,  4.0532,  0.8497, -0.2041, -0.1225, -0.4705, -5.1596,\n",
       "          -0.5844,  0.8584,  1.9199, -9.3135,  3.4563, -7.6283, -1.0000,\n",
       "          -2.4102,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.3748,  2.0882,  3.4288,  0.4911,  0.0229, -0.0407,  0.8698,\n",
       "          -1.2994, -0.6792,  0.3873, -3.1257,  4.6833, -2.2736, -0.2767,\n",
       "           1.2548,  4.3653,  0.9427, -0.1444, -0.0644, -0.2936, -4.9615,\n",
       "          -1.5380,  1.9857,  5.0367, -8.2899,  9.4962, -7.7534, -1.0000,\n",
       "          -1.9710,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([  0.0982,   2.3020,   3.3090,   0.4649,   0.0056,  -0.0108,\n",
       "            0.8853,  -0.5830,  -0.6939,   0.4689,  -3.3644,   2.0189,\n",
       "           -1.1959,  -0.0941,   1.0874,   5.0345,   0.9912,  -0.0434,\n",
       "           -0.0128,  -0.1244,  -4.3347,  -1.2917,   2.5683,   6.7464,\n",
       "           -4.4121,  15.2211,  -7.8532,  -1.0000,  -1.5254,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -0.0808,   2.2964,   3.3126,   0.4656,  -0.0047,   0.0089,\n",
       "            0.8849,   0.1844,  -0.3096,   0.2153,  -1.5161,  -0.6197,\n",
       "            0.4075,   0.1616,   0.9995,   5.9723,   0.9982,   0.0504,\n",
       "            0.0077,   0.0307,  -3.8660,  -0.3667,   2.0412,   6.4875,\n",
       "           -0.7810,  18.0668,  -7.9275,  -1.0000,  -1.0749,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -0.0472,   2.1379,   3.4172,   0.4864,  -0.0029,   0.0051,\n",
       "            0.8737,   0.6808,   0.3084,  -0.1976,   1.4723,  -2.2889,\n",
       "            1.5003,   0.4830,   0.9612,   7.0445,   0.9784,   0.0944,\n",
       "           -0.0114,   0.1836,  -3.9994,   0.4818,   0.4697,   5.1618,\n",
       "            1.4669,  19.0751,  -7.9759,  -1.0000,  -0.6208,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.1131,   1.8424,   3.5832,   0.5228,   0.0073,  -0.0120,\n",
       "            0.8524,   1.1778,   0.5014,  -0.2711,   2.2918,  -4.1838,\n",
       "            2.2187,   0.8466,   0.9585,   8.1650,   0.9324,   0.0976,\n",
       "           -0.0508,   0.3443,  -4.4063,   0.5887,  -0.1303,   5.0283,\n",
       "            3.7283,  19.0036,  -7.9983,  -1.0000,  -0.1647,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.3574,   1.3716,   3.7723,   0.5750,   0.0255,  -0.0365,\n",
       "            0.8169,   1.6656,   0.7664,  -0.3056,   3.3103,  -6.2964,\n",
       "            2.2520,   1.2280,   0.9233,   9.1590,   0.8572,   0.0700,\n",
       "           -0.0812,   0.5037,  -4.3972,  -0.0506,  -0.5595,   4.2079,\n",
       "            4.3243,  14.8933,  -7.9947,  -1.0000,   0.2920,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.5725,   0.6210,   3.9401,   0.6499,   0.0464,  -0.0543,\n",
       "            0.7566,   2.6752,   0.5805,  -0.1225,   2.3681, -10.5118,\n",
       "            1.8991,   1.5480,   0.8278,   9.8526,   0.7311,   0.0547,\n",
       "           -0.0748,   0.6760,  -5.7233,  -0.3565,   0.7223,   3.2348,\n",
       "            6.9655,   8.6927,  -7.9650,  -1.0000,   0.7477,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ 0.7154,  0.0008,  3.9575,  0.7060,  0.0633, -0.0630,  0.7026,\n",
       "           1.4278,  0.3860, -0.0089,  1.5304, -5.6639, -0.1341,  1.7143,\n",
       "           0.7431,  9.7855,  0.6100,  0.0653, -0.0473,  0.7883, -3.0687,\n",
       "          -0.1390,  0.8757,  1.3253,  4.0214, -2.7458, -7.9093, -1.0000,\n",
       "           1.2009,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.8333, -0.3110,  3.9194,  0.7322,  0.0767, -0.0705,  0.6730,\n",
       "           0.8645,  0.3865,  0.0261,  1.5261, -3.3772, -0.5398,  1.8315,\n",
       "           0.7319,  9.5311,  0.5336,  0.0777, -0.0250,  0.8418, -2.0237,\n",
       "          -0.1046,  0.8098,  0.8269,  2.8026, -4.4113, -7.8279, -1.0000,\n",
       "           1.6503,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.9886, -0.5237,  3.8590,  0.7490,  0.0935, -0.0813,  0.6509,\n",
       "           0.6470,  0.5586,  0.0715,  2.2006, -2.4403, -0.8489,  1.9554,\n",
       "           0.7309,  9.2303,  0.4728,  0.0904,  0.0054,  0.8765, -1.5512,\n",
       "          -0.2083,  1.0469,  0.6051,  2.0123, -5.0314, -7.7210, -1.0000,\n",
       "           2.0942,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.1692, -0.6957,  3.7796,  0.7617,  0.1132, -0.0938,  0.6310,\n",
       "           0.5810,  0.5892,  0.1047,  2.3101, -2.0908, -1.0542,  2.0714,\n",
       "           0.7298,  8.8751,  0.4145,  0.1074,  0.0441,  0.9026, -1.5064,\n",
       "          -0.1430,  1.2460,  0.0444,  1.7186, -6.0477, -7.5890, -1.0000,\n",
       "           2.5314,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.1937, -0.8690,  3.7346,  0.7758,  0.1179, -0.0931,  0.6128,\n",
       "           0.6032, -0.1860, -0.0420, -0.7312, -2.3069, -0.2844,  2.1085,\n",
       "           0.7203,  8.5076,  0.3508,  0.1264,  0.0436,  0.9269, -1.8599,\n",
       "           0.4361, -0.1916,  0.6809,  1.6810, -6.5070, -7.4322, -1.0000,\n",
       "           2.9602,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.1012, -1.0352,  3.7198,  0.7901,  0.1103, -0.0834,  0.5971,\n",
       "           0.5131, -0.3478, -0.0950, -1.3913, -2.0170, -0.1289,  2.0856,\n",
       "           0.7275,  8.0766,  0.2749,  0.1355,  0.0106,  0.9518, -2.2569,\n",
       "           0.2902, -0.5968,  0.4951,  2.0448, -8.5781, -7.2511, -1.0000,\n",
       "           3.3795,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.9423, -1.1650,  3.7244,  0.8016,  0.0953, -0.0696,  0.5861,\n",
       "           0.3631, -0.5637, -0.1753, -2.3005, -1.5245,  0.1370,  2.0315,\n",
       "           0.7342,  7.5718,  0.1882,  0.1284, -0.0414,  0.9728, -2.4848,\n",
       "           0.0097, -1.1859,  0.8130,  1.2167, -9.8491, -7.0465, -1.0000,\n",
       "           3.7877,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([  0.8048,  -1.2356,   3.7332,   0.8079,   0.0817,  -0.0587,\n",
       "            0.5807,   0.1655,  -0.3428,  -0.1143,  -1.4211,  -0.7125,\n",
       "            0.0798,   1.9793,   0.7404,   6.9929,   0.0896,   0.1090,\n",
       "           -0.0872,   0.9861,  -2.7290,  -0.2323,  -0.6941,   0.2775,\n",
       "            0.7533, -11.3779,  -6.8189,  -1.0000,   4.1836,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.7469,  -1.2381,   3.7443,   0.8084,   0.0758,  -0.0545,\n",
       "            0.5812,  -0.0609,  -0.0954,  -0.0323,  -0.3978,   0.2035,\n",
       "            0.1491,   1.9187,   0.7595,   6.3089,  -0.0294,   0.0848,\n",
       "           -0.1061,   0.9903,  -3.2473,  -0.2741,   0.0746,  -1.0037,\n",
       "            0.2264, -13.6659,  -6.5691,  -1.0000,   4.5659,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.7277,  -1.1274,   3.7837,   0.7999,   0.0730,  -0.0541,\n",
       "            0.5933,  -0.4983,  -0.0487,  -0.0154,  -0.2019,   1.8672,\n",
       "            0.6283,   1.8215,   0.7761,   5.5281,  -0.1773,   0.0559,\n",
       "           -0.1043,   0.9770,  -4.0432,  -0.2827,   0.4636,  -1.9410,\n",
       "           -1.4597, -15.6363,  -6.2978,  -1.0000,   4.9333,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.7273,  -0.8670,   3.8537,   0.7792,   0.0711,  -0.0566,\n",
       "            0.6202,  -0.9427,   0.0109,   0.0027,   0.0443,   3.6172,\n",
       "            0.9024,   1.7224,   0.7257,   4.7763,  -0.3439,   0.0257,\n",
       "           -0.0905,   0.9343,  -4.4361,  -0.1484,   0.6190,  -1.7540,\n",
       "           -4.7032, -14.1919,  -6.0061,  -1.0000,   5.2846,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.7862,  -0.4815,   3.9118,   0.7471,   0.0738,  -0.0649,\n",
       "            0.6574,  -1.2657,   0.2435,   0.0379,   0.9731,   4.9667,\n",
       "            0.5821,   1.6539,   0.5524,   4.1738,  -0.5133,   0.0063,\n",
       "           -0.0589,   0.8562,  -4.7055,   0.4063,   0.8790,  -1.9576,\n",
       "           -8.3695, -10.6807,  -5.6948,  -1.0000,   5.6187,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  0.9072,   0.0151,   3.9184,   0.7030,   0.0804,  -0.0802,\n",
       "            0.7021,  -1.5148,   0.4174,   0.0135,   1.6398,   5.9571,\n",
       "           -0.1707,   1.6391,   0.2477,   3.8285,  -0.6788,   0.0006,\n",
       "           -0.0138,   0.7342,  -5.0348,   0.7898,   0.8693,  -1.3087,\n",
       "          -11.6163,  -4.4542,  -5.3649,  -1.0000,   5.9344,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ 1.0417,  0.2199,  3.8777,  0.6828,  0.0900, -0.0948,  0.7189,\n",
       "          -0.2527,  0.3487, -0.0163,  1.3582,  0.9658, -0.3992,  1.6858,\n",
       "          -0.2022,  3.8228, -0.7709,  0.0059,  0.0273,  0.6364, -2.6091,\n",
       "           0.6889,  0.5516, -0.3310, -9.9181,  1.0123, -5.0176, -1.0000,\n",
       "           6.2309,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.1233,  0.1852,  3.8564,  0.6849,  0.0976, -0.1019,  0.7149,\n",
       "           0.2448,  0.2055, -0.0099,  0.7951, -0.9557, -0.1822,  1.7252,\n",
       "          -0.7239,  3.9244, -0.8177,  0.0079,  0.0573,  0.5727, -1.7272,\n",
       "           0.5119,  0.4582, -0.1395, -9.1126,  2.2385, -4.6539, -1.0000,\n",
       "           6.5070,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.2010,  0.1320,  3.8348,  0.6887,  0.1053, -0.1084,  0.7091,\n",
       "           0.1258,  0.2750, -0.0088,  1.0575, -0.4938, -0.3089,  1.7543,\n",
       "          -1.2634,  4.1038, -0.8591,  0.0137,  0.0897,  0.5037, -2.1806,\n",
       "           0.7931,  0.4313, -0.4114, -9.6684,  4.2381, -4.2750, -1.0000,\n",
       "           6.7620,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.2570,  0.0114,  3.8186,  0.6990,  0.1121, -0.1118,  0.6974,\n",
       "           0.4808,  0.1376, -0.0011,  0.5259, -1.8391, -0.1574,  1.7539,\n",
       "          -1.8327,  4.3350, -0.8898,  0.0232,  0.1198,  0.4398, -1.6371,\n",
       "           0.6838,  0.2743, -0.7992, -9.2084,  4.4234, -3.8822, -1.0000,\n",
       "           6.9949,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.2891, -0.1549,  3.8039,  0.7136,  0.1175, -0.1122,  0.6815,\n",
       "           0.5613,  0.0898,  0.0031,  0.3425, -2.1335, -0.1889,  1.7136,\n",
       "          -2.4149,  4.5949, -0.9129,  0.0374,  0.1457,  0.3795, -1.6473,\n",
       "           0.7060,  0.1067, -1.3015, -8.9997,  5.2440, -3.4768, -1.0000,\n",
       "           7.2050,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.3299, -0.3170,  3.7789,  0.7274,  0.1238, -0.1133,  0.6654,\n",
       "           0.5200,  0.1555,  0.0122,  0.5925, -1.9531, -0.3590,  1.6727,\n",
       "          -3.0052,  4.9645, -0.9360,  0.0603,  0.1711,  0.3016, -2.3010,\n",
       "           0.8299, -0.0067, -1.1495, -9.3953,  8.1933, -3.0600, -1.0000,\n",
       "           7.3916,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([  1.3916,  -0.5215,   3.7329,   0.7444,   0.1329,  -0.1151,\n",
       "            0.6442,   0.7538,   0.2331,   0.0301,   0.8880,  -2.7832,\n",
       "           -0.6847,   1.6278,  -3.6185,   5.4478,  -0.9539,   0.0978,\n",
       "            0.1943,   0.2066,  -2.6184,   0.9361,  -0.4040,  -1.7319,\n",
       "           -9.1617,  10.1112,  -2.6332,  -1.0000,   7.5542,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  1.4643,  -0.8148,   3.6507,   0.7684,   0.1449,  -0.1156,\n",
       "            0.6125,   1.1158,   0.2726,   0.0557,   1.0440,  -4.0217,\n",
       "           -1.2319,   1.5453,  -4.2476,   6.0013,  -0.9615,   0.1542,\n",
       "            0.2057,   0.0976,  -3.0980,   0.7783,  -0.9359,  -2.7115,\n",
       "           -8.2874,  11.8069,  -2.1979,  -1.0000,   7.6921,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  1.4903,  -1.2247,   3.5220,   0.8018,   0.1541,  -0.1090,\n",
       "            0.5670,   1.5497,  -0.0132,  -0.0042,  -0.0518,  -5.5214,\n",
       "           -1.7309,   1.4264,  -4.8844,   6.6412,  -0.9605,   0.2127,\n",
       "            0.1736,  -0.0460,  -4.3052,  -0.4402,  -0.5262,  -2.4241,\n",
       "           -7.0793,  13.9277,  -1.7554,  -1.0000,   7.8050,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([  1.4142,  -1.7993,   3.2987,   0.8472,   0.1540,  -0.0908,\n",
       "            0.5002,   2.1896,  -0.3543,  -0.1750,  -1.4831,  -7.6223,\n",
       "           -3.1239,   1.2434,  -5.4766,   7.2565,  -0.9384,   0.2329,\n",
       "            0.0482,  -0.2508,  -6.2932,  -2.2752,   1.0955,  -2.7839,\n",
       "           -3.7313,  13.3110,  -1.3072,  -1.0000,   7.8925,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ 1.1144, -2.4168,  3.0026,  0.8940,  0.1265, -0.0599,  0.4257,\n",
       "           2.0363, -0.9385, -0.7006, -4.4937, -7.1130, -3.5327,  0.9158,\n",
       "          -5.8096,  7.6052, -0.8661,  0.1472, -0.0981, -0.4676, -5.8207,\n",
       "          -0.6948,  2.7214, -2.9300,  1.8830,  7.9932, -0.8548, -1.0000,\n",
       "           7.9542,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.5142, -2.9813,  2.6345,  0.9339,  0.0601, -0.0222,  0.3517,\n",
       "           1.9516, -1.4490, -1.5364, -8.3792, -6.3743, -4.6315,  0.3977,\n",
       "          -5.8278,  7.5176, -0.7702,  0.0376, -0.0857, -0.6309, -4.2770,\n",
       "           2.5255,  0.4216, -3.5002,  6.4102, -0.2897, -0.3995, -1.0000,\n",
       "           7.9900,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.0014, -3.1682,  2.4511,  0.9468,  0.0002,  0.0000,  0.3219,\n",
       "           0.5499, -0.7920, -1.0085, -5.1559, -1.4714, -1.6556, -0.1025,\n",
       "          -5.6733,  7.2786, -0.7218,  0.0121, -0.0124, -0.6919, -1.3289,\n",
       "           1.1702, -0.8437, -4.0614,  3.5498, -2.1853,  0.0570, -1.0000,\n",
       "           7.9998,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.4089, -3.2504,  2.3043,  0.9520, -0.0485,  0.0154,  0.3017,\n",
       "           0.5361, -0.7368, -1.0231, -5.0553, -0.9412, -1.9712, -0.5511,\n",
       "          -5.5024,  7.0161, -0.6829,  0.0128,  0.0495, -0.7287, -1.3666,\n",
       "           1.0507, -1.1778, -3.9553,  4.2705, -3.8175,  0.5134, -1.0000,\n",
       "           7.9835,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.6975, -3.2963,  2.1635,  0.9549, -0.0834,  0.0248,  0.2839,\n",
       "           0.4399, -0.4074, -0.6127, -2.9206, -0.5752, -1.7144, -0.9392,\n",
       "          -5.4005,  6.7423, -0.6562,  0.0286,  0.0872, -0.7489, -0.5965,\n",
       "           0.1121, -0.7576, -4.2233,  1.3252, -3.3389,  0.9681, -1.0000,\n",
       "           7.9412,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.9850, -3.3081,  2.0301,  0.9554, -0.1188,  0.0334,  0.2684,\n",
       "           0.3503, -0.5321, -0.8587, -3.9573,  0.0552, -1.6487, -1.3454,\n",
       "          -5.3547,  6.4896, -0.6420,  0.0472,  0.1228, -0.7553, -0.2880,\n",
       "           0.3481, -1.0791, -4.7000,  0.8050, -3.2401,  1.4196, -1.0000,\n",
       "           7.8730,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.2865, -3.2946,  1.8776,  0.9542, -0.1568,  0.0414,  0.2515,\n",
       "           0.4390, -0.4808, -0.8315, -3.6821,  0.1665, -2.0403, -1.7679,\n",
       "          -5.2761,  6.1994, -0.6260,  0.0689,  0.1618, -0.7597, -0.4743,\n",
       "           0.2389, -1.0883, -4.6238,  1.6176, -4.0582,  1.8665, -1.0000,\n",
       "           7.7792,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.4977, -3.2966,  1.7092,  0.9542, -0.1844,  0.0447,  0.2314,\n",
       "           0.5240, -0.2689, -0.5085, -2.1559, -0.1783, -2.1275, -2.1400,\n",
       "          -5.2303,  5.8969, -0.6144,  0.0940,  0.1797, -0.7625, -0.2682,\n",
       "          -0.3122, -0.5638, -4.6693,  0.4400, -3.7005,  2.3074, -1.0000,\n",
       "           7.6600,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.6950, -3.2944,  1.5190,  0.9540, -0.2109,  0.0461,  0.2082,\n",
       "           0.6075, -0.3027, -0.6397, -2.5968,  0.0977, -2.5125, -2.4941,\n",
       "          -5.1942,  5.5602, -0.6051,  0.1182,  0.1956, -0.7626, -0.2570,\n",
       "          -0.1160, -0.7565, -4.3998,  0.7593, -4.5231,  2.7407, -1.0000,\n",
       "           7.5159,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.9405, -3.2497,  1.3084,  0.9510, -0.2447,  0.0472,  0.1833,\n",
       "           0.6099, -0.3615, -0.8719, -3.3581,  0.8029, -2.6819, -2.8746,\n",
       "          -5.0711,  5.1751, -0.5893,  0.1434,  0.2230, -0.7632, -0.4215,\n",
       "           0.0947, -1.0652, -4.4995,  2.4303, -5.1313,  3.1651, -1.0000,\n",
       "           7.3473,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.1483, -3.2011,  1.0842,  0.9479, -0.2745,  0.0450,  0.1553,\n",
       "           0.7442, -0.2153, -0.6090, -2.2131,  0.4321, -2.8571, -3.2310,\n",
       "          -4.9521,  4.7748, -0.5771,  0.1680,  0.2411, -0.7619, -0.2253,\n",
       "          -0.2572, -0.5987, -4.3903,  1.2495, -5.0034,  3.5791, -1.0000,\n",
       "           7.1547,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.3372, -3.1427,  0.8378,  0.9443, -0.3027,  0.0395,  0.1230,\n",
       "           0.8580, -0.2033, -0.7166, -2.4628,  0.8661, -3.1943, -3.5706,\n",
       "          -4.8818,  4.3534, -0.5748,  0.1889,  0.2571, -0.7535,  0.1480,\n",
       "          -0.1482, -0.7136, -4.2603,  0.3372, -5.3253,  3.9815, -1.0000,\n",
       "           6.9388,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.4941, -3.0822,  0.5681,  0.9407, -0.3270,  0.0298,  0.0855,\n",
       "           1.0262, -0.1092, -0.5330, -1.7303,  0.6568, -3.4661, -3.8897,\n",
       "          -4.7776,  3.8904, -0.5718,  0.2099,  0.2642, -0.7478, -0.2275,\n",
       "          -0.3710, -0.3734, -4.2789,  1.8576, -5.9921,  4.3710, -1.0000,\n",
       "           6.7003,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.5532, -3.0726,  0.2873,  0.9404, -0.3370,  0.0156,  0.0436,\n",
       "           1.1273, -0.0077, -0.0667, -0.2087, -0.2326, -3.5013, -4.1398,\n",
       "          -4.6361,  3.3914, -0.5629,  0.2318,  0.2431, -0.7552, -0.7299,\n",
       "          -0.7388,  0.3279, -3.8805,  2.9094, -6.4701,  4.7462, -1.0000,\n",
       "           6.4400,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.4864, -3.1396,  0.0221,  0.9449, -0.3273,  0.0011,  0.0033,\n",
       "           1.0274,  0.0121,  0.4493,  1.4100, -1.2171, -3.1913, -4.3036,\n",
       "          -4.4758,  2.8629, -0.5440,  0.2530,  0.1848, -0.7784, -1.4294,\n",
       "          -1.0898,  1.1056, -3.6877,  4.1209, -7.3660,  5.1059, -1.0000,\n",
       "           6.1587,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.3679, -3.2233, -0.1958,  0.9504, -0.3096, -0.0094, -0.0287,\n",
       "           0.7747, -0.0211,  0.4644,  1.5004, -1.0002, -2.5482, -4.4345,\n",
       "          -4.2749,  2.3157, -0.5107,  0.2688,  0.1077, -0.8095, -1.7597,\n",
       "          -0.9676,  1.2644, -3.6722,  4.9259, -8.1005,  5.4490, -1.0000,\n",
       "           5.8574,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.2907, -3.2583, -0.4114,  0.9525, -0.2979, -0.0186, -0.0596,\n",
       "           0.8871, -0.0220,  0.2042,  0.6765, -0.1570, -2.9567, -4.6019,\n",
       "          -4.0854,  1.7370, -0.4784,  0.2778,  0.0391, -0.8321, -1.1921,\n",
       "          -0.7707,  1.0192, -4.0593,  3.3505, -8.5519,  5.7743, -1.0000,\n",
       "           5.5369,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.2534, -3.2498, -0.6273,  0.9518, -0.2918, -0.0277, -0.0905,\n",
       "           0.7833, -0.0180,  0.1026,  0.3463,  0.2193, -2.6058, -4.7897,\n",
       "          -3.8551,  1.1226, -0.4405,  0.2767, -0.0242, -0.8537, -1.6670,\n",
       "          -0.4235,  1.1135, -3.7694,  4.7212, -9.4482,  6.0808, -1.0000,\n",
       "           5.1984,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ -2.2675,  -3.1723,  -0.9141,   0.9462,  -0.2923,  -0.0410,\n",
       "           -0.1328,   1.3102,   0.0251,  -0.0972,  -0.3339,   1.3088,\n",
       "           -4.1612,  -4.9941,  -3.5920,   0.4243,  -0.4092,   0.2615,\n",
       "           -0.0752,  -0.8710,  -0.9874,  -0.0609,   0.9870,  -3.6152,\n",
       "            3.8495, -10.2023,   6.3675,  -1.0000,   4.8430,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.2668,  -3.0552,  -1.2546,   0.9376,  -0.2896,  -0.0568,\n",
       "           -0.1839,   1.3857,  -0.0169,   0.0450,   0.1595,   1.5162,\n",
       "           -4.3432,  -5.1712,  -3.3128,  -0.3510,  -0.3787,   0.2252,\n",
       "           -0.1318,  -0.8880,  -1.3940,   0.3662,   1.4703,  -3.1030,\n",
       "            4.0053, -11.1274,   6.6335,  -1.0000,   4.4718,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.2436,  -2.9350,  -1.5492,   0.9288,  -0.2833,  -0.0698,\n",
       "           -0.2287,   1.0724,  -0.0432,   0.0869,   0.3234,   1.3954,\n",
       "           -3.2968,  -5.2964,  -3.0196,  -1.0891,  -0.3332,   0.1729,\n",
       "           -0.1900,  -0.9072,  -2.0637,   0.9754,   1.6804,  -2.2369,\n",
       "            4.2291, -10.2375,   6.8778,  -1.0000,   4.0860,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.2204,  -2.8503,  -1.7301,   0.9225,  -0.2779,  -0.0773,\n",
       "           -0.2565,   0.6059,  -0.0305,   0.0521,   0.2023,   0.9103,\n",
       "           -1.8187,  -5.3989,  -2.7352,  -1.7530,  -0.2386,   0.0450,\n",
       "           -0.2606,  -0.9344,  -3.5647,   2.0248,   1.9968,  -2.1193,\n",
       "            4.4017, -10.4409,   7.0998,  -1.0000,   3.6869,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.2355,  -2.7333,  -1.8936,   0.9138,  -0.2775,  -0.0862,\n",
       "           -0.2839,   0.8258,   0.0604,  -0.0911,  -0.3658,   1.7306,\n",
       "           -2.1685,  -5.5478,  -2.4350,  -2.4256,  -0.1217,  -0.1069,\n",
       "           -0.3067,  -0.9379,  -3.8706,   2.6404,   1.7601,  -2.9101,\n",
       "            4.4137, -10.8701,   7.2986,  -1.0000,   3.2758,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.2747,  -2.5390,  -2.1082,   0.8990,  -0.2788,  -0.1000,\n",
       "           -0.3226,   1.2043,   0.0997,  -0.1272,  -0.5370,   2.7564,\n",
       "           -2.9242,  -5.7716,  -2.1027,  -3.1579,  -0.0020,  -0.2589,\n",
       "           -0.3316,  -0.9072,  -3.8517,   2.6937,   1.6403,  -4.2325,\n",
       "            4.0309, -11.5624,   7.4736,  -1.0000,   2.8540,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.3384,  -2.3202,  -2.2848,   0.8819,  -0.2829,  -0.1152,\n",
       "           -0.3591,   0.9528,   0.1988,  -0.2118,  -0.9543,   2.6331,\n",
       "           -1.8203,  -6.0592,  -1.8071,  -3.8764,   0.1270,  -0.3877,\n",
       "           -0.3293,  -0.8515,  -4.1666,   2.0680,   1.1563,  -4.9022,\n",
       "            2.6662, -11.3845,   7.6243,  -1.0000,   2.4229,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.4237,  -2.0876,  -2.4186,   0.8630,  -0.2894,  -0.1316,\n",
       "           -0.3926,   1.0102,   0.2527,  -0.2298,  -1.1015,   2.9623,\n",
       "           -1.5849,  -6.4328,  -1.6432,  -4.5786,   0.2646,  -0.4792,\n",
       "           -0.3084,  -0.7780,  -4.2461,   1.3351,   1.3670,  -6.6424,\n",
       "           -0.6394, -11.7491,   7.7501,  -1.0000,   1.9839,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.5285,  -1.7358,  -2.5881,   0.8330,  -0.2948,  -0.1561,\n",
       "           -0.4414,   1.7196,   0.3618,  -0.2648,  -1.4123,   5.0338,\n",
       "           -2.2943,  -6.8754,  -1.4912,  -5.2793,   0.3955,  -0.5179,\n",
       "           -0.2923,  -0.7000,  -3.3829,   0.4083,   1.8114,  -7.4124,\n",
       "           -0.9889, -11.0401,   7.8507,  -1.0000,   1.5385,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([-2.6680, -1.2216, -2.7430,  0.7858, -0.2984, -0.1922, -0.5066,\n",
       "           2.2955,  0.5521, -0.2827, -1.8887,  6.9656, -1.7312, -7.3192,\n",
       "          -1.3010, -5.9222,  0.5253, -0.4948, -0.2890, -0.6290, -2.6802,\n",
       "          -0.7056,  2.6894, -6.4003, -2.4381, -9.9442,  7.9257, -1.0000,\n",
       "           1.0880,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.8721, -0.5387, -2.7638,  0.7139, -0.3002, -0.2449, -0.5834,\n",
       "           3.0287,  0.9374, -0.2529, -2.7934,  9.1271,  0.3771, -7.6226,\n",
       "          -1.1373, -6.3469,  0.6598, -0.3906, -0.3071, -0.5637, -1.7609,\n",
       "          -1.7501,  4.4162, -1.8966, -5.2106, -6.5308,  7.9748, -1.0000,\n",
       "           0.6340,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-3.1011,  0.2271, -2.5560,  0.6137, -0.2894, -0.3130, -0.6646,\n",
       "           3.3417,  0.9121,  0.0138, -2.3904,  8.7139,  2.9350, -7.4498,\n",
       "          -0.9228, -6.2760,  0.7593, -0.2004, -0.3717, -0.4950, -0.2078,\n",
       "          -1.2996,  5.4043,  7.8311, -3.0174,  1.1990,  7.9980, -1.0000,\n",
       "           0.1780,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-3.1491,  0.5197, -2.4486,  0.5695, -0.2751, -0.3369, -0.6975,\n",
       "           0.9044, -0.0313, -0.0058,  0.0796,  2.2387,  0.3149, -7.0736,\n",
       "          -0.8778, -6.1219,  0.7944, -0.1055, -0.4043, -0.4407, -0.6341,\n",
       "          -0.4200,  1.9359,  6.1409, -2.5963,  1.1040,  7.9951, -1.0000,\n",
       "          -0.2787,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-3.0679,  0.6159, -2.5289,  0.5632, -0.2610, -0.3297, -0.7113,\n",
       "           0.1521, -0.5630, -0.1311,  1.4814,  0.7857, -1.6558, -6.7643,\n",
       "          -0.9606, -6.1318,  0.8176, -0.0890, -0.4101, -0.3942, -1.1677,\n",
       "          -0.0951,  0.4623,  4.1858, -2.6585,  0.3186,  7.9662, -1.0000,\n",
       "          -0.7344,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.8916,  0.6388, -2.7244,  0.5744, -0.2437, -0.3052, -0.7194,\n",
       "          -0.2250, -0.9133, -0.2119,  2.5679,  0.0236, -2.8275, -6.4609,\n",
       "          -1.1021, -6.2290,  0.8398, -0.1143, -0.4019, -0.3466, -1.6148,\n",
       "          -0.0170, -0.3082,  3.5333, -3.0137,  0.2122,  7.9113, -1.0000,\n",
       "          -1.1878,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.6391,  0.6120, -2.9756,  0.5942, -0.2223, -0.2708, -0.7240,\n",
       "          -0.3828, -1.1353, -0.2350,  3.4454, -0.4773, -3.3058, -6.1174,\n",
       "          -1.2703, -6.3515,  0.8607, -0.1612, -0.3822, -0.2952, -1.8808,\n",
       "          -0.0930, -0.6947,  3.8153, -2.7674,  0.4444,  7.8307, -1.0000,\n",
       "          -1.6372,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.2728,  0.4976, -3.2842,  0.6251, -0.1936, -0.2236, -0.7224,\n",
       "          -0.7962, -1.5705, -0.2540,  5.1620, -1.9464, -4.1458, -5.7102,\n",
       "          -1.4793, -6.4770,  0.8759, -0.2378, -0.3473, -0.2356, -2.4819,\n",
       "          -0.0816, -1.5920,  3.5709, -2.6068,  1.2043,  7.7245, -1.0000,\n",
       "          -2.0814,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.8475,  0.2651, -3.5647,  0.6632, -0.1614, -0.1727, -0.7102,\n",
       "          -0.9974, -1.5064, -0.1338,  5.3173, -3.2317, -3.2546, -5.2677,\n",
       "          -1.7356, -6.5303,  0.8798, -0.3290, -0.2980, -0.1698, -2.6138,\n",
       "          -0.2100, -1.7227,  3.7035, -2.2127,  2.3653,  7.5932, -1.0000,\n",
       "          -2.5187,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.3786, -0.0965, -3.7781,  0.7071, -0.1251, -0.1210, -0.6854,\n",
       "          -1.3655, -1.6516,  0.0058,  6.1650, -5.1057, -2.4629, -4.7760,\n",
       "          -2.0329, -6.5007,  0.8686, -0.4286, -0.2295, -0.0958, -3.0820,\n",
       "          -0.4724, -2.1945,  4.4043, -1.4735,  3.0279,  7.4371, -1.0000,\n",
       "          -2.9479,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.9773, -0.4402, -3.8740,  0.7421, -0.0916, -0.0812, -0.6591,\n",
       "          -0.9457, -1.1822,  0.1178,  4.6066, -3.7748, -0.9008, -4.2592,\n",
       "          -2.3189, -6.3888,  0.8573, -0.4946, -0.1427, -0.0099, -3.2560,\n",
       "          -0.7844, -0.8573,  5.6430, -1.8712,  3.2228,  7.2567, -1.0000,\n",
       "          -3.3674,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.6383, -0.7231, -3.9003,  0.7680, -0.0614, -0.0507, -0.6355,\n",
       "          -0.8409, -1.0202,  0.1766,  4.0964, -3.4055, -0.1675, -3.7500,\n",
       "          -2.5842, -6.2135,  0.8462, -0.5231, -0.0351,  0.0952, -3.8773,\n",
       "          -0.9746, -0.2181,  5.9255, -1.9699,  3.7482,  7.0528, -1.0000,\n",
       "          -3.7760,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.3200, -1.0208, -3.8713,  0.7930, -0.0317, -0.0242, -0.6079,\n",
       "          -0.9718, -0.9501,  0.2356,  3.9174, -3.8685,  0.5577, -3.2531,\n",
       "          -2.8632, -5.9767,  0.8178, -0.5248,  0.0919,  0.2177, -4.5159,\n",
       "          -1.0671,  0.0697,  5.7860, -2.0777,  4.2943,  6.8258, -1.0000,\n",
       "          -4.1723,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.0211, -1.3302, -3.7880,  0.8172, -0.0022, -0.0014, -0.5763,\n",
       "          -1.0074, -0.8602,  0.2870,  3.6459, -3.8687,  1.2011, -2.7754,\n",
       "          -3.1420, -5.6863,  0.7646, -0.4970,  0.2215,  0.3453, -4.7199,\n",
       "          -0.8739,  0.3242,  5.6250, -1.8036,  4.6613,  6.5767, -1.0000,\n",
       "          -4.5550,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.2565, -1.6425, -3.6528,  0.8405,  0.0268,  0.0173, -0.5409,\n",
       "          -1.0820, -0.7712,  0.3309,  3.3711, -3.9318,  1.8597, -2.3239,\n",
       "          -3.3993, -5.3491,  0.6889, -0.4461,  0.3336,  0.4639, -4.5806,\n",
       "          -0.5663,  0.3068,  5.3089, -1.2777,  4.9462,  6.3060, -1.0000,\n",
       "          -4.9228,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.5148, -2.0195, -3.4284,  0.8675,  0.0557,  0.0318, -0.4933,\n",
       "          -1.4909, -0.6749,  0.3744,  3.0847, -5.0401,  3.1970, -1.9140,\n",
       "          -3.6485, -4.9401,  0.5746, -0.3753,  0.4334,  0.5841, -5.3993,\n",
       "          -0.4925,  0.0003,  4.6173, -0.3831,  5.3034,  6.0149, -1.0000,\n",
       "          -5.2746,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.7208, -2.3819, -3.1444,  0.8927,  0.0806,  0.0400, -0.4415,\n",
       "          -1.4414, -0.4827,  0.3469,  2.3570, -4.4065,  3.6614, -1.5598,\n",
       "          -3.8765, -4.4998,  0.4565, -0.2965,  0.4921,  0.6793, -4.1365,\n",
       "           0.0001, -0.2852,  4.1990, -0.3112,  5.1764,  5.7041, -1.0000,\n",
       "          -5.6092,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.8741, -2.7848, -2.7486,  0.9202,  0.1012,  0.0414, -0.3758,\n",
       "          -1.9554, -0.3054,  0.2880,  1.6512, -5.3530,  5.5349, -1.2655,\n",
       "          -4.1201, -3.9886,  0.3229, -0.2152,  0.5198,  0.7611, -4.6049,\n",
       "           0.0324, -0.7275,  3.6116, -0.3838,  5.4464,  5.3748, -1.0000,\n",
       "          -5.9255,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.9558, -3.1490, -2.2859,  0.9447,  0.1139,  0.0368, -0.3052,\n",
       "          -1.8539, -0.1142,  0.1465,  0.7265, -4.3193,  5.8259, -1.0441,\n",
       "          -4.3512, -3.4375,  0.2018, -0.1433,  0.5159,  0.8201, -3.4315,\n",
       "           0.1449, -0.9846,  2.9604, -0.3815,  5.3269,  5.0279, -1.0000,\n",
       "          -6.2226,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.9852, -3.4267, -1.8241,  0.9631,  0.1198,  0.0298, -0.2391,\n",
       "          -1.6886, -0.0236,  0.0411,  0.1847, -3.2356,  5.7369, -0.8979,\n",
       "          -4.5592, -2.8946,  0.1098, -0.0917,  0.4985,  0.8550, -2.4834,\n",
       "           0.0525, -0.8150,  2.0192, -1.1367,  5.1362,  4.6647, -1.0000,\n",
       "          -6.4993,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.9461, -3.6776, -1.2722,  0.9794,  0.1169,  0.0195, -0.1638,\n",
       "          -2.0401,  0.0780, -0.1999, -0.8382, -3.0903,  7.3477, -0.8369,\n",
       "          -4.7573, -2.2949,  0.0069, -0.0397,  0.4700,  0.8818, -2.9689,\n",
       "          -0.0570, -1.1268,  1.2472, -1.0531,  5.4658,  4.2862, -1.0000,\n",
       "          -6.7549,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.8279, -3.8653, -0.6394,  0.9913,  0.1032,  0.0083, -0.0810,\n",
       "          -2.1206,  0.0929, -0.4460, -1.7903, -2.0857,  8.0776, -0.8698,\n",
       "          -4.9189, -1.6209, -0.0978,  0.0085,  0.4286,  0.8981, -2.7853,\n",
       "          -0.1580, -1.2220,  0.2529, -0.9929,  6.0583,  3.8938, -1.0000,\n",
       "          -6.9884,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.6279, -3.9546,  0.0307,  0.9969,  0.0783, -0.0005,  0.0039,\n",
       "          -2.1416,  0.0254, -0.7265, -2.8823, -0.7959,  8.4691, -1.0295,\n",
       "          -5.0173, -0.8834, -0.1944,  0.0503,  0.3818,  0.9022, -2.5554,\n",
       "          -0.2086, -1.1622, -1.5023, -0.7906,  6.9163,  3.4887, -1.0000,\n",
       "          -7.1992,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.3777, -3.9330,  0.6457,  0.9956,  0.0469, -0.0040,  0.0808,\n",
       "          -1.8201, -0.1036, -0.8205, -3.3072,  0.5470,  7.2668, -1.3119,\n",
       "          -5.0211, -0.1601, -0.2713,  0.0836,  0.3414,  0.8960, -1.9545,\n",
       "          -0.1343, -0.8454, -3.1772, -0.0347,  6.8408,  3.0723, -1.0000,\n",
       "          -7.3866,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.0633, -3.8046,  1.2490,  0.9875,  0.0077, -0.0014,  0.1572,\n",
       "          -1.9336, -0.2872, -1.0105, -4.2242,  1.9768,  7.5213, -1.7143,\n",
       "          -4.9205,  0.5489, -0.3481,  0.1163,  0.2994,  0.8807, -2.2207,\n",
       "          -0.1806, -0.8710, -4.6629,  0.7590,  6.7760,  2.6458, -1.0000,\n",
       "          -7.5498,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.3002, -3.5377,  1.8577,  0.9705, -0.0363,  0.0087,  0.2381,\n",
       "          -2.1144, -0.5003, -1.0662, -4.7339,  3.8308,  7.5900, -2.2005,\n",
       "          -4.7109,  1.2394, -0.4366,  0.1507,  0.2512,  0.8506, -2.7582,\n",
       "          -0.2489, -0.9065, -5.4611,  1.1711,  6.2384,  2.2107, -1.0000,\n",
       "          -7.6885,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.6046, -3.1637,  2.3848,  0.9461, -0.0716,  0.0237,  0.3150,\n",
       "          -1.9405, -0.4738, -0.6867, -3.3270,  4.7653,  6.1133, -2.6900,\n",
       "          -4.4963,  1.8691, -0.5296,  0.1913,  0.2146,  0.7980, -3.0625,\n",
       "           0.3132, -0.4695, -6.0337, -0.7039,  6.1290,  1.7684, -1.0000,\n",
       "          -7.8021,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.8683, -2.7277,  2.8076,  0.9164, -0.1002,  0.0420,  0.3853,\n",
       "          -1.8743, -0.5797, -0.6113, -3.3217,  5.5759,  4.8967, -3.1746,\n",
       "          -4.3933,  2.4221, -0.6395,  0.2508,  0.1645,  0.7078, -4.3595,\n",
       "           0.3449, -0.8888, -6.2992, -3.8993,  5.7136,  1.3203, -1.0000,\n",
       "          -7.8903,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.1283, -2.2794,  3.1016,  0.8842, -0.1267,  0.0636,  0.4451,\n",
       "          -1.6402, -0.6473, -0.5131, -3.2045,  5.5330,  3.2637, -3.6410,\n",
       "          -4.4056,  2.9459, -0.7490,  0.3081,  0.0832,  0.5807, -4.9309,\n",
       "          -0.0899, -1.2188, -5.6352, -5.5357,  6.9843,  0.8680, -1.0000,\n",
       "          -7.9528,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.4530, -1.8199,  3.2691,  0.8486, -0.1588,  0.0926,  0.4960,\n",
       "          -1.5640, -1.0385, -0.6267, -4.5921,  5.9225,  1.6461, -4.1016,\n",
       "          -4.5269,  3.5003, -0.8477,  0.3308, -0.0455,  0.4122, -6.0762,\n",
       "          -1.4111, -0.9975, -4.8171, -7.9942,  9.3204,  0.4128, -1.0000,\n",
       "          -7.9893,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ -1.8650,  -1.4738,   3.2355,   0.8181,  -0.2012,   0.1286,\n",
       "            0.5232,  -0.7713,  -1.3554,  -0.6482,  -5.4375,   3.6562,\n",
       "           -1.1745,  -4.5500,  -4.8285,   4.0861,  -0.9142,   0.2821,\n",
       "           -0.1852,   0.2246,  -5.9830,  -1.8856,   0.3770,  -3.4407,\n",
       "           -9.9998,  12.0607,  -0.0437,  -1.0000,  -7.9999,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.3636,  -1.3711,   2.9436,   0.8034,  -0.2608,   0.1654,\n",
       "            0.5091,   0.5070,  -1.7373,  -0.7902,  -6.3819,   0.2241,\n",
       "           -4.5877,  -4.9496,  -5.2900,   4.6750,  -0.9455,   0.1554,\n",
       "           -0.2841,   0.0339,  -5.9019,  -1.1108,   2.0678,  -1.3912,\n",
       "           -9.3511,  14.5857,  -0.5001,  -1.0000,  -7.9844,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([ -2.7384,  -1.6359,   2.4406,   0.8221,  -0.3230,   0.1718,\n",
       "            0.4362,   2.4560,  -1.1649,  -0.6986,  -4.0977,  -4.4899,\n",
       "           -6.9195,  -5.2590,  -5.7287,   5.1667,  -0.9526,   0.0368,\n",
       "           -0.2526,  -0.1657,  -5.6589,   2.5786,   0.7176,  -1.9711,\n",
       "           -3.8831,  14.5711,  -0.9549,  -1.0000,  -7.9428,   0.0000,\n",
       "            1.0000,   0.0000,   0.8177]),\n",
       "  tensor([-2.7541, -2.1503,  1.9712,  0.8672, -0.3438,  0.1326,  0.3349,\n",
       "           2.3102,  0.3329,  0.3342,  1.3675, -5.6601, -3.8159, -5.2870,\n",
       "          -5.9508,  5.4714, -0.9282,  0.0728, -0.0225, -0.3643, -3.5181,\n",
       "           4.1649, -3.8796,  0.1614,  2.2270,  8.3545, -1.4065, -1.0000,\n",
       "          -7.8754,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.5435, -2.5513,  1.7584,  0.8999, -0.3209,  0.0990,  0.2781,\n",
       "           1.3746,  0.5496,  0.7616,  2.8776, -4.4503, -1.9823, -5.0284,\n",
       "          -5.8663,  5.6755, -0.8507,  0.1650,  0.0899, -0.4909, -3.3588,\n",
       "           1.2456, -2.7289,  3.1670,  6.9156,  5.5274, -1.8536, -1.0000,\n",
       "          -7.7823,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.3567, -2.6927,  1.8028,  0.9107, -0.2949,  0.0891,  0.2751,\n",
       "          -0.2831,  0.3010,  0.4589,  1.7732, -0.5965,  1.4852, -4.7177,\n",
       "          -5.6117,  5.9499, -0.7996,  0.1942,  0.0982, -0.5597, -1.5079,\n",
       "           0.2060, -0.2214,  3.6218,  5.3643,  4.9755, -2.2946, -1.0000,\n",
       "          -7.6639,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.2482, -2.6869,  1.9444,  0.9103, -0.2783,  0.0896,  0.2931,\n",
       "          -0.5363,  0.1811,  0.2579,  1.0458,  0.4371,  1.8677, -4.4772,\n",
       "          -5.2916,  6.2874, -0.7667,  0.1965,  0.0974, -0.6033, -1.2482,\n",
       "           0.3089, -0.0530,  3.0921,  6.1325,  4.7390, -2.7282, -1.0000,\n",
       "          -7.5204,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.2300, -2.5533,  2.1380,  0.9002, -0.2726,  0.0984,  0.3251,\n",
       "          -1.0707, -0.0534, -0.0672, -0.2875,  2.3810,  2.6881, -4.3162,\n",
       "          -4.9189,  6.6705, -0.7506,  0.1804,  0.1037, -0.6272, -0.2669,\n",
       "           0.6661,  0.3090,  2.6048,  5.1059,  5.3336, -3.1528, -1.0000,\n",
       "          -7.3525,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.2377, -2.3555,  2.3484,  0.8850, -0.2691,  0.1106,  0.3636,\n",
       "          -1.0826, -0.0125, -0.0132, -0.0606,  2.5156,  2.5988, -4.1953,\n",
       "          -4.4867,  7.0660, -0.7401,  0.1601,  0.1096, -0.6439, -0.4766,\n",
       "           0.4798,  0.2569,  2.1490,  6.3650,  5.0362, -3.5672, -1.0000,\n",
       "          -7.1606,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.2050, -2.2001,  2.5244,  0.8730, -0.2608,  0.1180,  0.3948,\n",
       "          -0.7480,  0.1371,  0.1243,  0.6206,  1.5827,  1.9889, -4.0497,\n",
       "          -3.9875,  7.4002, -0.7133,  0.1539,  0.1136, -0.6742, -1.2424,\n",
       "           0.3185, -0.1148,  2.4611,  8.3094,  3.9539, -3.9700, -1.0000,\n",
       "          -6.9454,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.1522, -2.0767,  2.6711,  0.8637, -0.2506,  0.1219,  0.4200,\n",
       "          -0.6571,  0.1429,  0.1153,  0.6221,  1.4828,  1.7070, -3.8898,\n",
       "          -3.4911,  7.6590, -0.6792,  0.1542,  0.1170, -0.7080, -1.1320,\n",
       "           0.2860, -0.1124,  2.3727,  7.6500,  2.9049, -4.3598, -1.0000,\n",
       "          -6.7076,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.1100, -1.9643,  2.7879,  0.8551, -0.2424,  0.1250,  0.4409,\n",
       "          -0.5499,  0.0967,  0.0705,  0.4090,  1.3691,  1.3116, -3.7293,\n",
       "          -2.9701,  7.8323, -0.6366,  0.1581,  0.1253, -0.7444, -1.4652,\n",
       "           0.3814, -0.3739,  2.6143,  8.9025,  1.4860, -4.7355, -1.0000,\n",
       "          -6.4479,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-2.0155, -1.8496,  2.9336,  0.8467, -0.2276,  0.1249,  0.4645,\n",
       "          -0.6722,  0.3922,  0.2575,  1.6231,  1.4162,  2.0799, -3.5398,\n",
       "          -2.4070,  8.0058, -0.5884,  0.1647,  0.1195, -0.7826, -1.6152,\n",
       "          -0.0633,  0.1078,  2.4415,  9.4443,  1.8444, -5.0956, -1.0000,\n",
       "          -6.1672,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.8492, -1.7533,  3.0985,  0.8405, -0.2048,  0.1188,  0.4874,\n",
       "          -0.5357,  0.5580,  0.3275,  2.2940,  1.0172,  2.0194, -3.3148,\n",
       "          -1.8440,  8.1479, -0.5347,  0.1721,  0.0945, -0.8219, -1.8563,\n",
       "          -0.2525,  0.3486,  2.3778,  9.4068,  0.3855, -5.4392, -1.0000,\n",
       "          -5.8664,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.6653, -1.6015,  3.2809,  0.8301, -0.1800,  0.1119,  0.5157,\n",
       "          -0.8360,  0.5661,  0.2917,  2.3168,  2.2039,  2.3626, -3.0932,\n",
       "          -1.2868,  8.3079, -0.4921,  0.1705,  0.0622, -0.8514, -1.2171,\n",
       "          -0.1500,  0.6552,  2.0386,  8.4209,  1.4444, -5.7651, -1.0000,\n",
       "          -5.5465,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.4444, -1.3760,  3.4836,  0.8143, -0.1513,  0.1025,  0.5510,\n",
       "          -1.0410,  0.7393,  0.3143,  2.9957,  3.0994,  2.6316, -2.8685,\n",
       "          -0.7166,  8.5314, -0.4651,  0.1613,  0.0198, -0.8702, -0.8601,\n",
       "          -0.2357,  1.0682,  1.7212,  8.1032,  2.3630, -6.0722, -1.0000,\n",
       "          -5.2085,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-1.1456, -1.0893,  3.6923,  0.7940, -0.1154,  0.0860,  0.5906,\n",
       "          -1.1553,  1.0287,  0.3352,  4.1432,  3.7941,  2.6358, -2.6075,\n",
       "          -0.0982,  8.7574, -0.4423,  0.1492, -0.0398, -0.8835, -0.9227,\n",
       "          -0.4447,  1.5154,  1.6486,  8.6448,  1.7942, -6.3595, -1.0000,\n",
       "          -4.8536,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.8359, -0.7706,  3.8535,  0.7706, -0.0809,  0.0661,  0.6286,\n",
       "          -1.0646,  0.9174,  0.2088,  3.6859,  3.8765,  1.7606, -2.3298,\n",
       "           0.5169,  8.9030, -0.4215,  0.1361, -0.0984, -0.8911, -0.7535,\n",
       "          -0.3042,  1.2496,  1.9761,  7.7338,  0.6203, -6.6261, -1.0000,\n",
       "          -4.4828,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.5282, -0.4603,  3.9576,  0.7469, -0.0492,  0.0437,  0.6617,\n",
       "          -0.9676,  0.9599,  0.1356,  3.8541,  3.7272,  1.1191, -2.0408,\n",
       "           1.0960,  8.9338, -0.3970,  0.1227, -0.1536, -0.8965, -0.9050,\n",
       "          -0.3248,  1.2570,  2.1776,  7.3073, -1.1165, -6.8710, -1.0000,\n",
       "          -4.0974,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.2494, -0.2068,  4.0068,  0.7265, -0.0225,  0.0214,  0.6865,\n",
       "          -0.6893,  0.8293,  0.0586,  3.3328,  2.7377,  0.4567, -1.7402,\n",
       "           1.5927,  8.8483, -0.3645,  0.1058, -0.1980, -0.9037, -1.1005,\n",
       "          -0.0971,  0.9364,  2.8324,  6.1205, -2.5740, -7.0936, -1.0000,\n",
       "          -3.6987,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([-0.0123, -0.0251,  4.0203,  0.7111, -0.0011,  0.0011,  0.7031,\n",
       "          -0.4766,  0.6851,  0.0143,  2.7549,  1.9145,  0.0861, -1.4375,\n",
       "           2.0307,  8.6449, -0.3151,  0.0804, -0.2297, -0.9173, -1.6911,\n",
       "           0.1504,  0.6345,  3.2558,  6.2699, -4.6871, -7.2931, -1.0000,\n",
       "          -3.2879,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.2142,  0.1240,  4.0135,  0.6976,  0.0186, -0.0191,  0.7160,\n",
       "          -0.4361,  0.7209, -0.0123,  2.8967,  1.7498, -0.1427, -1.1367,\n",
       "           2.4048,  8.3768, -0.2583,  0.0474, -0.2577, -0.9299, -1.6509,\n",
       "           0.2608,  0.7661,  3.1337,  4.8764, -5.0158, -7.4689, -1.0000,\n",
       "          -2.8664,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.4359,  0.2279,  3.9913,  0.6875,  0.0374, -0.0394,  0.7242,\n",
       "          -0.2572,  0.6852, -0.0320,  2.7456,  1.0160, -0.3093, -0.8392,\n",
       "           2.6819,  8.0491, -0.1931,  0.0058, -0.2829, -0.9395, -2.0063,\n",
       "           0.4426,  0.7040,  3.1759,  3.5680, -6.2802, -7.6202, -1.0000,\n",
       "          -2.4356,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.6916,  0.3200,  3.9494,  0.6773,  0.0587, -0.0633,  0.7307,\n",
       "          -0.3079,  0.8685, -0.0603,  3.4583,  1.1825, -0.6257, -0.5465,\n",
       "           2.8670,  7.6330, -0.1139, -0.0497, -0.3171, -0.9402, -2.4266,\n",
       "           0.6539,  1.2778,  2.4267,  1.8074, -7.8204, -7.7468, -1.0000,\n",
       "          -1.9968,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 0.9630,  0.4346,  3.8816,  0.6636,  0.0807, -0.0897,  0.7383,\n",
       "          -0.4008,  0.8585, -0.0844,  3.3811,  1.4879, -0.9228, -0.2821,\n",
       "           2.9851,  7.1520, -0.0213, -0.1205, -0.3562, -0.9264, -2.7762,\n",
       "           0.9025,  1.4076,  1.7838,  0.5265, -8.4088, -7.8481, -1.0000,\n",
       "          -1.5515,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.2254,  0.5635,  3.7907,  0.6472,  0.1011, -0.1165,  0.7466,\n",
       "          -0.4505,  0.8402, -0.1124,  3.2631,  1.5884, -1.2051, -0.0416,\n",
       "           3.0331,  6.6434,  0.0827, -0.2031, -0.3873, -0.8955, -3.1602,\n",
       "           1.1122,  1.3609,  1.6054, -1.0059, -8.5187, -7.9238, -1.0000,\n",
       "          -1.1012,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.4675,  0.6915,  3.6826,  0.6294,  0.1190, -0.1426,  0.7545,\n",
       "          -0.4631,  0.7739, -0.1333,  2.9574,  1.5307, -1.3866,  0.1869,\n",
       "           3.0053,  6.1319,  0.1940, -0.2877, -0.4012, -0.8477, -3.4057,\n",
       "           1.0571,  1.1230,  1.6833, -2.3216, -8.2754, -7.9738, -1.0000,\n",
       "          -0.6473,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.7022,  0.8660,  3.5432,  0.6049,  0.1344, -0.1702,  0.7662,\n",
       "          -0.7658,  0.7750, -0.1720,  2.9125,  2.4600, -1.8838,  0.3793,\n",
       "           2.8998,  5.6025,  0.3224, -0.3763, -0.4039, -0.7690, -4.3147,\n",
       "           1.2470,  1.5015,  0.7335, -4.6583, -8.3594, -7.9977, -1.0000,\n",
       "          -0.1913,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 1.8877,  1.0483,  3.3977,  0.5783,  0.1442, -0.1943,  0.7791,\n",
       "          -0.7119,  0.5775, -0.1654,  2.1456,  2.1389, -1.7665,  0.5526,\n",
       "           2.7206,  5.1079,  0.4519, -0.4420, -0.3814, -0.6745, -3.9567,\n",
       "           0.4437,  1.1906,  1.4177, -5.5680, -7.3568, -7.9956, -1.0000,\n",
       "           0.2654,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 2.0276,  1.2083,  3.2620,  0.5536,  0.1499, -0.2140,  0.7908,\n",
       "          -0.6675,  0.4466, -0.1557,  1.6509,  1.8889, -1.6586,  0.7418,\n",
       "           2.4905,  4.6784,  0.5616, -0.4688, -0.3449, -0.5881, -3.2664,\n",
       "          -0.1821,  1.1461,  2.2536, -6.1708, -6.1934, -7.9674, -1.0000,\n",
       "           0.7212,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 2.1398,  1.3540,  3.1313,  0.5298,  0.1528, -0.2310,  0.8016,\n",
       "          -0.6518,  0.3692, -0.1515,  1.3649,  1.7421, -1.6267,  0.9631,\n",
       "           2.2264,  4.3199,  0.6526, -0.4663, -0.3077, -0.5118, -2.6789,\n",
       "          -0.4799,  1.2522,  3.1671, -6.5942, -4.8566, -7.9133, -1.0000,\n",
       "           1.1746,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 2.2415,  1.4646,  3.0086,  0.5094,  0.1552, -0.2467,  0.8097,\n",
       "          -0.5155,  0.3567, -0.1667,  1.3206,  1.1972, -1.5226,  1.2310,\n",
       "           1.9439,  4.0446,  0.7228, -0.4455, -0.2779, -0.4493, -1.9406,\n",
       "          -0.5223,  1.2413,  4.1289, -6.3589, -3.3641, -7.8334, -1.0000,\n",
       "           1.6242,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 2.3214,  1.6298,  2.8609,  0.4811,  0.1530, -0.2615,  0.8227,\n",
       "          -0.9467,  0.2337, -0.1257,  0.8742,  2.4564, -2.0163,  1.5407,\n",
       "           1.6717,  3.8212,  0.7945, -0.4098, -0.2482, -0.3732, -2.4704,\n",
       "          -0.6049,  1.8146,  5.3111, -6.9991, -2.1314, -7.7279, -1.0000,\n",
       "           2.0685,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 2.4232,  1.7224,  2.7190,  0.4593,  0.1540, -0.2781,  0.8295,\n",
       "          -0.4677,  0.4098, -0.2513,  1.5531,  0.6868, -1.7705,  1.9172,\n",
       "           1.4068,  3.6779,  0.8424, -0.3706, -0.2332, -0.3140, -1.2982,\n",
       "          -0.1821,  1.3226,  5.9466, -5.5542, -0.8466, -7.5973, -1.0000,\n",
       "           2.5061,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 2.5151,  1.8237,  2.5660,  0.4349,  0.1529, -0.2942,  0.8372,\n",
       "          -0.7589,  0.2582, -0.1758,  0.9846,  1.5382, -1.9908,  2.3374,\n",
       "           1.1600,  3.6023,  0.8853, -0.3235, -0.2249, -0.2470, -1.7060,\n",
       "          -0.1616,  1.9007,  7.3005, -5.6983,  0.8203, -7.4420, -1.0000,\n",
       "           2.9355,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 2.6415,  1.8686,  2.4019,  0.4136,  0.1550, -0.3147,  0.8402,\n",
       "          -0.5079,  0.4971, -0.3747,  1.9071,  0.2667, -2.2310,  2.8030,\n",
       "           0.9284,  3.5916,  0.9121, -0.2838, -0.2328, -0.1824, -1.3036,\n",
       "           0.5249,  1.3015,  7.1565, -4.4499,  1.9194, -7.2623, -1.0000,\n",
       "           3.3554,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 2.8169,  1.8824,  2.1825,  0.3878,  0.1586, -0.3436,  0.8405,\n",
       "          -0.7360,  0.6302, -0.5220,  2.3851,  0.2062, -3.1141,  3.2894,\n",
       "           0.7576,  3.6013,  0.9237, -0.2630, -0.2556, -0.1106, -1.5698,\n",
       "           1.0325,  0.9419,  7.1315, -2.7250,  2.8889, -7.0590, -1.0000,\n",
       "           3.7643,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.0557,  1.8262,  1.8900,  0.3572,  0.1646, -0.3846,  0.8351,\n",
       "          -0.7036,  0.9192, -0.8537,  3.3744, -1.1657, -4.0361,  3.7813,\n",
       "           0.6241,  3.6389,  0.9149, -0.2738, -0.2954, -0.0269, -1.9016,\n",
       "           1.8077, -0.0405,  6.2351, -1.4181,  4.3655, -6.8328, -1.0000,\n",
       "           4.1609,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.2657,  1.7433,  1.5916,  0.3243,  0.1664, -0.4250,  0.8286,\n",
       "          -0.8243,  0.6638, -0.6956,  2.3152, -0.8702, -3.5741,  4.3021,\n",
       "           0.5522,  3.7516,  0.8926, -0.2880, -0.3396,  0.0715, -2.1087,\n",
       "           1.8964,  0.4630,  8.0496,  0.0251,  5.6827, -6.5842, -1.0000,\n",
       "           4.5440,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.4724,  1.5652,  1.3139,  0.2994,  0.1719, -0.4672,  0.8140,\n",
       "          -0.3731,  0.8552, -0.9922,  2.7745, -2.8759, -3.5219,  4.8477,\n",
       "           0.4974,  3.9203,  0.8474, -0.3174, -0.3888,  0.1732, -2.4096,\n",
       "           2.2484, -0.5626,  7.7909,  1.2510,  6.2977, -6.3142, -1.0000,\n",
       "           4.9123,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.6912,  1.2162,  1.0590,  0.2959,  0.1943, -0.5135,  0.7817,\n",
       "           0.5427,  1.0538, -1.2263,  2.7727, -5.0682, -3.1281,  5.3932,\n",
       "           0.4288,  4.1181,  0.7680, -0.3818, -0.4351,  0.2740, -2.9894,\n",
       "           2.2676, -1.5366,  7.7489,  3.0176,  6.3928, -6.0236, -1.0000,\n",
       "           5.2646,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.8409,  0.7867,  0.9124,  0.3388,  0.2494, -0.5383,  0.7302,\n",
       "           2.1734,  0.8686, -0.8117,  1.5211, -5.1325, -1.4195,  5.8638,\n",
       "           0.3433,  4.2968,  0.6767, -0.4500, -0.4595,  0.3584, -2.5486,\n",
       "           1.5779, -1.2754,  6.5691,  2.6548,  4.0679, -5.7134, -1.0000,\n",
       "           5.5997,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.9229,  0.3292,  0.8300,  0.4432,  0.3543, -0.5147,  0.6427,\n",
       "           4.7958,  0.7732, -0.3917,  0.8200, -5.5935, -1.0016,  6.2325,\n",
       "           0.2524,  4.3779,  0.5888, -0.5089, -0.4523,  0.4356, -2.8356,\n",
       "           1.0597, -0.8388,  5.3770,  3.2684,  1.3536, -5.3846, -1.0000,\n",
       "           5.9166,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.9583, -0.0270,  0.7037,  0.5585,  0.4678, -0.4401,  0.5249,\n",
       "           4.5071,  0.5526, -0.0097,  0.4147, -3.4196, -2.1455,  6.3422,\n",
       "           0.1903,  4.1634,  0.5204, -0.5682, -0.4320,  0.4688, -0.5337,\n",
       "          -0.5728, -7.4618, -0.1050,  2.4463, -4.2767, -5.0382, -1.0000,\n",
       "           6.2142,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.9857, -0.0234,  0.5256,  0.5542,  0.4859, -0.4454,  0.5083,\n",
       "          -2.1927,  0.6340,  0.0836,  0.3693,  1.5882, -2.3590,  6.3128,\n",
       "           0.3375,  3.8209,  0.5810, -0.4912, -0.3120,  0.5691, -1.2239,\n",
       "           0.3432,  5.9476, -1.3600,  2.5787, -4.5201, -4.6755, -1.0000,\n",
       "           6.4915,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0002, -0.0729,  0.3898,  0.5810,  0.5258, -0.4170,  0.4606,\n",
       "           3.5238,  0.2767,  0.0429,  0.1179, -1.2941, -1.3387,  6.2882,\n",
       "           0.4880,  3.5317,  0.5448, -0.5359, -0.3133,  0.5637, -0.4661,\n",
       "          -0.8397, -4.0092, -0.1192,  3.8473, -3.5768, -4.2974, -1.0000,\n",
       "           6.7477,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0102,  0.0342,  0.2820,  0.5058,  0.4716, -0.4925,  0.5284,\n",
       "          -4.3128,  0.3249,  0.0105,  0.0996,  1.3633, -1.2731,  6.2545,\n",
       "           0.7813,  3.3031,  0.5892, -0.4117, -0.1743,  0.6730, -2.3460,\n",
       "           1.6297,  7.4170, -0.7874,  4.0810, -2.8975, -3.9054, -1.0000,\n",
       "           6.9819,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0137, -0.0505,  0.2168,  0.5870,  0.5549, -0.4051,  0.4284,\n",
       "           7.0492,  0.1246,  0.0191,  0.0295, -1.5508, -0.7601,  6.2301,\n",
       "           0.8954,  3.0998,  0.5091, -0.5675, -0.2729,  0.5868,  0.4360,\n",
       "          -2.0286, -5.8504, -0.1591,  2.2614, -3.0588, -3.5007, -1.0000,\n",
       "           7.1934,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0160,  0.0242,  0.1811,  0.5067,  0.4846, -0.4928,  0.5154,\n",
       "          -7.1938,  0.1301,  0.0158,  0.0248,  1.4147, -0.3724,  6.1924,\n",
       "           1.1554,  2.9726,  0.5278, -0.4925, -0.1838,  0.6672, -2.1502,\n",
       "           1.9708,  5.4971, -1.0997,  4.4115, -1.7933, -3.0845, -1.0000,\n",
       "           7.3814,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0168,  0.0515,  0.1571,  0.4574,  0.4396, -0.5356,  0.5574,\n",
       "          -2.2289,  0.0849, -0.0131,  0.0143,  0.3146, -0.3979,  6.0971,\n",
       "           1.3590,  2.8268,  0.5289, -0.4044, -0.0817,  0.7416, -1.8789,\n",
       "           1.0744,  3.4247, -2.1989,  3.2334, -2.7569, -2.6583, -1.0000,\n",
       "           7.5454,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0171, -0.0205,  0.1489,  0.5728,  0.5516, -0.4205,  0.4368,\n",
       "           7.9928,  0.0091,  0.0009,  0.0014, -1.2020, -0.1517,  6.0187,\n",
       "           1.4384,  2.6676,  0.4675, -0.5971, -0.1821,  0.6259,  1.0200,\n",
       "          -3.2147, -5.0399, -0.9048,  1.5706, -2.7824, -2.2235, -1.0000,\n",
       "           7.6848,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0180,  0.0480,  0.1239,  0.4493,  0.4354, -0.5429,  0.5602,\n",
       "          -6.2255,  0.0589, -0.0063,  0.0077,  0.7800, -0.3283,  5.9323,\n",
       "           1.6157,  2.5472,  0.4899, -0.4481, -0.0516,  0.7460, -2.8924,\n",
       "           3.3153,  5.8055, -1.6164,  2.2879, -1.9143, -1.7814, -1.0000,\n",
       "           7.7992,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0185,  0.0603,  0.1039,  0.4054,  0.3943, -0.5750,  0.5912,\n",
       "          -1.7261,  0.0649, -0.0225,  0.0080,  0.0995, -0.3271,  5.8338,\n",
       "           1.7316,  2.3971,  0.4751, -0.3623,  0.0316,  0.8013, -1.7013,\n",
       "           0.9588,  2.1630, -1.9695,  2.1383, -3.0022, -1.3335, -1.0000,\n",
       "           7.8881,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0189,  0.0322,  0.0932,  0.4709,  0.4600, -0.5261,  0.5384,\n",
       "           5.4756,  0.0430, -0.0111,  0.0043, -0.5559, -0.0429,  5.7515,\n",
       "           1.8564,  2.1902,  0.4428, -0.5280, -0.0333,  0.7239,  2.0221,\n",
       "          -5.0084, -5.4946, -1.1060,  2.9745, -4.0794, -0.8812, -1.0000,\n",
       "           7.9513,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0189,  0.0612,  0.0829,  0.3765,  0.3680, -0.5943,  0.6080,\n",
       "          -6.3219,  0.0069, -0.0025,  0.0007,  0.5356, -0.2226,  5.6971,\n",
       "           2.0885,  1.9544,  0.4046, -0.4138,  0.0661,  0.8128, -4.0888,\n",
       "           4.0613,  4.2708, -1.1481,  3.9638, -4.3713, -0.4261, -1.0000,\n",
       "           7.9886,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0192,  0.0377,  0.0797,  0.4442,  0.4353, -0.5481,  0.5592,\n",
       "           6.2306,  0.0821, -0.0313,  0.0077, -0.6342, -0.1386,  5.6741,\n",
       "           2.2345,  1.6989,  0.3680, -0.5596,  0.0228,  0.7422,  2.1084,\n",
       "          -5.5707, -4.2836,  0.1901,  2.3778, -4.6848,  0.0304, -1.0000,\n",
       "           7.9999,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0198,  0.0468,  0.0320,  0.3094,  0.3064, -0.6332,  0.6398,\n",
       "          -6.1165,  0.1131, -0.0702,  0.0068, -0.0196, -0.6270,  5.6437,\n",
       "           2.3500,  1.4333,  0.3236, -0.3832,  0.1238,  0.8562, -4.0374,\n",
       "           5.1582,  3.5241, -0.9457,  1.3480, -4.2113,  0.4869, -1.0000,\n",
       "           7.9852,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0200,  0.0078, -0.0175,  0.3603,  0.3621, -0.6095,  0.6062,\n",
       "           5.5147,  0.2026, -0.1430, -0.0003, -0.5731, -0.8234,  5.6427,\n",
       "           2.3895,  1.1492,  0.3041, -0.5026,  0.0942,  0.8037,  2.5628,\n",
       "          -6.1285, -3.3904,  0.7016,  1.2997, -5.0607,  0.9417, -1.0000,\n",
       "           7.9444,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0189, -0.0532, -0.0620,  0.2329,  0.2387, -0.6745,  0.6587,\n",
       "          -5.8990,  0.1773, -0.1751, -0.0190, -1.0338, -0.4052,  5.6461,\n",
       "           2.3886,  0.8364,  0.2367, -0.3275,  0.1692,  0.8989, -4.2567,\n",
       "           5.4806,  2.2916, -0.2562, -0.1019, -5.1814,  1.3934, -1.0000,\n",
       "           7.8777,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0147, -0.1682, -0.0922,  0.1522,  0.1605, -0.7073,  0.6714,\n",
       "          -3.0869,  0.2009, -0.3615, -0.0732, -1.7218, -0.3321,  5.6690,\n",
       "           2.2928,  0.5053,  0.1626, -0.2111,  0.2014,  0.9426, -2.8113,\n",
       "           2.4355,  0.3911,  1.0763, -0.6813, -6.3928,  1.8407, -1.0000,\n",
       "           7.7854,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 4.0037, -0.3007, -0.1735,  0.1675,  0.1833, -0.7153,  0.6532,\n",
       "           2.4791,  0.2380, -0.4910, -0.1749, -1.6235, -1.6702,  5.7373,\n",
       "           2.1538,  0.1146,  0.1375, -0.3164,  0.1791,  0.9214,  1.3717,\n",
       "          -4.7175, -1.3193,  1.6774, -1.2718, -6.4399,  2.2819, -1.0000,\n",
       "           7.6677,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.9849, -0.4565, -0.2362,  0.1494,  0.1707, -0.7328,  0.6415,\n",
       "          -1.7450,  0.2373, -0.4432, -0.2474, -2.1752, -0.1903,  5.7794,\n",
       "           1.9460, -0.2890,  0.0888, -0.3370,  0.1813,  0.9196, -1.8250,\n",
       "           0.3971, -0.1841,  0.4453, -2.8909, -7.0702,  2.7157, -1.0000,\n",
       "           7.5250,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.9376, -0.6180, -0.5108,  0.2120,  0.2597, -0.7307,  0.5947,\n",
       "           4.1553,  0.6366, -0.9187, -0.8116, -1.9349, -5.0112,  5.7913,\n",
       "           1.7026, -0.8314,  0.0909, -0.4355,  0.1604,  0.8811,  1.4463,\n",
       "          -2.6297, -0.5846,  0.8513, -2.4862, -7.1247,  3.1406, -1.0000,\n",
       "           7.3577,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.8740, -0.8483, -0.6346,  0.1872,  0.2464, -0.7569,  0.5756,\n",
       "          -2.1694,  0.3950, -0.4975, -0.6517, -3.3206,  0.2056,  5.7990,\n",
       "           1.3410, -1.2942,  0.0417, -0.4231,  0.1611,  0.8907, -2.0481,\n",
       "           0.5375, -0.4742,  0.7913, -5.3439, -7.4586,  3.5553, -1.0000,\n",
       "           7.1666,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.8042, -1.1182, -0.6308,  0.1452,  0.2032, -0.7877,  0.5632,\n",
       "          -1.4054,  0.4027, -0.6857, -0.9871, -3.5079, -0.0371,  5.8449,\n",
       "           0.8597, -1.7271, -0.0393, -0.4136,  0.1669,  0.8942, -1.9003,\n",
       "          -0.2871, -0.8513,  2.0774, -6.4995, -8.4219,  3.9585, -1.0000,\n",
       "           6.9520,  0.0000,  1.0000,  0.0000,  0.8177]),\n",
       "  tensor([ 3.6920, -1.4540, -0.6054,  0.1059,  0.1613, -0.8198,  0.5392,\n",
       "          -1.5553,  0.4458, -1.0061, -1.6644, -4.7048,  0.4880,  5.9681,\n",
       "           0.2112, -2.1327, -0.1311, -0.4145,  0.1511,  0.8878, -1.8801,\n",
       "          -0.5472, -1.5344,  4.2241, -9.5980, -7.3904,  4.3487, -1.0000,\n",
       "           6.7148,  0.0000,  1.0000,  0.0000,  0.8177])],\n",
       " [tensor([ 0.3189, -0.9161, -1.5375, -1.2414]),\n",
       "  tensor([ 2.2996, -0.7101, -0.9032, -1.4569]),\n",
       "  tensor([ 1.5014, -1.3096, -0.6655,  0.3862]),\n",
       "  tensor([ 0.5137, -0.8709, -0.2849,  0.4222]),\n",
       "  tensor([ 1.1894, -0.2851, -1.6778,  0.3113]),\n",
       "  tensor([ 0.7768, -0.3574, -1.1240,  0.3211]),\n",
       "  tensor([ 0.0694, -1.8065, -0.8292,  1.0840]),\n",
       "  tensor([-0.2122, -1.1632, -1.2719,  0.3505]),\n",
       "  tensor([-0.0057, -0.2006, -0.9333,  0.7332]),\n",
       "  tensor([-0.5833, -1.2821, -1.2930, -0.6946]),\n",
       "  tensor([-1.1267, -1.1354, -0.6524,  1.3964]),\n",
       "  tensor([-0.9709, -0.6133, -1.1338,  0.0686]),\n",
       "  tensor([-0.4360, -1.6742, -1.4836,  0.6677]),\n",
       "  tensor([-0.9029, -1.2539, -0.8910,  0.8941]),\n",
       "  tensor([-1.7186, -1.2767, -0.7740,  1.6685]),\n",
       "  tensor([-2.2007, -1.2281, -1.0050, -0.2974]),\n",
       "  tensor([-0.9662, -0.7983, -0.5040,  0.6719]),\n",
       "  tensor([-1.2365, -0.0176, -0.7303, -0.9335]),\n",
       "  tensor([-1.1776, -0.8985, -1.1720, -1.1297]),\n",
       "  tensor([-0.9274, -0.7217, -0.8640, -0.3583]),\n",
       "  tensor([-1.3319, -1.4780, -1.9454, -0.6651]),\n",
       "  tensor([-1.0127, -1.2503, -0.6280, -1.3004]),\n",
       "  tensor([ 0.2922, -1.4549, -1.2735, -0.8758]),\n",
       "  tensor([ 0.6542, -0.9275, -1.4657, -0.2792]),\n",
       "  tensor([-0.1045, -1.1652, -0.6017,  0.0518]),\n",
       "  tensor([ 0.2306, -0.8731, -0.0191, -1.0556]),\n",
       "  tensor([-0.8517, -0.6383, -0.8913, -0.5877]),\n",
       "  tensor([ 1.1337, -1.0659, -0.5560, -0.4215]),\n",
       "  tensor([-0.5097, -0.9680, -0.3152, -1.6614]),\n",
       "  tensor([ 0.3117, -0.7821, -0.9147, -1.1045]),\n",
       "  tensor([ 0.4159, -0.0949, -0.9991, -0.7659]),\n",
       "  tensor([ 0.2516, -0.5074, -1.2709, -0.7221]),\n",
       "  tensor([-0.1894, -1.3697, -1.0001,  0.6132]),\n",
       "  tensor([ 1.1122, -0.1373, -0.5882,  0.6792]),\n",
       "  tensor([ 0.2979, -0.9716,  0.5696,  1.4021]),\n",
       "  tensor([ 0.1234, -0.9579,  0.2391, -0.1230]),\n",
       "  tensor([ 0.1053,  0.2602, -0.7212, -0.3041]),\n",
       "  tensor([ 0.0376, -0.6567, -0.1900, -0.0687]),\n",
       "  tensor([-0.1635, -1.0846, -0.7131,  0.6432]),\n",
       "  tensor([-0.1161, -0.8069, -0.8580,  1.7916]),\n",
       "  tensor([-0.2975, -0.8743, -0.2781,  0.2079]),\n",
       "  tensor([-0.7786, -1.0856, -0.5885,  0.6423]),\n",
       "  tensor([-1.3624, -0.5535, -0.3571,  0.6787]),\n",
       "  tensor([-0.4028, -0.2010, -0.3275,  0.1801]),\n",
       "  tensor([-1.1177, -1.4031, -0.4435,  0.6244]),\n",
       "  tensor([ 1.0302, -1.3042, -1.1495,  0.3252]),\n",
       "  tensor([-0.0967, -1.0786, -0.8461,  1.0563]),\n",
       "  tensor([-0.7618, -1.2550, -1.8805,  0.2223]),\n",
       "  tensor([-0.9975, -1.1421, -0.6767, -0.3396]),\n",
       "  tensor([-1.5473, -1.3248, -0.5565, -0.8087]),\n",
       "  tensor([-1.5007, -0.2584, -0.6133, -0.0008]),\n",
       "  tensor([-1.2329, -1.2461, -1.1879, -0.4714]),\n",
       "  tensor([-1.6125, -0.7363, -1.8152,  0.5719]),\n",
       "  tensor([-0.9977, -0.8998, -1.1347,  1.6476]),\n",
       "  tensor([-0.7113, -1.6457, -1.2438,  1.9602]),\n",
       "  tensor([-0.6523, -0.1777, -0.8384,  1.2729]),\n",
       "  tensor([-1.0790, -1.0842, -0.8215,  0.8647]),\n",
       "  tensor([-0.4245, -1.0541, -1.8469, -1.0674]),\n",
       "  tensor([-0.8704, -0.2956, -1.1599, -0.0110]),\n",
       "  tensor([ 0.1645, -1.1909, -0.4829, -0.2995]),\n",
       "  tensor([-1.2713, -1.0480, -0.6477,  0.3792]),\n",
       "  tensor([-1.1329, -1.6140, -1.0767,  0.7175]),\n",
       "  tensor([-0.8707, -1.4946, -1.3997,  0.4223]),\n",
       "  tensor([-0.6183, -0.8702, -0.1191, -0.2071]),\n",
       "  tensor([-0.8446, -1.5895, -0.0530,  0.0670]),\n",
       "  tensor([-1.1612, -0.7938, -1.3687, -0.6221]),\n",
       "  tensor([-0.7770, -0.9703, -1.0460, -1.0475]),\n",
       "  tensor([-1.0123, -0.9822, -1.5131, -1.5206]),\n",
       "  tensor([-1.3225, -2.9260, -0.5436, -0.6105]),\n",
       "  tensor([-0.3785, -1.8577, -0.8141, -1.1270]),\n",
       "  tensor([-1.4527, -1.0197, -1.2365, -0.9339]),\n",
       "  tensor([-1.2787, -1.7515, -1.2118, -0.2060]),\n",
       "  tensor([-0.6819, -1.0777, -0.5787, -0.5883]),\n",
       "  tensor([-1.3269, -1.4797, -1.1489, -1.3347]),\n",
       "  tensor([-2.0418, -1.7672, -1.1907, -0.1176]),\n",
       "  tensor([-0.7203, -0.9654, -1.0571, -0.6214]),\n",
       "  tensor([-0.8017, -1.6919, -0.1236, -0.5787]),\n",
       "  tensor([ 1.9350, -0.3122, -0.9464, -1.1287]),\n",
       "  tensor([-0.1960, -1.1704,  0.8456,  1.2994]),\n",
       "  tensor([ 0.2379, -0.5983, -0.5743,  0.1426]),\n",
       "  tensor([ 1.1982, -0.8763,  0.8598,  1.1484]),\n",
       "  tensor([-0.5088, -1.4172, -0.2694, -0.9514]),\n",
       "  tensor([ 0.0782, -0.9743, -0.6694, -0.0812]),\n",
       "  tensor([ 0.3147, -1.0881,  0.0564,  1.1546]),\n",
       "  tensor([ 1.1893, -1.7047, -1.5263, -1.2858]),\n",
       "  tensor([-0.3722, -1.7315, -0.9520, -0.1336]),\n",
       "  tensor([ 0.9808, -1.0428,  0.1871,  0.3141]),\n",
       "  tensor([ 0.7012, -0.3729,  0.1358, -0.3555]),\n",
       "  tensor([ 0.1350, -1.4424, -1.5354,  0.3558]),\n",
       "  tensor([ 0.7732, -0.1643, -0.8871,  0.0837]),\n",
       "  tensor([ 0.5308, -0.4931, -1.0201,  0.4190]),\n",
       "  tensor([ 1.0110, -1.7081, -0.7654, -0.0670]),\n",
       "  tensor([ 1.0574, -1.2965,  0.3945,  0.2791]),\n",
       "  tensor([ 0.6740, -0.7736, -1.2627, -0.4660]),\n",
       "  tensor([ 0.7171, -0.9185, -0.1648,  0.9991]),\n",
       "  tensor([ 0.3941, -0.4516, -0.6967,  0.7791]),\n",
       "  tensor([-0.0606,  0.2261, -0.4712, -1.0257]),\n",
       "  tensor([-0.2556, -0.9863, -1.5511,  0.1685]),\n",
       "  tensor([ 0.5069, -2.0964, -0.5568,  0.1858]),\n",
       "  tensor([ 0.7374, -0.7496, -0.2986,  0.3380]),\n",
       "  tensor([-0.2386, -1.3200, -0.5030,  0.3363]),\n",
       "  tensor([-0.5207, -0.6946, -0.2942,  1.2643]),\n",
       "  tensor([ 0.8812, -0.9344, -0.9914,  1.2226]),\n",
       "  tensor([ 1.0385, -0.4336, -0.7365,  0.4800]),\n",
       "  tensor([ 0.2346, -1.4404, -1.3133,  1.2286]),\n",
       "  tensor([ 0.7806, -1.3757, -0.2845,  1.6206]),\n",
       "  tensor([-0.3096, -1.5402, -0.5515, -1.0307]),\n",
       "  tensor([ 0.2244, -0.7885, -0.8776, -1.4369]),\n",
       "  tensor([ 0.3764, -1.4771, -0.7217, -0.7390]),\n",
       "  tensor([ 0.6510, -0.4147, -1.3256, -0.7058]),\n",
       "  tensor([ 0.3335, -0.6426, -0.3347, -0.7112]),\n",
       "  tensor([ 0.5551, -1.3590, -0.3289, -0.4230]),\n",
       "  tensor([ 0.4916, -0.0416, -0.5344, -1.1330]),\n",
       "  tensor([ 1.2903, -0.8596, -1.1335, -0.9226]),\n",
       "  tensor([ 0.6247, -1.6375, -1.4156, -1.4691]),\n",
       "  tensor([-1.2130, -1.5348, -1.9748, -1.6501]),\n",
       "  tensor([ 0.2946, -0.9507, -1.4651, -1.4724]),\n",
       "  tensor([ 0.4240, -1.4816, -1.4330, -1.1716]),\n",
       "  tensor([-0.9080, -1.2300, -0.4495, -0.6036]),\n",
       "  tensor([-0.0180, -1.3280, -1.2442, -1.1094]),\n",
       "  tensor([-1.6328, -0.8074, -0.8689, -1.8355]),\n",
       "  tensor([-0.1374, -1.3831, -0.8980, -1.7330]),\n",
       "  tensor([-0.0528, -1.3984, -1.7704, -0.4456]),\n",
       "  tensor([-0.2666, -0.4951, -0.8923, -1.2790]),\n",
       "  tensor([-0.1872, -0.5224, -0.8316, -2.0921]),\n",
       "  tensor([-0.4191, -1.1269, -1.0988, -0.9170]),\n",
       "  tensor([ 0.4697, -0.7029, -1.2244, -0.9418]),\n",
       "  tensor([-0.5025, -1.3324, -0.8629, -0.8065]),\n",
       "  tensor([-0.3652, -0.5069, -0.4857, -0.5173]),\n",
       "  tensor([-0.2977, -1.4750, -0.4440,  1.0524]),\n",
       "  tensor([ 0.1130, -1.7232, -1.6165,  0.3276]),\n",
       "  tensor([-0.2528, -0.6272, -0.4696,  1.0733]),\n",
       "  tensor([ 0.0886, -0.0268, -2.3709,  0.9292]),\n",
       "  tensor([ 0.5471, -1.2998, -0.9705,  0.9101]),\n",
       "  tensor([-0.0599, -1.4855, -1.2248,  1.2109]),\n",
       "  tensor([-1.2862, -1.2850, -0.9177, -0.9710]),\n",
       "  tensor([-1.1602, -0.7237, -1.2080, -1.0313]),\n",
       "  tensor([-1.7277, -1.4134, -1.5992,  0.4371]),\n",
       "  tensor([-0.9472, -1.3672, -1.8221,  0.9302]),\n",
       "  tensor([-1.0464, -1.0264, -0.8192, -0.9961]),\n",
       "  tensor([-1.7866, -0.8043,  0.4818, -0.1898]),\n",
       "  tensor([-1.3008, -0.5508, -0.9393, -1.2466]),\n",
       "  tensor([-0.6670, -0.1882, -1.8191, -0.6849]),\n",
       "  tensor([-0.8582,  0.3848, -0.5855, -1.0120]),\n",
       "  tensor([-0.6704, -0.6370, -0.8261, -0.6298]),\n",
       "  tensor([-0.7898, -0.4276, -0.9755,  0.6483]),\n",
       "  tensor([-0.3104, -1.2237, -0.5931,  0.2531]),\n",
       "  tensor([-0.9014, -0.9460, -0.7433,  1.0052]),\n",
       "  tensor([-0.8736, -0.6804, -0.3431,  0.8127]),\n",
       "  tensor([-1.2256, -0.2603, -0.5814,  0.2497]),\n",
       "  tensor([-1.4446, -1.7607, -0.7153,  0.7683]),\n",
       "  tensor([-0.8939, -0.6784, -0.8141,  0.4789]),\n",
       "  tensor([ 0.3367, -0.4270, -1.3311,  0.6879]),\n",
       "  tensor([-1.2844, -0.4874, -0.8953, -0.1919]),\n",
       "  tensor([-0.5492, -1.0513, -0.9752,  0.9311]),\n",
       "  tensor([ 0.1612, -1.7822, -0.9387,  0.4523]),\n",
       "  tensor([-0.0700, -1.4441, -0.3454,  0.6931]),\n",
       "  tensor([-1.8272, -0.6570, -0.1589,  0.3328]),\n",
       "  tensor([-0.6185, -1.2546, -0.8130,  1.2457]),\n",
       "  tensor([-0.6816, -1.1556, -1.1957,  1.2670]),\n",
       "  tensor([-0.3833, -0.9527, -0.2067,  0.7871]),\n",
       "  tensor([-1.1236, -1.2372, -0.9807,  0.9961]),\n",
       "  tensor([-1.4779, -1.0902, -0.8582,  0.4850]),\n",
       "  tensor([-0.7635, -1.6636, -0.9497,  0.4856]),\n",
       "  tensor([-0.8053, -1.0063, -1.5198,  0.2194]),\n",
       "  tensor([-0.4157, -0.2157, -0.5629,  0.0739]),\n",
       "  tensor([-0.4530, -0.5205, -1.0225, -0.1940]),\n",
       "  tensor([-1.6020, -0.8826, -0.9866,  0.4296]),\n",
       "  tensor([-1.7710, -0.5925, -0.6349, -0.7683]),\n",
       "  tensor([-1.6224,  0.4562, -1.6986, -0.6248]),\n",
       "  tensor([-0.7720, -0.8937, -1.8212, -1.2347]),\n",
       "  tensor([-1.4213, -0.6543, -0.9510,  0.4370]),\n",
       "  tensor([-0.8773, -1.5688, -0.6888, -0.6489]),\n",
       "  tensor([-1.6997, -1.6620, -0.8285, -0.6711]),\n",
       "  tensor([-0.8135, -1.1723, -0.6414, -1.0166]),\n",
       "  tensor([-0.5111, -1.5882, -1.2031, -0.8589]),\n",
       "  tensor([-0.1547, -0.6380, -1.3859, -1.0275]),\n",
       "  tensor([-1.3514, -0.3638, -0.7320,  1.5924]),\n",
       "  tensor([-0.3956, -1.6369, -0.9624, -0.6546]),\n",
       "  tensor([-1.3711, -1.4160, -0.5669,  0.7580]),\n",
       "  tensor([ 1.1365, -1.0846, -0.5638, -1.4635]),\n",
       "  tensor([-0.8787, -1.4254, -1.2964,  0.2938]),\n",
       "  tensor([ 0.6703, -0.7127, -0.5763,  0.1140]),\n",
       "  tensor([ 1.4169, -1.4861, -0.3366, -1.5281]),\n",
       "  tensor([-0.6601, -2.0047, -1.1327,  0.9986]),\n",
       "  tensor([ 0.6690, -0.9584, -1.1488, -0.2272]),\n",
       "  tensor([ 0.7723, -0.6865, -2.0669, -0.7417]),\n",
       "  tensor([-0.6748, -1.0284, -0.8587,  0.0002]),\n",
       "  tensor([ 0.3212, -0.9600, -0.1040, -0.6866]),\n",
       "  tensor([-0.9322, -0.5435, -0.2229,  1.5932]),\n",
       "  tensor([ 1.3294, -0.6832, -0.5283, -1.0242]),\n",
       "  tensor([-0.2026, -0.4063, -1.0488,  0.8048]),\n",
       "  tensor([ 1.6050, -1.1865, -1.3382, -0.9024]),\n",
       "  tensor([ 1.4445, -0.2070, -0.0082, -0.3524]),\n",
       "  tensor([ 0.5584, -1.6518, -0.7910,  0.4981]),\n",
       "  tensor([ 0.3151, -0.8170,  0.7770, -0.2307]),\n",
       "  tensor([-1.1431, -1.2398, -1.3176,  0.1441]),\n",
       "  tensor([ 0.6529, -0.8921, -0.6029, -0.7595]),\n",
       "  tensor([-0.4226, -0.7127, -0.0579, -1.5435]),\n",
       "  tensor([-0.0014, -0.7693, -0.8384, -0.4970])],\n",
       " [tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.])],\n",
       " [tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.]),\n",
       "  tensor([ 0.])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run_episode(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.agent.policy.save_model('./checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'action_std'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-11c3dc81c01b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPPOAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./checkpoint.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/RL_repos/DeepRL_Continuous_Control/src/model/ppo/agent.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, env, network_state_path, action_std_min, seed)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mnetwork_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpolicy_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'network'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/RL_repos/DeepRL_Continuous_Control/src/model/ppo/agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, action_std_min, network_config, seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mnetwork_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'action_std_init'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_ACTION_STD_INIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnetwork_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m31\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' Params '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'action_std'"
     ]
    }
   ],
   "source": [
    "PPOAgent.from_file(env, './checkpoint.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
